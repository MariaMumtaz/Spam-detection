{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8846c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import tensorflow as tf\n",
    "\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602799b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 57) (4601,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. read the dataset\n",
    "x = []\n",
    "y = []\n",
    "with open('data/spambase.data', 'rt') as csvfile:\n",
    "\tdata = csv.reader(csvfile, delimiter=',')\n",
    "\tfor raw in data:\n",
    "\t\tx.append(np.array(raw[:-1], dtype=np.float32))\n",
    "\t\ty.append(int(raw[-1]))\n",
    "\t\t\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "n_ch = x.shape[-1]\n",
    "\n",
    "#normalize inputs\n",
    "for ch in range(n_ch):\n",
    "\tch_v = x[:, ch]\n",
    "\tnorm = ch_v.max()\n",
    "\tx[:, ch] /= norm\n",
    "\n",
    "print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5211ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'class']\n"
     ]
    }
   ],
   "source": [
    "#importing columns names\n",
    "cols=[]\n",
    "with open(\"data/columns.txt\",\"r\") as doc:\n",
    "    lines=doc.readlines()\n",
    "    for line in lines :\n",
    "        cols.append(line.split(\":\")[0])\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84ca500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.028886</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.029985</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.064895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.048553</td>\n",
       "      <td>0.142605</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0        0.000000           0.044818       0.125490           0.0   \n",
       "1        0.046256           0.019608       0.098039           0.0   \n",
       "2        0.013216           0.000000       0.139216           0.0   \n",
       "3        0.000000           0.000000       0.000000           0.0   \n",
       "4        0.000000           0.000000       0.000000           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0          0.032        0.000000          0.000000            0.000000   \n",
       "1          0.014        0.047619          0.028886            0.006301   \n",
       "2          0.123        0.032313          0.026135            0.010801   \n",
       "3          0.063        0.000000          0.042641            0.056706   \n",
       "4          0.063        0.000000          0.042641            0.056706   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0         0.000000        0.000000  ...     0.000000     0.000000   \n",
       "1         0.000000        0.051705  ...     0.000000     0.013536   \n",
       "2         0.121673        0.013751  ...     0.002281     0.014664   \n",
       "3         0.058935        0.034653  ...     0.000000     0.014048   \n",
       "4         0.058935        0.034653  ...     0.000000     0.013843   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0     0.023955     0.000000     0.000000   \n",
       "1          0.0     0.011454     0.029985     0.002421   \n",
       "2          0.0     0.008498     0.030651     0.000504   \n",
       "3          0.0     0.004218     0.000000     0.000000   \n",
       "4          0.0     0.004157     0.000000     0.000000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                    0.003407                    0.006107   \n",
       "1                    0.004639                    0.010111   \n",
       "2                    0.008908                    0.048553   \n",
       "3                    0.003208                    0.004004   \n",
       "4                    0.003208                    0.004004   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                  0.017549    1.0  \n",
       "1                  0.064895    1.0  \n",
       "2                  0.142605    1.0  \n",
       "3                  0.012057    1.0  \n",
       "4                  0.012057    1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.append(x,y.reshape(y.shape[0],1),axis = 1), columns=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347eb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances =  4601\n",
    "# attributes: 57 float, 1 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a fully connected classifier network that will classify the mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6320337",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns!= 'class']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82ee83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da2ded4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_x = X.sample(frac=0.8)\n",
    "test_x = X.loc[~X.index.isin(train_x.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fe7aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = Y.sample(frac=0.8)\n",
    "test_y = Y.loc[~Y.index.isin(train_y.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62203890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = train_x.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ad3d71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               [(None, 57)]              0         \n",
      "_________________________________________________________________\n",
      "L1 (Dense)                   (None, 60)                3480      \n",
      "_________________________________________________________________\n",
      "L2 (Dense)                   (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "L3 (Dense)                   (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "L4 (Dense)                   (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,631\n",
      "Trainable params: 5,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dim = train_x.shape[1]\n",
    "x = tf.keras.layers.Input(name = 'X', dtype =  tf.float32, shape = dim)\n",
    "\n",
    "#1 layer: 57 inputs -> 60 outputs, relu activation\n",
    "l1 = tf.keras.layers.Dense(units=60, name='L1', activation = 'relu')(x)\n",
    "#layer 2: 60 inputs -> 30 output, relu activation\n",
    "l2 = tf.keras.layers.Dense(units=30, name='L2', activation='relu')(l1)\n",
    "#layer 3: 30 inputs -> 10 output, relu activation\n",
    "l3 = tf.keras.layers.Dense(units=10, name='L3', activation='relu')(l2)\n",
    "#layer 4: 10 inputs -> 1 output, softmax activation\n",
    "l4 = tf.keras.layers.Dense(units=1, name='L4', activation='sigmoid')(l3)\n",
    "\n",
    "model =  tf.keras.Model(inputs=x, outputs=l4)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00025)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dd39ce7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.6859 - mse: 0.2464 - val_loss: 0.6850 - val_mse: 0.2459\n",
      "Epoch 2/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6733 - mse: 0.2401 - val_loss: 0.6836 - val_mse: 0.2452\n",
      "Epoch 3/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6690 - mse: 0.2380 - val_loss: 0.6848 - val_mse: 0.2457\n",
      "Epoch 4/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6681 - mse: 0.2376 - val_loss: 0.6845 - val_mse: 0.2456\n",
      "Epoch 5/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6675 - mse: 0.2373 - val_loss: 0.6828 - val_mse: 0.2448\n",
      "Epoch 6/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6672 - mse: 0.2372 - val_loss: 0.6807 - val_mse: 0.2438\n",
      "Epoch 7/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6666 - mse: 0.2369 - val_loss: 0.6809 - val_mse: 0.2439\n",
      "Epoch 8/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6662 - mse: 0.2367 - val_loss: 0.6793 - val_mse: 0.2431\n",
      "Epoch 9/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6658 - mse: 0.2365 - val_loss: 0.6795 - val_mse: 0.2432\n",
      "Epoch 10/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6652 - mse: 0.2362 - val_loss: 0.6783 - val_mse: 0.2427\n",
      "Epoch 11/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6646 - mse: 0.2360 - val_loss: 0.6794 - val_mse: 0.2432\n",
      "Epoch 12/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6642 - mse: 0.2358 - val_loss: 0.6787 - val_mse: 0.2428\n",
      "Epoch 13/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6635 - mse: 0.2354 - val_loss: 0.6776 - val_mse: 0.2423\n",
      "Epoch 14/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6630 - mse: 0.2352 - val_loss: 0.6766 - val_mse: 0.2418\n",
      "Epoch 15/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6623 - mse: 0.2349 - val_loss: 0.6763 - val_mse: 0.2417\n",
      "Epoch 16/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6618 - mse: 0.2346 - val_loss: 0.6774 - val_mse: 0.2423\n",
      "Epoch 17/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6613 - mse: 0.2344 - val_loss: 0.6754 - val_mse: 0.2413\n",
      "Epoch 18/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6605 - mse: 0.2340 - val_loss: 0.6758 - val_mse: 0.2415\n",
      "Epoch 19/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6598 - mse: 0.2337 - val_loss: 0.6750 - val_mse: 0.2411\n",
      "Epoch 20/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6591 - mse: 0.2334 - val_loss: 0.6774 - val_mse: 0.2423\n",
      "Epoch 21/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6586 - mse: 0.2331 - val_loss: 0.6770 - val_mse: 0.2421\n",
      "Epoch 22/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6576 - mse: 0.2327 - val_loss: 0.6770 - val_mse: 0.2421\n",
      "Epoch 23/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6569 - mse: 0.2324 - val_loss: 0.6777 - val_mse: 0.2424\n",
      "Epoch 24/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6557 - mse: 0.2318 - val_loss: 0.6810 - val_mse: 0.2440\n",
      "Epoch 25/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6554 - mse: 0.2317 - val_loss: 0.6783 - val_mse: 0.2427\n",
      "Epoch 26/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6541 - mse: 0.2311 - val_loss: 0.6777 - val_mse: 0.2425\n",
      "Epoch 27/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6531 - mse: 0.2306 - val_loss: 0.6826 - val_mse: 0.2448\n",
      "Epoch 28/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6529 - mse: 0.2306 - val_loss: 0.6856 - val_mse: 0.2461\n",
      "Epoch 29/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6517 - mse: 0.2299 - val_loss: 0.6792 - val_mse: 0.2432\n",
      "Epoch 30/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6508 - mse: 0.2295 - val_loss: 0.6818 - val_mse: 0.2444\n",
      "Epoch 31/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6502 - mse: 0.2293 - val_loss: 0.6869 - val_mse: 0.2467\n",
      "Epoch 32/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6498 - mse: 0.2291 - val_loss: 0.6807 - val_mse: 0.2439\n",
      "Epoch 33/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6485 - mse: 0.2285 - val_loss: 0.6803 - val_mse: 0.2437\n",
      "Epoch 34/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6480 - mse: 0.2283 - val_loss: 0.6824 - val_mse: 0.2447\n",
      "Epoch 35/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6468 - mse: 0.2277 - val_loss: 0.6835 - val_mse: 0.2452\n",
      "Epoch 36/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6464 - mse: 0.2276 - val_loss: 0.6890 - val_mse: 0.2476\n",
      "Epoch 37/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6450 - mse: 0.2270 - val_loss: 0.6810 - val_mse: 0.2441\n",
      "Epoch 38/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6438 - mse: 0.2264 - val_loss: 0.6904 - val_mse: 0.2482\n",
      "Epoch 39/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6443 - mse: 0.2267 - val_loss: 0.6824 - val_mse: 0.2446\n",
      "Epoch 40/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6423 - mse: 0.2257 - val_loss: 0.6869 - val_mse: 0.2467\n",
      "Epoch 41/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6415 - mse: 0.2254 - val_loss: 0.6881 - val_mse: 0.2472\n",
      "Epoch 42/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6407 - mse: 0.2250 - val_loss: 0.6884 - val_mse: 0.2473\n",
      "Epoch 43/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6397 - mse: 0.2246 - val_loss: 0.6856 - val_mse: 0.2461\n",
      "Epoch 44/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6385 - mse: 0.2240 - val_loss: 0.6877 - val_mse: 0.2470\n",
      "Epoch 45/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6376 - mse: 0.2236 - val_loss: 0.6904 - val_mse: 0.2482\n",
      "Epoch 46/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6366 - mse: 0.2232 - val_loss: 0.6916 - val_mse: 0.2486\n",
      "Epoch 47/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.6355 - mse: 0.2226 - val_loss: 0.6921 - val_mse: 0.2487\n",
      "Epoch 48/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6343 - mse: 0.2221 - val_loss: 0.6879 - val_mse: 0.2469\n",
      "Epoch 49/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6329 - mse: 0.2215 - val_loss: 0.6888 - val_mse: 0.2472\n",
      "Epoch 50/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6315 - mse: 0.2209 - val_loss: 0.6963 - val_mse: 0.2505\n",
      "Epoch 51/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6304 - mse: 0.2204 - val_loss: 0.6936 - val_mse: 0.2492\n",
      "Epoch 52/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6300 - mse: 0.2201 - val_loss: 0.7001 - val_mse: 0.2518\n",
      "Epoch 53/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6282 - mse: 0.2195 - val_loss: 0.6951 - val_mse: 0.2498\n",
      "Epoch 54/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6271 - mse: 0.2190 - val_loss: 0.6905 - val_mse: 0.2477\n",
      "Epoch 55/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6256 - mse: 0.2183 - val_loss: 0.7011 - val_mse: 0.2522\n",
      "Epoch 56/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6239 - mse: 0.2175 - val_loss: 0.6960 - val_mse: 0.2500\n",
      "Epoch 57/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6222 - mse: 0.2168 - val_loss: 0.6970 - val_mse: 0.2501\n",
      "Epoch 58/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6214 - mse: 0.2165 - val_loss: 0.7069 - val_mse: 0.2544\n",
      "Epoch 59/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6194 - mse: 0.2156 - val_loss: 0.6992 - val_mse: 0.2510\n",
      "Epoch 60/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6183 - mse: 0.2151 - val_loss: 0.7006 - val_mse: 0.2513\n",
      "Epoch 61/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6170 - mse: 0.2146 - val_loss: 0.7137 - val_mse: 0.2566\n",
      "Epoch 62/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6144 - mse: 0.2134 - val_loss: 0.7009 - val_mse: 0.2511\n",
      "Epoch 63/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6129 - mse: 0.2128 - val_loss: 0.6981 - val_mse: 0.2499\n",
      "Epoch 64/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6122 - mse: 0.2125 - val_loss: 0.7056 - val_mse: 0.2533\n",
      "Epoch 65/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6107 - mse: 0.2118 - val_loss: 0.7135 - val_mse: 0.2556\n",
      "Epoch 66/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6091 - mse: 0.2112 - val_loss: 0.7089 - val_mse: 0.2537\n",
      "Epoch 67/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6072 - mse: 0.2103 - val_loss: 0.7116 - val_mse: 0.2544\n",
      "Epoch 68/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6062 - mse: 0.2099 - val_loss: 0.7058 - val_mse: 0.2520\n",
      "Epoch 69/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6044 - mse: 0.2091 - val_loss: 0.7194 - val_mse: 0.2573\n",
      "Epoch 70/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6033 - mse: 0.2087 - val_loss: 0.7218 - val_mse: 0.2575\n",
      "Epoch 71/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6022 - mse: 0.2082 - val_loss: 0.7260 - val_mse: 0.2602\n",
      "Epoch 72/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.6007 - mse: 0.2076 - val_loss: 0.7122 - val_mse: 0.2540\n",
      "Epoch 73/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5987 - mse: 0.2067 - val_loss: 0.7176 - val_mse: 0.2558\n",
      "Epoch 74/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5974 - mse: 0.2062 - val_loss: 0.7262 - val_mse: 0.2597\n",
      "Epoch 75/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5969 - mse: 0.2060 - val_loss: 0.7339 - val_mse: 0.2625\n",
      "Epoch 76/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5957 - mse: 0.2056 - val_loss: 0.7255 - val_mse: 0.2589\n",
      "Epoch 77/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5940 - mse: 0.2048 - val_loss: 0.7155 - val_mse: 0.2544\n",
      "Epoch 78/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5920 - mse: 0.2040 - val_loss: 0.7116 - val_mse: 0.2523\n",
      "Epoch 79/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5919 - mse: 0.2040 - val_loss: 0.7385 - val_mse: 0.2626\n",
      "Epoch 80/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5900 - mse: 0.2032 - val_loss: 0.7247 - val_mse: 0.2575\n",
      "Epoch 81/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5887 - mse: 0.2026 - val_loss: 0.7380 - val_mse: 0.2610\n",
      "Epoch 82/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5879 - mse: 0.2023 - val_loss: 0.7333 - val_mse: 0.2601\n",
      "Epoch 83/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5853 - mse: 0.2012 - val_loss: 0.7412 - val_mse: 0.2623\n",
      "Epoch 84/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5850 - mse: 0.2012 - val_loss: 0.7627 - val_mse: 0.2705\n",
      "Epoch 85/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5840 - mse: 0.2007 - val_loss: 0.7456 - val_mse: 0.2649\n",
      "Epoch 86/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5818 - mse: 0.1999 - val_loss: 0.7181 - val_mse: 0.2531\n",
      "Epoch 87/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5802 - mse: 0.1992 - val_loss: 0.7471 - val_mse: 0.2643\n",
      "Epoch 88/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5792 - mse: 0.1987 - val_loss: 0.7336 - val_mse: 0.2585\n",
      "Epoch 89/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5789 - mse: 0.1987 - val_loss: 0.7403 - val_mse: 0.2617\n",
      "Epoch 90/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5776 - mse: 0.1983 - val_loss: 0.7473 - val_mse: 0.2652\n",
      "Epoch 91/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5749 - mse: 0.1971 - val_loss: 0.7440 - val_mse: 0.2625\n",
      "Epoch 92/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5735 - mse: 0.1965 - val_loss: 0.7410 - val_mse: 0.2608\n",
      "Epoch 93/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5728 - mse: 0.1963 - val_loss: 0.7504 - val_mse: 0.2633\n",
      "Epoch 94/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5720 - mse: 0.1960 - val_loss: 0.7476 - val_mse: 0.2610\n",
      "Epoch 95/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5729 - mse: 0.1964 - val_loss: 0.7615 - val_mse: 0.2678\n",
      "Epoch 96/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5696 - mse: 0.1951 - val_loss: 0.7605 - val_mse: 0.2667\n",
      "Epoch 97/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5682 - mse: 0.1944 - val_loss: 0.7551 - val_mse: 0.2644\n",
      "Epoch 98/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5664 - mse: 0.1937 - val_loss: 0.7524 - val_mse: 0.2628\n",
      "Epoch 99/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5647 - mse: 0.1930 - val_loss: 0.7878 - val_mse: 0.2755\n",
      "Epoch 100/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5635 - mse: 0.1925 - val_loss: 0.7527 - val_mse: 0.2630\n",
      "Epoch 101/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5630 - mse: 0.1923 - val_loss: 0.7665 - val_mse: 0.2671\n",
      "Epoch 102/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5624 - mse: 0.1922 - val_loss: 0.7638 - val_mse: 0.2695\n",
      "Epoch 103/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5610 - mse: 0.1916 - val_loss: 0.7729 - val_mse: 0.2706\n",
      "Epoch 104/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5595 - mse: 0.1910 - val_loss: 0.7475 - val_mse: 0.2614\n",
      "Epoch 105/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5609 - mse: 0.1917 - val_loss: 0.7729 - val_mse: 0.2692\n",
      "Epoch 106/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5575 - mse: 0.1902 - val_loss: 0.7678 - val_mse: 0.2673\n",
      "Epoch 107/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5574 - mse: 0.1901 - val_loss: 0.7668 - val_mse: 0.2681\n",
      "Epoch 108/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5545 - mse: 0.1889 - val_loss: 0.7975 - val_mse: 0.2748\n",
      "Epoch 109/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5545 - mse: 0.1891 - val_loss: 0.7737 - val_mse: 0.2692\n",
      "Epoch 110/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5512 - mse: 0.1876 - val_loss: 0.7689 - val_mse: 0.2687\n",
      "Epoch 111/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5527 - mse: 0.1884 - val_loss: 0.7649 - val_mse: 0.2640\n",
      "Epoch 112/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5512 - mse: 0.1877 - val_loss: 0.7679 - val_mse: 0.2661\n",
      "Epoch 113/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5486 - mse: 0.1867 - val_loss: 0.7532 - val_mse: 0.2606\n",
      "Epoch 114/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5493 - mse: 0.1869 - val_loss: 0.7873 - val_mse: 0.2708\n",
      "Epoch 115/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5474 - mse: 0.1861 - val_loss: 0.7884 - val_mse: 0.2726\n",
      "Epoch 116/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5463 - mse: 0.1857 - val_loss: 0.7782 - val_mse: 0.2680\n",
      "Epoch 117/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5452 - mse: 0.1853 - val_loss: 0.7769 - val_mse: 0.2678\n",
      "Epoch 118/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5433 - mse: 0.1844 - val_loss: 0.7882 - val_mse: 0.2704\n",
      "Epoch 119/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5420 - mse: 0.1840 - val_loss: 0.7906 - val_mse: 0.2725\n",
      "Epoch 120/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5410 - mse: 0.1836 - val_loss: 0.8071 - val_mse: 0.2764\n",
      "Epoch 121/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5396 - mse: 0.1830 - val_loss: 0.8030 - val_mse: 0.2772\n",
      "Epoch 122/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5399 - mse: 0.1833 - val_loss: 0.7875 - val_mse: 0.2704\n",
      "Epoch 123/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5388 - mse: 0.1829 - val_loss: 0.7865 - val_mse: 0.2689\n",
      "Epoch 124/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5377 - mse: 0.1826 - val_loss: 0.7852 - val_mse: 0.2704\n",
      "Epoch 125/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5381 - mse: 0.1827 - val_loss: 0.7995 - val_mse: 0.2753\n",
      "Epoch 126/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5350 - mse: 0.1813 - val_loss: 0.7950 - val_mse: 0.2741\n",
      "Epoch 127/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5337 - mse: 0.1808 - val_loss: 0.7635 - val_mse: 0.2607\n",
      "Epoch 128/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5330 - mse: 0.1805 - val_loss: 0.7908 - val_mse: 0.2741\n",
      "Epoch 129/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5332 - mse: 0.1806 - val_loss: 0.7798 - val_mse: 0.2679\n",
      "Epoch 130/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5317 - mse: 0.1798 - val_loss: 0.8131 - val_mse: 0.2800\n",
      "Epoch 131/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5336 - mse: 0.1807 - val_loss: 0.7947 - val_mse: 0.2729\n",
      "Epoch 132/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5268 - mse: 0.1779 - val_loss: 0.7919 - val_mse: 0.2710\n",
      "Epoch 133/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5275 - mse: 0.1784 - val_loss: 0.8014 - val_mse: 0.2739\n",
      "Epoch 134/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5285 - mse: 0.1789 - val_loss: 0.8014 - val_mse: 0.2752\n",
      "Epoch 135/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5254 - mse: 0.1776 - val_loss: 0.8035 - val_mse: 0.2726\n",
      "Epoch 136/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5272 - mse: 0.1784 - val_loss: 0.8101 - val_mse: 0.2764\n",
      "Epoch 137/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5253 - mse: 0.1774 - val_loss: 0.8033 - val_mse: 0.2735\n",
      "Epoch 138/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5222 - mse: 0.1759 - val_loss: 0.8208 - val_mse: 0.2791\n",
      "Epoch 139/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5216 - mse: 0.1758 - val_loss: 0.8253 - val_mse: 0.2783\n",
      "Epoch 140/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5229 - mse: 0.1767 - val_loss: 0.8069 - val_mse: 0.2745\n",
      "Epoch 141/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5184 - mse: 0.1747 - val_loss: 0.8170 - val_mse: 0.2776\n",
      "Epoch 142/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5181 - mse: 0.1745 - val_loss: 0.8231 - val_mse: 0.2822\n",
      "Epoch 143/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5163 - mse: 0.1739 - val_loss: 0.8118 - val_mse: 0.2753\n",
      "Epoch 144/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5172 - mse: 0.1744 - val_loss: 0.8249 - val_mse: 0.2808\n",
      "Epoch 145/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5155 - mse: 0.1736 - val_loss: 0.8393 - val_mse: 0.2810\n",
      "Epoch 146/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5158 - mse: 0.1736 - val_loss: 0.8153 - val_mse: 0.2747\n",
      "Epoch 147/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5125 - mse: 0.1725 - val_loss: 0.8558 - val_mse: 0.2861\n",
      "Epoch 148/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5138 - mse: 0.1732 - val_loss: 0.8345 - val_mse: 0.2796\n",
      "Epoch 149/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5127 - mse: 0.1726 - val_loss: 0.8293 - val_mse: 0.2801\n",
      "Epoch 150/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5090 - mse: 0.1711 - val_loss: 0.8361 - val_mse: 0.2831\n",
      "Epoch 151/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5088 - mse: 0.1710 - val_loss: 0.8486 - val_mse: 0.2860\n",
      "Epoch 152/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5076 - mse: 0.1706 - val_loss: 0.8575 - val_mse: 0.2885\n",
      "Epoch 153/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5079 - mse: 0.1708 - val_loss: 0.7949 - val_mse: 0.2678\n",
      "Epoch 154/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5060 - mse: 0.1699 - val_loss: 0.8405 - val_mse: 0.2828\n",
      "Epoch 155/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5046 - mse: 0.1693 - val_loss: 0.8318 - val_mse: 0.2790\n",
      "Epoch 156/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.5045 - mse: 0.1696 - val_loss: 0.8412 - val_mse: 0.2857\n",
      "Epoch 157/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5094 - mse: 0.1717 - val_loss: 0.8507 - val_mse: 0.2884\n",
      "Epoch 158/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5021 - mse: 0.1685 - val_loss: 0.8381 - val_mse: 0.2807\n",
      "Epoch 159/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5011 - mse: 0.1682 - val_loss: 0.8542 - val_mse: 0.2845\n",
      "Epoch 160/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5025 - mse: 0.1689 - val_loss: 0.8736 - val_mse: 0.2902\n",
      "Epoch 161/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.5007 - mse: 0.1679 - val_loss: 0.8606 - val_mse: 0.2874\n",
      "Epoch 162/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4992 - mse: 0.1677 - val_loss: 0.8324 - val_mse: 0.2782\n",
      "Epoch 163/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4974 - mse: 0.1668 - val_loss: 0.8720 - val_mse: 0.2931\n",
      "Epoch 164/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4980 - mse: 0.1667 - val_loss: 0.8549 - val_mse: 0.2867\n",
      "Epoch 165/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4962 - mse: 0.1662 - val_loss: 0.8690 - val_mse: 0.2892\n",
      "Epoch 166/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4970 - mse: 0.1667 - val_loss: 0.8309 - val_mse: 0.2767\n",
      "Epoch 167/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4950 - mse: 0.1657 - val_loss: 0.8924 - val_mse: 0.2960\n",
      "Epoch 168/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4941 - mse: 0.1655 - val_loss: 0.8696 - val_mse: 0.2911\n",
      "Epoch 169/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4938 - mse: 0.1656 - val_loss: 0.8817 - val_mse: 0.2947\n",
      "Epoch 170/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4911 - mse: 0.1644 - val_loss: 0.8652 - val_mse: 0.2934\n",
      "Epoch 171/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4940 - mse: 0.1655 - val_loss: 0.8587 - val_mse: 0.2857\n",
      "Epoch 172/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4916 - mse: 0.1646 - val_loss: 0.8640 - val_mse: 0.2912\n",
      "Epoch 173/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4906 - mse: 0.1641 - val_loss: 0.8773 - val_mse: 0.2889\n",
      "Epoch 174/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4907 - mse: 0.1639 - val_loss: 0.8294 - val_mse: 0.2769\n",
      "Epoch 175/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4887 - mse: 0.1635 - val_loss: 0.8541 - val_mse: 0.2840\n",
      "Epoch 176/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4890 - mse: 0.1635 - val_loss: 0.9310 - val_mse: 0.3038\n",
      "Epoch 177/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4861 - mse: 0.1621 - val_loss: 0.8603 - val_mse: 0.2820\n",
      "Epoch 178/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4851 - mse: 0.1621 - val_loss: 0.8856 - val_mse: 0.2951\n",
      "Epoch 179/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4863 - mse: 0.1624 - val_loss: 0.9075 - val_mse: 0.3001\n",
      "Epoch 180/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4832 - mse: 0.1612 - val_loss: 0.8911 - val_mse: 0.2929\n",
      "Epoch 181/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4830 - mse: 0.1614 - val_loss: 0.9108 - val_mse: 0.3012\n",
      "Epoch 182/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4842 - mse: 0.1619 - val_loss: 0.8809 - val_mse: 0.2899\n",
      "Epoch 183/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4797 - mse: 0.1597 - val_loss: 0.9048 - val_mse: 0.2962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4812 - mse: 0.1606 - val_loss: 0.8928 - val_mse: 0.2944\n",
      "Epoch 185/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4807 - mse: 0.1607 - val_loss: 0.9233 - val_mse: 0.3061\n",
      "Epoch 186/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4807 - mse: 0.1607 - val_loss: 0.8739 - val_mse: 0.2876\n",
      "Epoch 187/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4800 - mse: 0.1601 - val_loss: 0.9059 - val_mse: 0.2932\n",
      "Epoch 188/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4752 - mse: 0.1585 - val_loss: 0.8874 - val_mse: 0.2913\n",
      "Epoch 189/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4749 - mse: 0.1584 - val_loss: 0.9059 - val_mse: 0.2929\n",
      "Epoch 190/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4763 - mse: 0.1588 - val_loss: 0.9175 - val_mse: 0.2979\n",
      "Epoch 191/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4748 - mse: 0.1583 - val_loss: 0.9127 - val_mse: 0.2960\n",
      "Epoch 192/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4752 - mse: 0.1583 - val_loss: 0.9318 - val_mse: 0.3050\n",
      "Epoch 193/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4745 - mse: 0.1581 - val_loss: 0.8904 - val_mse: 0.2918\n",
      "Epoch 194/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4733 - mse: 0.1577 - val_loss: 0.8949 - val_mse: 0.2921\n",
      "Epoch 195/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4712 - mse: 0.1568 - val_loss: 0.9179 - val_mse: 0.2954\n",
      "Epoch 196/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4760 - mse: 0.1591 - val_loss: 0.9663 - val_mse: 0.3065\n",
      "Epoch 197/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4711 - mse: 0.1568 - val_loss: 0.9161 - val_mse: 0.2976\n",
      "Epoch 198/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4695 - mse: 0.1563 - val_loss: 0.9400 - val_mse: 0.3054\n",
      "Epoch 199/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4677 - mse: 0.1558 - val_loss: 0.8806 - val_mse: 0.2849\n",
      "Epoch 200/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4686 - mse: 0.1558 - val_loss: 0.9120 - val_mse: 0.2963\n",
      "Epoch 201/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4708 - mse: 0.1569 - val_loss: 0.9315 - val_mse: 0.3030\n",
      "Epoch 202/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4678 - mse: 0.1557 - val_loss: 0.9570 - val_mse: 0.3094\n",
      "Epoch 203/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4657 - mse: 0.1549 - val_loss: 0.9008 - val_mse: 0.2907\n",
      "Epoch 204/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4677 - mse: 0.1556 - val_loss: 0.9355 - val_mse: 0.3047\n",
      "Epoch 205/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4671 - mse: 0.1557 - val_loss: 0.9297 - val_mse: 0.3016\n",
      "Epoch 206/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4629 - mse: 0.1539 - val_loss: 0.9179 - val_mse: 0.2975\n",
      "Epoch 207/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4648 - mse: 0.1547 - val_loss: 0.9157 - val_mse: 0.2946\n",
      "Epoch 208/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4635 - mse: 0.1540 - val_loss: 0.9317 - val_mse: 0.2966\n",
      "Epoch 209/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4598 - mse: 0.1525 - val_loss: 0.9857 - val_mse: 0.3144\n",
      "Epoch 210/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4610 - mse: 0.1530 - val_loss: 0.9903 - val_mse: 0.3154\n",
      "Epoch 211/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4637 - mse: 0.1547 - val_loss: 0.9347 - val_mse: 0.3005\n",
      "Epoch 212/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4595 - mse: 0.1524 - val_loss: 0.9892 - val_mse: 0.3155\n",
      "Epoch 213/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - mse: 0.1517 - val_loss: 0.9728 - val_mse: 0.3072\n",
      "Epoch 214/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - mse: 0.1527 - val_loss: 0.9451 - val_mse: 0.3027\n",
      "Epoch 215/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4588 - mse: 0.1521 - val_loss: 0.9707 - val_mse: 0.3059\n",
      "Epoch 216/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4563 - mse: 0.1513 - val_loss: 1.0106 - val_mse: 0.3219\n",
      "Epoch 217/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - mse: 0.1527 - val_loss: 0.9760 - val_mse: 0.3069\n",
      "Epoch 218/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4571 - mse: 0.1518 - val_loss: 0.9780 - val_mse: 0.3107\n",
      "Epoch 219/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4557 - mse: 0.1514 - val_loss: 0.9987 - val_mse: 0.3190\n",
      "Epoch 220/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4574 - mse: 0.1519 - val_loss: 0.9171 - val_mse: 0.2930\n",
      "Epoch 221/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4563 - mse: 0.1514 - val_loss: 0.9442 - val_mse: 0.2979\n",
      "Epoch 222/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4495 - mse: 0.1486 - val_loss: 0.9775 - val_mse: 0.3132\n",
      "Epoch 223/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4514 - mse: 0.1496 - val_loss: 0.9444 - val_mse: 0.3022\n",
      "Epoch 224/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4551 - mse: 0.1508 - val_loss: 0.9753 - val_mse: 0.3046\n",
      "Epoch 225/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4524 - mse: 0.1502 - val_loss: 1.0343 - val_mse: 0.3201\n",
      "Epoch 226/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4542 - mse: 0.1507 - val_loss: 0.9479 - val_mse: 0.2985\n",
      "Epoch 227/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4548 - mse: 0.1513 - val_loss: 0.9748 - val_mse: 0.3078\n",
      "Epoch 228/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4524 - mse: 0.1500 - val_loss: 1.0050 - val_mse: 0.3150\n",
      "Epoch 229/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4508 - mse: 0.1491 - val_loss: 0.9885 - val_mse: 0.3132\n",
      "Epoch 230/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4460 - mse: 0.1477 - val_loss: 0.9865 - val_mse: 0.3095\n",
      "Epoch 231/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4450 - mse: 0.1473 - val_loss: 0.9693 - val_mse: 0.3035\n",
      "Epoch 232/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4476 - mse: 0.1483 - val_loss: 0.9894 - val_mse: 0.3090\n",
      "Epoch 233/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4447 - mse: 0.1471 - val_loss: 0.9799 - val_mse: 0.3052\n",
      "Epoch 234/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4504 - mse: 0.1496 - val_loss: 0.9795 - val_mse: 0.3042\n",
      "Epoch 235/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4439 - mse: 0.1467 - val_loss: 1.0286 - val_mse: 0.3186\n",
      "Epoch 236/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4434 - mse: 0.1471 - val_loss: 1.0374 - val_mse: 0.3230\n",
      "Epoch 237/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4421 - mse: 0.1459 - val_loss: 1.0588 - val_mse: 0.3310\n",
      "Epoch 238/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4413 - mse: 0.1459 - val_loss: 1.0098 - val_mse: 0.3148\n",
      "Epoch 239/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4392 - mse: 0.1450 - val_loss: 0.9920 - val_mse: 0.3123\n",
      "Epoch 240/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4401 - mse: 0.1455 - val_loss: 1.0250 - val_mse: 0.3238\n",
      "Epoch 241/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4385 - mse: 0.1447 - val_loss: 0.9891 - val_mse: 0.3097\n",
      "Epoch 242/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4400 - mse: 0.1457 - val_loss: 0.9887 - val_mse: 0.3084\n",
      "Epoch 243/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4434 - mse: 0.1468 - val_loss: 1.0337 - val_mse: 0.3228\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4405 - mse: 0.1458 - val_loss: 1.0189 - val_mse: 0.3138\n",
      "Epoch 245/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4379 - mse: 0.1451 - val_loss: 1.0035 - val_mse: 0.3107\n",
      "Epoch 246/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4383 - mse: 0.1451 - val_loss: 0.9866 - val_mse: 0.3088\n",
      "Epoch 247/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4380 - mse: 0.1450 - val_loss: 1.0127 - val_mse: 0.3106\n",
      "Epoch 248/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4374 - mse: 0.1445 - val_loss: 1.0207 - val_mse: 0.3157\n",
      "Epoch 249/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4323 - mse: 0.1425 - val_loss: 0.9931 - val_mse: 0.3043\n",
      "Epoch 250/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4319 - mse: 0.1423 - val_loss: 0.9620 - val_mse: 0.2962\n",
      "Epoch 251/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4323 - mse: 0.1424 - val_loss: 1.0128 - val_mse: 0.3123\n",
      "Epoch 252/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4367 - mse: 0.1448 - val_loss: 1.0532 - val_mse: 0.3172\n",
      "Epoch 253/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4357 - mse: 0.1441 - val_loss: 1.0326 - val_mse: 0.3198\n",
      "Epoch 254/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4320 - mse: 0.1428 - val_loss: 0.9885 - val_mse: 0.3036\n",
      "Epoch 255/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4284 - mse: 0.1408 - val_loss: 1.0020 - val_mse: 0.3115\n",
      "Epoch 256/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4312 - mse: 0.1425 - val_loss: 1.0068 - val_mse: 0.3072\n",
      "Epoch 257/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4300 - mse: 0.1416 - val_loss: 1.0292 - val_mse: 0.3206\n",
      "Epoch 258/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4284 - mse: 0.1410 - val_loss: 1.0702 - val_mse: 0.3303\n",
      "Epoch 259/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4306 - mse: 0.1420 - val_loss: 1.0280 - val_mse: 0.3144\n",
      "Epoch 260/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4299 - mse: 0.1421 - val_loss: 1.0452 - val_mse: 0.3205\n",
      "Epoch 261/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4270 - mse: 0.1407 - val_loss: 1.0270 - val_mse: 0.3160\n",
      "Epoch 262/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4262 - mse: 0.1406 - val_loss: 1.0625 - val_mse: 0.3299\n",
      "Epoch 263/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4254 - mse: 0.1403 - val_loss: 1.0056 - val_mse: 0.3050\n",
      "Epoch 264/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4252 - mse: 0.1405 - val_loss: 1.0131 - val_mse: 0.3057\n",
      "Epoch 265/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4266 - mse: 0.1407 - val_loss: 1.1040 - val_mse: 0.3288\n",
      "Epoch 266/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4294 - mse: 0.1419 - val_loss: 1.0819 - val_mse: 0.3284\n",
      "Epoch 267/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4199 - mse: 0.1381 - val_loss: 1.1307 - val_mse: 0.3318\n",
      "Epoch 268/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4249 - mse: 0.1403 - val_loss: 1.0412 - val_mse: 0.3174\n",
      "Epoch 269/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4291 - mse: 0.1421 - val_loss: 1.0529 - val_mse: 0.3140\n",
      "Epoch 270/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4229 - mse: 0.1393 - val_loss: 1.0910 - val_mse: 0.3236\n",
      "Epoch 271/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4195 - mse: 0.1376 - val_loss: 1.0225 - val_mse: 0.3081\n",
      "Epoch 272/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4206 - mse: 0.1385 - val_loss: 1.0844 - val_mse: 0.3300\n",
      "Epoch 273/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4198 - mse: 0.1381 - val_loss: 1.0360 - val_mse: 0.3140\n",
      "Epoch 274/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4186 - mse: 0.1376 - val_loss: 1.1211 - val_mse: 0.3379\n",
      "Epoch 275/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4199 - mse: 0.1386 - val_loss: 1.0809 - val_mse: 0.3246\n",
      "Epoch 276/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4214 - mse: 0.1387 - val_loss: 1.0669 - val_mse: 0.3237\n",
      "Epoch 277/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4162 - mse: 0.1369 - val_loss: 1.1013 - val_mse: 0.3263\n",
      "Epoch 278/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4173 - mse: 0.1372 - val_loss: 1.0840 - val_mse: 0.3331\n",
      "Epoch 279/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4162 - mse: 0.1367 - val_loss: 1.0383 - val_mse: 0.3096\n",
      "Epoch 280/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4143 - mse: 0.1362 - val_loss: 1.0625 - val_mse: 0.3199\n",
      "Epoch 281/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4150 - mse: 0.1364 - val_loss: 1.0749 - val_mse: 0.3130\n",
      "Epoch 282/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4196 - mse: 0.1385 - val_loss: 1.0740 - val_mse: 0.3227\n",
      "Epoch 283/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4119 - mse: 0.1351 - val_loss: 1.0934 - val_mse: 0.3296\n",
      "Epoch 284/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4157 - mse: 0.1372 - val_loss: 1.0486 - val_mse: 0.3118\n",
      "Epoch 285/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4137 - mse: 0.1365 - val_loss: 1.0640 - val_mse: 0.3174\n",
      "Epoch 286/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4118 - mse: 0.1352 - val_loss: 1.0985 - val_mse: 0.3223\n",
      "Epoch 287/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4134 - mse: 0.1362 - val_loss: 1.0568 - val_mse: 0.3134\n",
      "Epoch 288/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4148 - mse: 0.1368 - val_loss: 1.0991 - val_mse: 0.3225\n",
      "Epoch 289/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4100 - mse: 0.1347 - val_loss: 1.1095 - val_mse: 0.3286\n",
      "Epoch 290/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4120 - mse: 0.1356 - val_loss: 1.0093 - val_mse: 0.2982\n",
      "Epoch 291/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4081 - mse: 0.1342 - val_loss: 1.0798 - val_mse: 0.3190\n",
      "Epoch 292/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4109 - mse: 0.1354 - val_loss: 1.0942 - val_mse: 0.3187\n",
      "Epoch 293/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4090 - mse: 0.1344 - val_loss: 1.0593 - val_mse: 0.3170\n",
      "Epoch 294/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4063 - mse: 0.1335 - val_loss: 1.0835 - val_mse: 0.3178\n",
      "Epoch 295/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4085 - mse: 0.1345 - val_loss: 1.0456 - val_mse: 0.3132\n",
      "Epoch 296/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4077 - mse: 0.1341 - val_loss: 1.2017 - val_mse: 0.3451\n",
      "Epoch 297/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4102 - mse: 0.1347 - val_loss: 1.0923 - val_mse: 0.3178\n",
      "Epoch 298/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4139 - mse: 0.1367 - val_loss: 1.1300 - val_mse: 0.3344\n",
      "Epoch 299/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4051 - mse: 0.1332 - val_loss: 1.0705 - val_mse: 0.3179\n",
      "Epoch 300/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4024 - mse: 0.1318 - val_loss: 1.1576 - val_mse: 0.3376\n",
      "Epoch 301/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4078 - mse: 0.1341 - val_loss: 1.1004 - val_mse: 0.3246\n",
      "Epoch 302/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4090 - mse: 0.1347 - val_loss: 1.1224 - val_mse: 0.3289\n",
      "Epoch 303/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4077 - mse: 0.1340 - val_loss: 1.0930 - val_mse: 0.3184\n",
      "Epoch 304/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4037 - mse: 0.1325 - val_loss: 1.1127 - val_mse: 0.3300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3990 - mse: 0.1306 - val_loss: 1.1196 - val_mse: 0.3291\n",
      "Epoch 306/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.4017 - mse: 0.1320 - val_loss: 1.1460 - val_mse: 0.3355\n",
      "Epoch 307/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4002 - mse: 0.1310 - val_loss: 1.0749 - val_mse: 0.3159\n",
      "Epoch 308/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4022 - mse: 0.1321 - val_loss: 1.0724 - val_mse: 0.3081\n",
      "Epoch 309/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4003 - mse: 0.1316 - val_loss: 1.1523 - val_mse: 0.3339\n",
      "Epoch 310/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4019 - mse: 0.1316 - val_loss: 1.1010 - val_mse: 0.3179\n",
      "Epoch 311/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4038 - mse: 0.1326 - val_loss: 1.1364 - val_mse: 0.3304\n",
      "Epoch 312/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3975 - mse: 0.1307 - val_loss: 1.1708 - val_mse: 0.3328\n",
      "Epoch 313/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4010 - mse: 0.1315 - val_loss: 1.0975 - val_mse: 0.3244\n",
      "Epoch 314/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.4017 - mse: 0.1319 - val_loss: 1.1848 - val_mse: 0.3407\n",
      "Epoch 315/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3984 - mse: 0.1307 - val_loss: 1.0955 - val_mse: 0.3150\n",
      "Epoch 316/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3987 - mse: 0.1302 - val_loss: 1.1056 - val_mse: 0.3154\n",
      "Epoch 317/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3956 - mse: 0.1299 - val_loss: 1.1594 - val_mse: 0.3314\n",
      "Epoch 318/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3997 - mse: 0.1310 - val_loss: 1.2315 - val_mse: 0.3460\n",
      "Epoch 319/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3939 - mse: 0.1291 - val_loss: 1.1501 - val_mse: 0.3249\n",
      "Epoch 320/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3950 - mse: 0.1296 - val_loss: 1.1387 - val_mse: 0.3293\n",
      "Epoch 321/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3945 - mse: 0.1290 - val_loss: 1.1958 - val_mse: 0.3354\n",
      "Epoch 322/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3946 - mse: 0.1293 - val_loss: 1.1320 - val_mse: 0.3191\n",
      "Epoch 323/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3951 - mse: 0.1292 - val_loss: 1.1486 - val_mse: 0.3223\n",
      "Epoch 324/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3937 - mse: 0.1291 - val_loss: 1.1729 - val_mse: 0.3326\n",
      "Epoch 325/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3946 - mse: 0.1289 - val_loss: 1.1776 - val_mse: 0.3360\n",
      "Epoch 326/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3929 - mse: 0.1287 - val_loss: 1.1599 - val_mse: 0.3301\n",
      "Epoch 327/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3915 - mse: 0.1280 - val_loss: 1.0952 - val_mse: 0.3168\n",
      "Epoch 328/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3900 - mse: 0.1280 - val_loss: 1.1724 - val_mse: 0.3387\n",
      "Epoch 329/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3951 - mse: 0.1296 - val_loss: 1.1727 - val_mse: 0.3321\n",
      "Epoch 330/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3931 - mse: 0.1290 - val_loss: 1.1956 - val_mse: 0.3406\n",
      "Epoch 331/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3895 - mse: 0.1276 - val_loss: 1.1631 - val_mse: 0.3351\n",
      "Epoch 332/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3925 - mse: 0.1285 - val_loss: 1.1188 - val_mse: 0.3162\n",
      "Epoch 333/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3889 - mse: 0.1271 - val_loss: 1.1610 - val_mse: 0.3341\n",
      "Epoch 334/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3895 - mse: 0.1277 - val_loss: 1.1664 - val_mse: 0.3319\n",
      "Epoch 335/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3906 - mse: 0.1280 - val_loss: 1.2355 - val_mse: 0.3458\n",
      "Epoch 336/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3939 - mse: 0.1291 - val_loss: 1.1785 - val_mse: 0.3299\n",
      "Epoch 337/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3870 - mse: 0.1267 - val_loss: 1.2044 - val_mse: 0.3458\n",
      "Epoch 338/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3900 - mse: 0.1282 - val_loss: 1.1661 - val_mse: 0.3268\n",
      "Epoch 339/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3842 - mse: 0.1254 - val_loss: 1.2304 - val_mse: 0.3444\n",
      "Epoch 340/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3842 - mse: 0.1254 - val_loss: 1.1989 - val_mse: 0.3320\n",
      "Epoch 341/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3840 - mse: 0.1256 - val_loss: 1.2340 - val_mse: 0.3467\n",
      "Epoch 342/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3860 - mse: 0.1263 - val_loss: 1.1775 - val_mse: 0.3330\n",
      "Epoch 343/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3914 - mse: 0.1283 - val_loss: 1.2291 - val_mse: 0.3493\n",
      "Epoch 344/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3835 - mse: 0.1257 - val_loss: 1.1788 - val_mse: 0.3270\n",
      "Epoch 345/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3861 - mse: 0.1264 - val_loss: 1.2028 - val_mse: 0.3401\n",
      "Epoch 346/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3891 - mse: 0.1274 - val_loss: 1.1513 - val_mse: 0.3293\n",
      "Epoch 347/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3815 - mse: 0.1244 - val_loss: 1.2249 - val_mse: 0.3406\n",
      "Epoch 348/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3866 - mse: 0.1268 - val_loss: 1.2202 - val_mse: 0.3398\n",
      "Epoch 349/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3837 - mse: 0.1255 - val_loss: 1.2036 - val_mse: 0.3419\n",
      "Epoch 350/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3811 - mse: 0.1245 - val_loss: 1.2016 - val_mse: 0.3370\n",
      "Epoch 351/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3804 - mse: 0.1249 - val_loss: 1.1513 - val_mse: 0.3222\n",
      "Epoch 352/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3797 - mse: 0.1242 - val_loss: 1.2723 - val_mse: 0.3451\n",
      "Epoch 353/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3812 - mse: 0.1244 - val_loss: 1.2104 - val_mse: 0.3337\n",
      "Epoch 354/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3812 - mse: 0.1248 - val_loss: 1.2498 - val_mse: 0.3389\n",
      "Epoch 355/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3778 - mse: 0.1237 - val_loss: 1.1924 - val_mse: 0.3343\n",
      "Epoch 356/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3781 - mse: 0.1235 - val_loss: 1.2238 - val_mse: 0.3375\n",
      "Epoch 357/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3811 - mse: 0.1250 - val_loss: 1.1911 - val_mse: 0.3325\n",
      "Epoch 358/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3797 - mse: 0.1240 - val_loss: 1.2044 - val_mse: 0.3368\n",
      "Epoch 359/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3768 - mse: 0.1233 - val_loss: 1.2292 - val_mse: 0.3336\n",
      "Epoch 360/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3763 - mse: 0.1232 - val_loss: 1.2312 - val_mse: 0.3332\n",
      "Epoch 361/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3791 - mse: 0.1240 - val_loss: 1.2500 - val_mse: 0.3386\n",
      "Epoch 362/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3815 - mse: 0.1247 - val_loss: 1.2228 - val_mse: 0.3340\n",
      "Epoch 363/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3756 - mse: 0.1227 - val_loss: 1.2514 - val_mse: 0.3389\n",
      "Epoch 364/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3792 - mse: 0.1242 - val_loss: 1.2819 - val_mse: 0.3520\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3741 - mse: 0.1220 - val_loss: 1.2767 - val_mse: 0.3415\n",
      "Epoch 366/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3771 - mse: 0.1233 - val_loss: 1.2914 - val_mse: 0.3578\n",
      "Epoch 367/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3738 - mse: 0.1221 - val_loss: 1.2350 - val_mse: 0.3415\n",
      "Epoch 368/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3772 - mse: 0.1231 - val_loss: 1.2820 - val_mse: 0.3522\n",
      "Epoch 369/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3728 - mse: 0.1219 - val_loss: 1.2309 - val_mse: 0.3345\n",
      "Epoch 370/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3722 - mse: 0.1218 - val_loss: 1.2727 - val_mse: 0.3485\n",
      "Epoch 371/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3698 - mse: 0.1209 - val_loss: 1.1786 - val_mse: 0.3211\n",
      "Epoch 372/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3711 - mse: 0.1212 - val_loss: 1.2915 - val_mse: 0.3503\n",
      "Epoch 373/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3711 - mse: 0.1210 - val_loss: 1.2170 - val_mse: 0.3290\n",
      "Epoch 374/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3684 - mse: 0.1199 - val_loss: 1.2407 - val_mse: 0.3366\n",
      "Epoch 375/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3742 - mse: 0.1221 - val_loss: 1.2302 - val_mse: 0.3382\n",
      "Epoch 376/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3671 - mse: 0.1198 - val_loss: 1.2265 - val_mse: 0.3343\n",
      "Epoch 377/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3683 - mse: 0.1202 - val_loss: 1.2540 - val_mse: 0.3397\n",
      "Epoch 378/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3694 - mse: 0.1203 - val_loss: 1.3043 - val_mse: 0.3541\n",
      "Epoch 379/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3725 - mse: 0.1219 - val_loss: 1.2383 - val_mse: 0.3305\n",
      "Epoch 380/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3681 - mse: 0.1202 - val_loss: 1.2682 - val_mse: 0.3400\n",
      "Epoch 381/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3673 - mse: 0.1196 - val_loss: 1.2049 - val_mse: 0.3258\n",
      "Epoch 382/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3656 - mse: 0.1192 - val_loss: 1.3459 - val_mse: 0.3541\n",
      "Epoch 383/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3733 - mse: 0.1226 - val_loss: 1.2408 - val_mse: 0.3338\n",
      "Epoch 384/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3713 - mse: 0.1216 - val_loss: 1.1802 - val_mse: 0.3223\n",
      "Epoch 385/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3667 - mse: 0.1194 - val_loss: 1.2785 - val_mse: 0.3505\n",
      "Epoch 386/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3627 - mse: 0.1181 - val_loss: 1.2239 - val_mse: 0.3291\n",
      "Epoch 387/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3664 - mse: 0.1199 - val_loss: 1.2502 - val_mse: 0.3371\n",
      "Epoch 388/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3700 - mse: 0.1211 - val_loss: 1.2797 - val_mse: 0.3410\n",
      "Epoch 389/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3611 - mse: 0.1174 - val_loss: 1.2861 - val_mse: 0.3471\n",
      "Epoch 390/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3673 - mse: 0.1198 - val_loss: 1.3065 - val_mse: 0.3454\n",
      "Epoch 391/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3660 - mse: 0.1195 - val_loss: 1.3211 - val_mse: 0.3504\n",
      "Epoch 392/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3652 - mse: 0.1194 - val_loss: 1.3220 - val_mse: 0.3507\n",
      "Epoch 393/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3639 - mse: 0.1191 - val_loss: 1.3365 - val_mse: 0.3412\n",
      "Epoch 394/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3619 - mse: 0.1176 - val_loss: 1.3847 - val_mse: 0.3539\n",
      "Epoch 395/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3600 - mse: 0.1171 - val_loss: 1.3140 - val_mse: 0.3495\n",
      "Epoch 396/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3603 - mse: 0.1175 - val_loss: 1.3324 - val_mse: 0.3566\n",
      "Epoch 397/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3621 - mse: 0.1185 - val_loss: 1.3281 - val_mse: 0.3487\n",
      "Epoch 398/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3621 - mse: 0.1183 - val_loss: 1.3306 - val_mse: 0.3523\n",
      "Epoch 399/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3592 - mse: 0.1171 - val_loss: 1.3187 - val_mse: 0.3526\n",
      "Epoch 400/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3651 - mse: 0.1194 - val_loss: 1.2757 - val_mse: 0.3412\n",
      "Epoch 401/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3628 - mse: 0.1184 - val_loss: 1.3874 - val_mse: 0.3726\n",
      "Epoch 402/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3577 - mse: 0.1167 - val_loss: 1.3763 - val_mse: 0.3693\n",
      "Epoch 403/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3598 - mse: 0.1172 - val_loss: 1.3741 - val_mse: 0.3485\n",
      "Epoch 404/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3599 - mse: 0.1175 - val_loss: 1.3199 - val_mse: 0.3471\n",
      "Epoch 405/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3546 - mse: 0.1155 - val_loss: 1.3508 - val_mse: 0.3624\n",
      "Epoch 406/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3604 - mse: 0.1177 - val_loss: 1.2473 - val_mse: 0.3317\n",
      "Epoch 407/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3572 - mse: 0.1164 - val_loss: 1.2660 - val_mse: 0.3344\n",
      "Epoch 408/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3631 - mse: 0.1185 - val_loss: 1.3219 - val_mse: 0.3455\n",
      "Epoch 409/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3553 - mse: 0.1153 - val_loss: 1.3854 - val_mse: 0.3586\n",
      "Epoch 410/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3585 - mse: 0.1167 - val_loss: 1.3464 - val_mse: 0.3572\n",
      "Epoch 411/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3600 - mse: 0.1178 - val_loss: 1.3741 - val_mse: 0.3426\n",
      "Epoch 412/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3602 - mse: 0.1179 - val_loss: 1.4164 - val_mse: 0.3655\n",
      "Epoch 413/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3601 - mse: 0.1178 - val_loss: 1.3856 - val_mse: 0.3651\n",
      "Epoch 414/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3659 - mse: 0.1201 - val_loss: 1.3434 - val_mse: 0.3515\n",
      "Epoch 415/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3531 - mse: 0.1153 - val_loss: 1.3891 - val_mse: 0.3555\n",
      "Epoch 416/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3546 - mse: 0.1154 - val_loss: 1.3189 - val_mse: 0.3475\n",
      "Epoch 417/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3564 - mse: 0.1163 - val_loss: 1.2713 - val_mse: 0.3307\n",
      "Epoch 418/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3503 - mse: 0.1141 - val_loss: 1.3923 - val_mse: 0.3583\n",
      "Epoch 419/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3544 - mse: 0.1149 - val_loss: 1.3599 - val_mse: 0.3545\n",
      "Epoch 420/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3508 - mse: 0.1133 - val_loss: 1.4020 - val_mse: 0.3582\n",
      "Epoch 421/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3519 - mse: 0.1143 - val_loss: 1.3233 - val_mse: 0.3451\n",
      "Epoch 422/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3524 - mse: 0.1147 - val_loss: 1.3942 - val_mse: 0.3499\n",
      "Epoch 423/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3632 - mse: 0.1197 - val_loss: 1.3483 - val_mse: 0.3461\n",
      "Epoch 424/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3540 - mse: 0.1156 - val_loss: 1.3690 - val_mse: 0.3463\n",
      "Epoch 425/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3512 - mse: 0.1144 - val_loss: 1.4010 - val_mse: 0.3615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3505 - mse: 0.1141 - val_loss: 1.3363 - val_mse: 0.3470\n",
      "Epoch 427/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3523 - mse: 0.1143 - val_loss: 1.3302 - val_mse: 0.3421\n",
      "Epoch 428/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3483 - mse: 0.1131 - val_loss: 1.4005 - val_mse: 0.3566\n",
      "Epoch 429/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3552 - mse: 0.1153 - val_loss: 1.3323 - val_mse: 0.3382\n",
      "Epoch 430/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3486 - mse: 0.1132 - val_loss: 1.3117 - val_mse: 0.3336\n",
      "Epoch 431/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3522 - mse: 0.1151 - val_loss: 1.3428 - val_mse: 0.3440\n",
      "Epoch 432/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3470 - mse: 0.1129 - val_loss: 1.3510 - val_mse: 0.3421\n",
      "Epoch 433/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3498 - mse: 0.1138 - val_loss: 1.4800 - val_mse: 0.3621\n",
      "Epoch 434/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3522 - mse: 0.1153 - val_loss: 1.3696 - val_mse: 0.3455\n",
      "Epoch 435/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3490 - mse: 0.1134 - val_loss: 1.4650 - val_mse: 0.3751\n",
      "Epoch 436/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3445 - mse: 0.1115 - val_loss: 1.4015 - val_mse: 0.3585\n",
      "Epoch 437/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3457 - mse: 0.1124 - val_loss: 1.3630 - val_mse: 0.3456\n",
      "Epoch 438/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3447 - mse: 0.1121 - val_loss: 1.4060 - val_mse: 0.3497\n",
      "Epoch 439/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3479 - mse: 0.1134 - val_loss: 1.3412 - val_mse: 0.3426\n",
      "Epoch 440/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3450 - mse: 0.1121 - val_loss: 1.3774 - val_mse: 0.3447\n",
      "Epoch 441/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3482 - mse: 0.1138 - val_loss: 1.3239 - val_mse: 0.3328\n",
      "Epoch 442/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3510 - mse: 0.1145 - val_loss: 1.4171 - val_mse: 0.3654\n",
      "Epoch 443/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3430 - mse: 0.1115 - val_loss: 1.4201 - val_mse: 0.3560\n",
      "Epoch 444/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3447 - mse: 0.1123 - val_loss: 1.4064 - val_mse: 0.3581\n",
      "Epoch 445/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3512 - mse: 0.1142 - val_loss: 1.4027 - val_mse: 0.3468\n",
      "Epoch 446/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3494 - mse: 0.1140 - val_loss: 1.4217 - val_mse: 0.3629\n",
      "Epoch 447/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3450 - mse: 0.1125 - val_loss: 1.4519 - val_mse: 0.3626\n",
      "Epoch 448/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3467 - mse: 0.1125 - val_loss: 1.3783 - val_mse: 0.3443\n",
      "Epoch 449/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3510 - mse: 0.1148 - val_loss: 1.3992 - val_mse: 0.3490\n",
      "Epoch 450/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3438 - mse: 0.1117 - val_loss: 1.4543 - val_mse: 0.3655\n",
      "Epoch 451/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3429 - mse: 0.1113 - val_loss: 1.3808 - val_mse: 0.3454\n",
      "Epoch 452/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3430 - mse: 0.1117 - val_loss: 1.3937 - val_mse: 0.3480\n",
      "Epoch 453/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3437 - mse: 0.1111 - val_loss: 1.3681 - val_mse: 0.3457\n",
      "Epoch 454/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3452 - mse: 0.1124 - val_loss: 1.4198 - val_mse: 0.3535\n",
      "Epoch 455/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3410 - mse: 0.1109 - val_loss: 1.3817 - val_mse: 0.3441\n",
      "Epoch 456/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3448 - mse: 0.1123 - val_loss: 1.5038 - val_mse: 0.3640\n",
      "Epoch 457/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3455 - mse: 0.1119 - val_loss: 1.4781 - val_mse: 0.3654\n",
      "Epoch 458/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3437 - mse: 0.1121 - val_loss: 1.3972 - val_mse: 0.3431\n",
      "Epoch 459/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3444 - mse: 0.1120 - val_loss: 1.4231 - val_mse: 0.3568\n",
      "Epoch 460/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3398 - mse: 0.1105 - val_loss: 1.4806 - val_mse: 0.3638\n",
      "Epoch 461/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3420 - mse: 0.1112 - val_loss: 1.4230 - val_mse: 0.3534\n",
      "Epoch 462/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3390 - mse: 0.1098 - val_loss: 1.4541 - val_mse: 0.3616\n",
      "Epoch 463/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3389 - mse: 0.1100 - val_loss: 1.4071 - val_mse: 0.3487\n",
      "Epoch 464/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3389 - mse: 0.1097 - val_loss: 1.4023 - val_mse: 0.3466\n",
      "Epoch 465/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3410 - mse: 0.1114 - val_loss: 1.4719 - val_mse: 0.3649\n",
      "Epoch 466/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3379 - mse: 0.1095 - val_loss: 1.4282 - val_mse: 0.3586\n",
      "Epoch 467/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3342 - mse: 0.1083 - val_loss: 1.4036 - val_mse: 0.3532\n",
      "Epoch 468/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3423 - mse: 0.1115 - val_loss: 1.4165 - val_mse: 0.3393\n",
      "Epoch 469/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3403 - mse: 0.1108 - val_loss: 1.4541 - val_mse: 0.3564\n",
      "Epoch 470/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3395 - mse: 0.1101 - val_loss: 1.4454 - val_mse: 0.3640\n",
      "Epoch 471/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3401 - mse: 0.1106 - val_loss: 1.5133 - val_mse: 0.3616\n",
      "Epoch 472/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3408 - mse: 0.1115 - val_loss: 1.4290 - val_mse: 0.3468\n",
      "Epoch 473/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3347 - mse: 0.1087 - val_loss: 1.4501 - val_mse: 0.3577\n",
      "Epoch 474/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3347 - mse: 0.1084 - val_loss: 1.4008 - val_mse: 0.3470\n",
      "Epoch 475/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3353 - mse: 0.1089 - val_loss: 1.4424 - val_mse: 0.3532\n",
      "Epoch 476/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3357 - mse: 0.1087 - val_loss: 1.3727 - val_mse: 0.3401\n",
      "Epoch 477/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3360 - mse: 0.1095 - val_loss: 1.5357 - val_mse: 0.3654\n",
      "Epoch 478/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3317 - mse: 0.1082 - val_loss: 1.3952 - val_mse: 0.3365\n",
      "Epoch 479/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3335 - mse: 0.1078 - val_loss: 1.4398 - val_mse: 0.3583\n",
      "Epoch 480/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3345 - mse: 0.1091 - val_loss: 1.5017 - val_mse: 0.3612\n",
      "Epoch 481/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3362 - mse: 0.1091 - val_loss: 1.5162 - val_mse: 0.3740\n",
      "Epoch 482/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3319 - mse: 0.1078 - val_loss: 1.4368 - val_mse: 0.3493\n",
      "Epoch 483/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3421 - mse: 0.1112 - val_loss: 1.4697 - val_mse: 0.3672\n",
      "Epoch 484/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3333 - mse: 0.1077 - val_loss: 1.4766 - val_mse: 0.3575\n",
      "Epoch 485/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3312 - mse: 0.1078 - val_loss: 1.5051 - val_mse: 0.3594\n",
      "Epoch 486/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3309 - mse: 0.1073 - val_loss: 1.5116 - val_mse: 0.3684\n",
      "Epoch 487/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3347 - mse: 0.1094 - val_loss: 1.5179 - val_mse: 0.3576\n",
      "Epoch 488/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3300 - mse: 0.1075 - val_loss: 1.5249 - val_mse: 0.3691\n",
      "Epoch 489/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3339 - mse: 0.1088 - val_loss: 1.4609 - val_mse: 0.3596\n",
      "Epoch 490/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3349 - mse: 0.1091 - val_loss: 1.5167 - val_mse: 0.3631\n",
      "Epoch 491/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3312 - mse: 0.1076 - val_loss: 1.4674 - val_mse: 0.3557\n",
      "Epoch 492/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3309 - mse: 0.1077 - val_loss: 1.4292 - val_mse: 0.3401\n",
      "Epoch 493/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3293 - mse: 0.1068 - val_loss: 1.4726 - val_mse: 0.3536\n",
      "Epoch 494/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3312 - mse: 0.1078 - val_loss: 1.4030 - val_mse: 0.3361\n",
      "Epoch 495/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3395 - mse: 0.1110 - val_loss: 1.4863 - val_mse: 0.3609\n",
      "Epoch 496/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3301 - mse: 0.1068 - val_loss: 1.4866 - val_mse: 0.3531\n",
      "Epoch 497/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3245 - mse: 0.1050 - val_loss: 1.4275 - val_mse: 0.3446\n",
      "Epoch 498/500\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.3377 - mse: 0.1105 - val_loss: 1.5222 - val_mse: 0.3643\n",
      "Epoch 499/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3342 - mse: 0.1076 - val_loss: 1.5403 - val_mse: 0.3640\n",
      "Epoch 500/500\n",
      "123/123 [==============================] - 0s 1ms/step - loss: 0.3296 - mse: 0.1071 - val_loss: 1.5456 - val_mse: 0.3599\n"
     ]
    }
   ],
   "source": [
    "hist =  model.fit(x=train_x, y=train_y,\n",
    "                  epochs=500, batch_size=30,\n",
    "                  validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "53b9c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].plot(hist.epoch, hist.history['loss'])\n",
    "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
    "axs[0].legend(('training loss', 'validation loss'), loc='lower right')\n",
    "axs[1].plot(hist.epoch, hist.history['mse'])\n",
    "axs[1].plot(hist.epoch, hist.history['val_mse'])\n",
    "axs[1].legend(('training accuracy','validation accuracy'), loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1b958e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 228)               13224     \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 199)               45571     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 185)               37000     \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 142)               26412     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 114)               16302     \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 71)                8165      \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 28)                2016      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 7)                 105       \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 149,209\n",
      "Trainable params: 149,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dim = train_x.shape[1]\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(dim),\n",
    "  tf.keras.layers.Dense(int(dim*4), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*3.5), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*3.25), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*2.5), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*2), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*1.25), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*.5), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*0.25), activation='relu'),\n",
    "  tf.keras.layers.Dense(int(dim*0.125), activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['mse','accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1df7061b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.6920 - mse: 0.2494 - accuracy: 0.6066 - val_loss: 0.6913 - val_mse: 0.2491 - val_accuracy: 0.5891\n",
      "Epoch 2/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6843 - mse: 0.2456 - accuracy: 0.6102 - val_loss: 0.6877 - val_mse: 0.2471 - val_accuracy: 0.5891\n",
      "Epoch 3/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6692 - mse: 0.2381 - accuracy: 0.6102 - val_loss: 0.6850 - val_mse: 0.2459 - val_accuracy: 0.5891\n",
      "Epoch 4/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6688 - mse: 0.2379 - accuracy: 0.6102 - val_loss: 0.6859 - val_mse: 0.2462 - val_accuracy: 0.5891\n",
      "Epoch 5/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6676 - mse: 0.2374 - accuracy: 0.6102 - val_loss: 0.6833 - val_mse: 0.2450 - val_accuracy: 0.5891\n",
      "Epoch 6/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6672 - mse: 0.2372 - accuracy: 0.6102 - val_loss: 0.6809 - val_mse: 0.2439 - val_accuracy: 0.5891\n",
      "Epoch 7/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6668 - mse: 0.2370 - accuracy: 0.6102 - val_loss: 0.6809 - val_mse: 0.2439 - val_accuracy: 0.5891\n",
      "Epoch 8/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6656 - mse: 0.2365 - accuracy: 0.6102 - val_loss: 0.6825 - val_mse: 0.2446 - val_accuracy: 0.5891\n",
      "Epoch 9/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6655 - mse: 0.2364 - accuracy: 0.6102 - val_loss: 0.6782 - val_mse: 0.2426 - val_accuracy: 0.5891\n",
      "Epoch 10/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6650 - mse: 0.2361 - accuracy: 0.6102 - val_loss: 0.6776 - val_mse: 0.2423 - val_accuracy: 0.5891\n",
      "Epoch 11/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6638 - mse: 0.2356 - accuracy: 0.6102 - val_loss: 0.6755 - val_mse: 0.2414 - val_accuracy: 0.5891\n",
      "Epoch 12/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6625 - mse: 0.2350 - accuracy: 0.6102 - val_loss: 0.6796 - val_mse: 0.2432 - val_accuracy: 0.5891\n",
      "Epoch 13/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6624 - mse: 0.2350 - accuracy: 0.6102 - val_loss: 0.6728 - val_mse: 0.2400 - val_accuracy: 0.5891\n",
      "Epoch 14/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6605 - mse: 0.2341 - accuracy: 0.6102 - val_loss: 0.6773 - val_mse: 0.2421 - val_accuracy: 0.5891\n",
      "Epoch 15/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6592 - mse: 0.2335 - accuracy: 0.6115 - val_loss: 0.6776 - val_mse: 0.2423 - val_accuracy: 0.5957\n",
      "Epoch 16/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6580 - mse: 0.2330 - accuracy: 0.6083 - val_loss: 0.6738 - val_mse: 0.2406 - val_accuracy: 0.5924\n",
      "Epoch 17/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6562 - mse: 0.2321 - accuracy: 0.6140 - val_loss: 0.6777 - val_mse: 0.2424 - val_accuracy: 0.5804\n",
      "Epoch 18/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6534 - mse: 0.2309 - accuracy: 0.6197 - val_loss: 0.6736 - val_mse: 0.2406 - val_accuracy: 0.5674\n",
      "Epoch 19/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6511 - mse: 0.2298 - accuracy: 0.6197 - val_loss: 0.6791 - val_mse: 0.2432 - val_accuracy: 0.5793\n",
      "Epoch 20/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6472 - mse: 0.2279 - accuracy: 0.6294 - val_loss: 0.6749 - val_mse: 0.2413 - val_accuracy: 0.5641\n",
      "Epoch 21/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6433 - mse: 0.2262 - accuracy: 0.6333 - val_loss: 0.6773 - val_mse: 0.2423 - val_accuracy: 0.5826\n",
      "Epoch 22/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6395 - mse: 0.2243 - accuracy: 0.6390 - val_loss: 0.6699 - val_mse: 0.2388 - val_accuracy: 0.5913\n",
      "Epoch 23/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6317 - mse: 0.2208 - accuracy: 0.6438 - val_loss: 0.6907 - val_mse: 0.2485 - val_accuracy: 0.5478\n",
      "Epoch 24/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6319 - mse: 0.2209 - accuracy: 0.6504 - val_loss: 0.6918 - val_mse: 0.2492 - val_accuracy: 0.5500\n",
      "Epoch 25/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6230 - mse: 0.2169 - accuracy: 0.6506 - val_loss: 0.6892 - val_mse: 0.2467 - val_accuracy: 0.5913\n",
      "Epoch 26/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6222 - mse: 0.2166 - accuracy: 0.6574 - val_loss: 0.6997 - val_mse: 0.2518 - val_accuracy: 0.5717\n",
      "Epoch 27/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6162 - mse: 0.2138 - accuracy: 0.6618 - val_loss: 0.6979 - val_mse: 0.2513 - val_accuracy: 0.5587\n",
      "Epoch 28/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6086 - mse: 0.2103 - accuracy: 0.6792 - val_loss: 0.7189 - val_mse: 0.2607 - val_accuracy: 0.5511\n",
      "Epoch 29/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.6023 - mse: 0.2077 - accuracy: 0.6737 - val_loss: 0.7171 - val_mse: 0.2580 - val_accuracy: 0.5641\n",
      "Epoch 30/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5947 - mse: 0.2042 - accuracy: 0.6846 - val_loss: 0.7344 - val_mse: 0.2635 - val_accuracy: 0.5793\n",
      "Epoch 31/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5918 - mse: 0.2030 - accuracy: 0.6835 - val_loss: 0.7459 - val_mse: 0.2685 - val_accuracy: 0.5761\n",
      "Epoch 32/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5851 - mse: 0.2001 - accuracy: 0.6982 - val_loss: 0.7981 - val_mse: 0.2946 - val_accuracy: 0.4717\n",
      "Epoch 33/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5769 - mse: 0.1965 - accuracy: 0.7047 - val_loss: 0.7723 - val_mse: 0.2815 - val_accuracy: 0.5228\n",
      "Epoch 34/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5753 - mse: 0.1961 - accuracy: 0.6990 - val_loss: 0.7456 - val_mse: 0.2679 - val_accuracy: 0.5685\n",
      "Epoch 35/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5657 - mse: 0.1920 - accuracy: 0.7112 - val_loss: 0.7526 - val_mse: 0.2682 - val_accuracy: 0.5859\n",
      "Epoch 36/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5620 - mse: 0.1905 - accuracy: 0.7161 - val_loss: 0.7581 - val_mse: 0.2718 - val_accuracy: 0.5587\n",
      "Epoch 37/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5591 - mse: 0.1893 - accuracy: 0.7183 - val_loss: 0.7829 - val_mse: 0.2827 - val_accuracy: 0.5380\n",
      "Epoch 38/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5518 - mse: 0.1862 - accuracy: 0.7199 - val_loss: 0.8301 - val_mse: 0.3020 - val_accuracy: 0.4891\n",
      "Epoch 39/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5491 - mse: 0.1850 - accuracy: 0.7226 - val_loss: 0.7698 - val_mse: 0.2733 - val_accuracy: 0.5870\n",
      "Epoch 40/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5406 - mse: 0.1815 - accuracy: 0.7335 - val_loss: 0.7725 - val_mse: 0.2741 - val_accuracy: 0.5804\n",
      "Epoch 41/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5396 - mse: 0.1812 - accuracy: 0.7357 - val_loss: 0.8348 - val_mse: 0.3032 - val_accuracy: 0.4946\n",
      "Epoch 42/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5306 - mse: 0.1772 - accuracy: 0.7384 - val_loss: 0.8416 - val_mse: 0.3023 - val_accuracy: 0.5457\n",
      "Epoch 43/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5225 - mse: 0.1738 - accuracy: 0.7468 - val_loss: 0.8478 - val_mse: 0.3044 - val_accuracy: 0.5207\n",
      "Epoch 44/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5241 - mse: 0.1750 - accuracy: 0.7411 - val_loss: 0.8245 - val_mse: 0.2930 - val_accuracy: 0.5554\n",
      "Epoch 45/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5155 - mse: 0.1714 - accuracy: 0.7517 - val_loss: 0.8591 - val_mse: 0.3053 - val_accuracy: 0.5424\n",
      "Epoch 46/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5100 - mse: 0.1693 - accuracy: 0.7525 - val_loss: 0.8407 - val_mse: 0.2952 - val_accuracy: 0.5663\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5094 - mse: 0.1689 - accuracy: 0.7544 - val_loss: 0.8417 - val_mse: 0.2972 - val_accuracy: 0.5609\n",
      "Epoch 48/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5023 - mse: 0.1659 - accuracy: 0.7642 - val_loss: 0.9162 - val_mse: 0.3272 - val_accuracy: 0.4924\n",
      "Epoch 49/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.5056 - mse: 0.1674 - accuracy: 0.7574 - val_loss: 0.8966 - val_mse: 0.3189 - val_accuracy: 0.5152\n",
      "Epoch 50/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4905 - mse: 0.1614 - accuracy: 0.7732 - val_loss: 0.8923 - val_mse: 0.3137 - val_accuracy: 0.5163\n",
      "Epoch 51/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4868 - mse: 0.1601 - accuracy: 0.7650 - val_loss: 0.8865 - val_mse: 0.3097 - val_accuracy: 0.5337\n",
      "Epoch 52/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4812 - mse: 0.1578 - accuracy: 0.7715 - val_loss: 0.8828 - val_mse: 0.3074 - val_accuracy: 0.5543\n",
      "Epoch 53/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4881 - mse: 0.1605 - accuracy: 0.7691 - val_loss: 0.9452 - val_mse: 0.3294 - val_accuracy: 0.5098\n",
      "Epoch 54/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4731 - mse: 0.1546 - accuracy: 0.7827 - val_loss: 0.9370 - val_mse: 0.3255 - val_accuracy: 0.5207\n",
      "Epoch 55/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4723 - mse: 0.1544 - accuracy: 0.7789 - val_loss: 0.8858 - val_mse: 0.3075 - val_accuracy: 0.5435\n",
      "Epoch 56/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4704 - mse: 0.1532 - accuracy: 0.7810 - val_loss: 0.9074 - val_mse: 0.3138 - val_accuracy: 0.5424\n",
      "Epoch 57/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4702 - mse: 0.1536 - accuracy: 0.7819 - val_loss: 0.9229 - val_mse: 0.3196 - val_accuracy: 0.5348\n",
      "Epoch 58/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4606 - mse: 0.1497 - accuracy: 0.7876 - val_loss: 0.9221 - val_mse: 0.3167 - val_accuracy: 0.5446\n",
      "Epoch 59/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4618 - mse: 0.1494 - accuracy: 0.7881 - val_loss: 0.8894 - val_mse: 0.3073 - val_accuracy: 0.5674\n",
      "Epoch 60/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4492 - mse: 0.1456 - accuracy: 0.7922 - val_loss: 0.9969 - val_mse: 0.3395 - val_accuracy: 0.5196\n",
      "Epoch 61/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4492 - mse: 0.1460 - accuracy: 0.7946 - val_loss: 1.0595 - val_mse: 0.3626 - val_accuracy: 0.4522\n",
      "Epoch 62/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4439 - mse: 0.1438 - accuracy: 0.7971 - val_loss: 1.0307 - val_mse: 0.3464 - val_accuracy: 0.5098\n",
      "Epoch 63/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4362 - mse: 0.1405 - accuracy: 0.8017 - val_loss: 0.9501 - val_mse: 0.3176 - val_accuracy: 0.5478\n",
      "Epoch 64/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4388 - mse: 0.1414 - accuracy: 0.7998 - val_loss: 0.9741 - val_mse: 0.3299 - val_accuracy: 0.5359\n",
      "Epoch 65/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4309 - mse: 0.1386 - accuracy: 0.8058 - val_loss: 0.9675 - val_mse: 0.3233 - val_accuracy: 0.5565\n",
      "Epoch 66/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4268 - mse: 0.1378 - accuracy: 0.8017 - val_loss: 0.9656 - val_mse: 0.3178 - val_accuracy: 0.5565\n",
      "Epoch 67/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4241 - mse: 0.1364 - accuracy: 0.8025 - val_loss: 1.0500 - val_mse: 0.3448 - val_accuracy: 0.5196\n",
      "Epoch 68/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4336 - mse: 0.1400 - accuracy: 0.8014 - val_loss: 0.9666 - val_mse: 0.3236 - val_accuracy: 0.5402\n",
      "Epoch 69/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.4240 - mse: 0.1362 - accuracy: 0.8109 - val_loss: 1.0694 - val_mse: 0.3472 - val_accuracy: 0.5185\n",
      "Epoch 70/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4202 - mse: 0.1351 - accuracy: 0.8098 - val_loss: 1.0287 - val_mse: 0.3357 - val_accuracy: 0.5457\n",
      "Epoch 71/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4202 - mse: 0.1349 - accuracy: 0.8093 - val_loss: 1.0154 - val_mse: 0.3306 - val_accuracy: 0.5457\n",
      "Epoch 72/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4237 - mse: 0.1369 - accuracy: 0.8085 - val_loss: 0.9789 - val_mse: 0.3232 - val_accuracy: 0.5565\n",
      "Epoch 73/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4163 - mse: 0.1339 - accuracy: 0.8096 - val_loss: 1.2023 - val_mse: 0.3769 - val_accuracy: 0.4870\n",
      "Epoch 74/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4104 - mse: 0.1314 - accuracy: 0.8191 - val_loss: 1.0496 - val_mse: 0.3315 - val_accuracy: 0.5543\n",
      "Epoch 75/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4188 - mse: 0.1352 - accuracy: 0.8077 - val_loss: 1.1074 - val_mse: 0.3546 - val_accuracy: 0.4870\n",
      "Epoch 76/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3979 - mse: 0.1270 - accuracy: 0.8234 - val_loss: 1.0570 - val_mse: 0.3383 - val_accuracy: 0.5359\n",
      "Epoch 77/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4011 - mse: 0.1267 - accuracy: 0.8242 - val_loss: 1.1497 - val_mse: 0.3646 - val_accuracy: 0.5130\n",
      "Epoch 78/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4031 - mse: 0.1291 - accuracy: 0.8223 - val_loss: 1.0473 - val_mse: 0.3306 - val_accuracy: 0.5500\n",
      "Epoch 79/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3934 - mse: 0.1258 - accuracy: 0.8242 - val_loss: 1.1717 - val_mse: 0.3601 - val_accuracy: 0.5217\n",
      "Epoch 80/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.4080 - mse: 0.1312 - accuracy: 0.8158 - val_loss: 1.1570 - val_mse: 0.3636 - val_accuracy: 0.5043\n",
      "Epoch 81/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3914 - mse: 0.1250 - accuracy: 0.8269 - val_loss: 1.1278 - val_mse: 0.3452 - val_accuracy: 0.5370\n",
      "Epoch 82/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3871 - mse: 0.1232 - accuracy: 0.8245 - val_loss: 1.0929 - val_mse: 0.3410 - val_accuracy: 0.5500\n",
      "Epoch 83/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3884 - mse: 0.1235 - accuracy: 0.8261 - val_loss: 1.1228 - val_mse: 0.3473 - val_accuracy: 0.5478\n",
      "Epoch 84/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3822 - mse: 0.1216 - accuracy: 0.8297 - val_loss: 1.1912 - val_mse: 0.3611 - val_accuracy: 0.5087\n",
      "Epoch 85/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3778 - mse: 0.1208 - accuracy: 0.8302 - val_loss: 1.1835 - val_mse: 0.3607 - val_accuracy: 0.5348\n",
      "Epoch 86/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3734 - mse: 0.1187 - accuracy: 0.8321 - val_loss: 1.2087 - val_mse: 0.3580 - val_accuracy: 0.5380\n",
      "Epoch 87/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3696 - mse: 0.1174 - accuracy: 0.8343 - val_loss: 1.1659 - val_mse: 0.3534 - val_accuracy: 0.5413\n",
      "Epoch 88/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3748 - mse: 0.1199 - accuracy: 0.8302 - val_loss: 1.2301 - val_mse: 0.3685 - val_accuracy: 0.5163\n",
      "Epoch 89/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3655 - mse: 0.1159 - accuracy: 0.8381 - val_loss: 1.1705 - val_mse: 0.3521 - val_accuracy: 0.5435\n",
      "Epoch 90/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3901 - mse: 0.1259 - accuracy: 0.8166 - val_loss: 1.2078 - val_mse: 0.3633 - val_accuracy: 0.4913\n",
      "Epoch 91/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3765 - mse: 0.1199 - accuracy: 0.8329 - val_loss: 1.2937 - val_mse: 0.3741 - val_accuracy: 0.5098\n",
      "Epoch 92/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3626 - mse: 0.1155 - accuracy: 0.8384 - val_loss: 1.1925 - val_mse: 0.3512 - val_accuracy: 0.5500\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3655 - mse: 0.1167 - accuracy: 0.8362 - val_loss: 1.1634 - val_mse: 0.3530 - val_accuracy: 0.5402\n",
      "Epoch 94/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3748 - mse: 0.1202 - accuracy: 0.8275 - val_loss: 1.1520 - val_mse: 0.3448 - val_accuracy: 0.5467\n",
      "Epoch 95/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3614 - mse: 0.1144 - accuracy: 0.8413 - val_loss: 1.3783 - val_mse: 0.3888 - val_accuracy: 0.4837\n",
      "Epoch 96/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3530 - mse: 0.1117 - accuracy: 0.8441 - val_loss: 1.3248 - val_mse: 0.3795 - val_accuracy: 0.5109\n",
      "Epoch 97/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3516 - mse: 0.1113 - accuracy: 0.8443 - val_loss: 1.1931 - val_mse: 0.3481 - val_accuracy: 0.5576\n",
      "Epoch 98/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3503 - mse: 0.1111 - accuracy: 0.8460 - val_loss: 1.2361 - val_mse: 0.3572 - val_accuracy: 0.5522\n",
      "Epoch 99/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3496 - mse: 0.1110 - accuracy: 0.8400 - val_loss: 1.1602 - val_mse: 0.3424 - val_accuracy: 0.5609\n",
      "Epoch 100/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3511 - mse: 0.1117 - accuracy: 0.8435 - val_loss: 1.2270 - val_mse: 0.3593 - val_accuracy: 0.5402\n",
      "Epoch 101/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3380 - mse: 0.1068 - accuracy: 0.8490 - val_loss: 1.3099 - val_mse: 0.3570 - val_accuracy: 0.5424\n",
      "Epoch 102/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3363 - mse: 0.1065 - accuracy: 0.8468 - val_loss: 1.2511 - val_mse: 0.3574 - val_accuracy: 0.5511\n",
      "Epoch 103/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.3588 - mse: 0.1144 - accuracy: 0.8392 - val_loss: 1.1722 - val_mse: 0.3371 - val_accuracy: 0.5652\n",
      "Epoch 104/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3411 - mse: 0.1083 - accuracy: 0.8432 - val_loss: 1.2381 - val_mse: 0.3488 - val_accuracy: 0.5565\n",
      "Epoch 105/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3357 - mse: 0.1058 - accuracy: 0.8525 - val_loss: 1.5013 - val_mse: 0.4013 - val_accuracy: 0.4717\n",
      "Epoch 106/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.3435 - mse: 0.1100 - accuracy: 0.8370 - val_loss: 1.2456 - val_mse: 0.3509 - val_accuracy: 0.5576\n",
      "Epoch 107/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3348 - mse: 0.1059 - accuracy: 0.8503 - val_loss: 1.4906 - val_mse: 0.4049 - val_accuracy: 0.4793\n",
      "Epoch 108/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.3279 - mse: 0.1031 - accuracy: 0.8536 - val_loss: 1.4248 - val_mse: 0.3855 - val_accuracy: 0.5185\n",
      "Epoch 109/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3323 - mse: 0.1054 - accuracy: 0.8473 - val_loss: 1.2936 - val_mse: 0.3559 - val_accuracy: 0.5630\n",
      "Epoch 110/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3281 - mse: 0.1039 - accuracy: 0.8490 - val_loss: 1.6243 - val_mse: 0.4124 - val_accuracy: 0.4880\n",
      "Epoch 111/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3296 - mse: 0.1055 - accuracy: 0.8452 - val_loss: 1.3464 - val_mse: 0.3662 - val_accuracy: 0.5424\n",
      "Epoch 112/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.3281 - mse: 0.1044 - accuracy: 0.8465 - val_loss: 1.5418 - val_mse: 0.4071 - val_accuracy: 0.4707\n",
      "Epoch 113/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.3306 - mse: 0.1052 - accuracy: 0.8457 - val_loss: 1.3899 - val_mse: 0.3667 - val_accuracy: 0.5315\n",
      "Epoch 114/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.3230 - mse: 0.1023 - accuracy: 0.8544 - val_loss: 1.4579 - val_mse: 0.3934 - val_accuracy: 0.5163\n",
      "Epoch 115/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3167 - mse: 0.1001 - accuracy: 0.8587 - val_loss: 1.4579 - val_mse: 0.3786 - val_accuracy: 0.5217\n",
      "Epoch 116/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3181 - mse: 0.1015 - accuracy: 0.8533 - val_loss: 1.4325 - val_mse: 0.3712 - val_accuracy: 0.5326\n",
      "Epoch 117/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3276 - mse: 0.1052 - accuracy: 0.8484 - val_loss: 1.6053 - val_mse: 0.3978 - val_accuracy: 0.4663\n",
      "Epoch 118/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3196 - mse: 0.1014 - accuracy: 0.8590 - val_loss: 1.4548 - val_mse: 0.3760 - val_accuracy: 0.5228\n",
      "Epoch 119/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3162 - mse: 0.1003 - accuracy: 0.8522 - val_loss: 1.4663 - val_mse: 0.3812 - val_accuracy: 0.5250\n",
      "Epoch 120/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3155 - mse: 0.1010 - accuracy: 0.8525 - val_loss: 1.3220 - val_mse: 0.3535 - val_accuracy: 0.5543\n",
      "Epoch 121/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3123 - mse: 0.0998 - accuracy: 0.8528 - val_loss: 1.4307 - val_mse: 0.3711 - val_accuracy: 0.5413\n",
      "Epoch 122/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3121 - mse: 0.0994 - accuracy: 0.8560 - val_loss: 1.5166 - val_mse: 0.3753 - val_accuracy: 0.5348\n",
      "Epoch 123/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3161 - mse: 0.1010 - accuracy: 0.8528 - val_loss: 1.4113 - val_mse: 0.3753 - val_accuracy: 0.5283\n",
      "Epoch 124/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3103 - mse: 0.0990 - accuracy: 0.8574 - val_loss: 1.5286 - val_mse: 0.3831 - val_accuracy: 0.5239\n",
      "Epoch 125/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2986 - mse: 0.0951 - accuracy: 0.8639 - val_loss: 1.6048 - val_mse: 0.3926 - val_accuracy: 0.5076\n",
      "Epoch 126/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3190 - mse: 0.1021 - accuracy: 0.8549 - val_loss: 1.4909 - val_mse: 0.3760 - val_accuracy: 0.5380\n",
      "Epoch 127/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3018 - mse: 0.0961 - accuracy: 0.8609 - val_loss: 1.4809 - val_mse: 0.3653 - val_accuracy: 0.5489\n",
      "Epoch 128/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3155 - mse: 0.1002 - accuracy: 0.8601 - val_loss: 1.6389 - val_mse: 0.4082 - val_accuracy: 0.4620\n",
      "Epoch 129/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3070 - mse: 0.0974 - accuracy: 0.8574 - val_loss: 1.4166 - val_mse: 0.3606 - val_accuracy: 0.5478\n",
      "Epoch 130/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2996 - mse: 0.0954 - accuracy: 0.8625 - val_loss: 1.4086 - val_mse: 0.3644 - val_accuracy: 0.5576\n",
      "Epoch 131/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3066 - mse: 0.0976 - accuracy: 0.8574 - val_loss: 1.4076 - val_mse: 0.3582 - val_accuracy: 0.5576\n",
      "Epoch 132/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3022 - mse: 0.0969 - accuracy: 0.8552 - val_loss: 1.6800 - val_mse: 0.4015 - val_accuracy: 0.5043\n",
      "Epoch 133/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2904 - mse: 0.0925 - accuracy: 0.8650 - val_loss: 1.6256 - val_mse: 0.3859 - val_accuracy: 0.5446\n",
      "Epoch 134/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3012 - mse: 0.0967 - accuracy: 0.8549 - val_loss: 1.4377 - val_mse: 0.3584 - val_accuracy: 0.5435\n",
      "Epoch 135/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2923 - mse: 0.0929 - accuracy: 0.8628 - val_loss: 1.5949 - val_mse: 0.3824 - val_accuracy: 0.5043\n",
      "Epoch 136/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3005 - mse: 0.0956 - accuracy: 0.8609 - val_loss: 1.4783 - val_mse: 0.3617 - val_accuracy: 0.5543\n",
      "Epoch 137/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2961 - mse: 0.0944 - accuracy: 0.8601 - val_loss: 1.4164 - val_mse: 0.3678 - val_accuracy: 0.5380\n",
      "Epoch 138/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.2944 - mse: 0.0945 - accuracy: 0.8587 - val_loss: 1.5106 - val_mse: 0.3720 - val_accuracy: 0.5402\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3016 - mse: 0.0956 - accuracy: 0.8574 - val_loss: 1.4939 - val_mse: 0.3601 - val_accuracy: 0.5435\n",
      "Epoch 140/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2857 - mse: 0.0901 - accuracy: 0.8696 - val_loss: 1.6597 - val_mse: 0.3871 - val_accuracy: 0.5217\n",
      "Epoch 141/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2887 - mse: 0.0919 - accuracy: 0.8655 - val_loss: 1.4784 - val_mse: 0.3789 - val_accuracy: 0.5435\n",
      "Epoch 142/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2909 - mse: 0.0927 - accuracy: 0.8642 - val_loss: 1.5300 - val_mse: 0.3842 - val_accuracy: 0.5370\n",
      "Epoch 143/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2789 - mse: 0.0889 - accuracy: 0.8701 - val_loss: 1.7038 - val_mse: 0.3955 - val_accuracy: 0.5293\n",
      "Epoch 144/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2819 - mse: 0.0899 - accuracy: 0.8669 - val_loss: 1.6794 - val_mse: 0.3998 - val_accuracy: 0.4848\n",
      "Epoch 145/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2840 - mse: 0.0918 - accuracy: 0.8590 - val_loss: 1.6293 - val_mse: 0.3908 - val_accuracy: 0.5272\n",
      "Epoch 146/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2864 - mse: 0.0911 - accuracy: 0.8669 - val_loss: 1.6945 - val_mse: 0.3949 - val_accuracy: 0.4783\n",
      "Epoch 147/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2858 - mse: 0.0912 - accuracy: 0.8650 - val_loss: 1.6151 - val_mse: 0.3868 - val_accuracy: 0.5163\n",
      "Epoch 148/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2743 - mse: 0.0878 - accuracy: 0.8666 - val_loss: 1.5928 - val_mse: 0.3657 - val_accuracy: 0.5554\n",
      "Epoch 149/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2778 - mse: 0.0890 - accuracy: 0.8707 - val_loss: 1.5932 - val_mse: 0.3809 - val_accuracy: 0.5348\n",
      "Epoch 150/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2763 - mse: 0.0883 - accuracy: 0.8701 - val_loss: 1.5483 - val_mse: 0.3640 - val_accuracy: 0.5402\n",
      "Epoch 151/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2727 - mse: 0.0871 - accuracy: 0.8734 - val_loss: 1.6668 - val_mse: 0.3808 - val_accuracy: 0.5272\n",
      "Epoch 152/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2711 - mse: 0.0862 - accuracy: 0.8750 - val_loss: 1.7662 - val_mse: 0.4006 - val_accuracy: 0.5152\n",
      "Epoch 153/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2685 - mse: 0.0861 - accuracy: 0.8718 - val_loss: 1.5924 - val_mse: 0.3744 - val_accuracy: 0.5467\n",
      "Epoch 154/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2706 - mse: 0.0868 - accuracy: 0.8696 - val_loss: 1.6465 - val_mse: 0.3793 - val_accuracy: 0.5304\n",
      "Epoch 155/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2716 - mse: 0.0884 - accuracy: 0.8625 - val_loss: 1.6138 - val_mse: 0.3723 - val_accuracy: 0.5467\n",
      "Epoch 156/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2730 - mse: 0.0872 - accuracy: 0.8707 - val_loss: 1.6096 - val_mse: 0.3827 - val_accuracy: 0.5359\n",
      "Epoch 157/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2748 - mse: 0.0876 - accuracy: 0.8680 - val_loss: 1.6969 - val_mse: 0.3912 - val_accuracy: 0.5391\n",
      "Epoch 158/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2688 - mse: 0.0859 - accuracy: 0.8726 - val_loss: 1.5186 - val_mse: 0.3548 - val_accuracy: 0.5609\n",
      "Epoch 159/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2595 - mse: 0.0831 - accuracy: 0.8756 - val_loss: 1.7081 - val_mse: 0.3930 - val_accuracy: 0.5250\n",
      "Epoch 160/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2641 - mse: 0.0842 - accuracy: 0.8718 - val_loss: 1.7504 - val_mse: 0.3864 - val_accuracy: 0.5391\n",
      "Epoch 161/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2663 - mse: 0.0856 - accuracy: 0.8704 - val_loss: 1.6160 - val_mse: 0.3740 - val_accuracy: 0.5446\n",
      "Epoch 162/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2670 - mse: 0.0863 - accuracy: 0.8704 - val_loss: 1.6894 - val_mse: 0.3937 - val_accuracy: 0.5163\n",
      "Epoch 163/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2623 - mse: 0.0835 - accuracy: 0.8748 - val_loss: 2.1013 - val_mse: 0.4345 - val_accuracy: 0.4511\n",
      "Epoch 164/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2657 - mse: 0.0847 - accuracy: 0.8764 - val_loss: 1.7445 - val_mse: 0.3841 - val_accuracy: 0.5413\n",
      "Epoch 165/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2933 - mse: 0.0947 - accuracy: 0.8609 - val_loss: 1.6671 - val_mse: 0.3768 - val_accuracy: 0.5467\n",
      "Epoch 166/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2591 - mse: 0.0833 - accuracy: 0.8734 - val_loss: 1.6791 - val_mse: 0.3863 - val_accuracy: 0.5152\n",
      "Epoch 167/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2611 - mse: 0.0837 - accuracy: 0.8810 - val_loss: 1.6011 - val_mse: 0.3643 - val_accuracy: 0.5587\n",
      "Epoch 168/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2705 - mse: 0.0872 - accuracy: 0.8680 - val_loss: 1.8889 - val_mse: 0.4017 - val_accuracy: 0.5054\n",
      "Epoch 169/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2535 - mse: 0.0819 - accuracy: 0.8745 - val_loss: 1.7851 - val_mse: 0.3965 - val_accuracy: 0.5163\n",
      "Epoch 170/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2574 - mse: 0.0829 - accuracy: 0.8715 - val_loss: 1.6425 - val_mse: 0.3763 - val_accuracy: 0.5511\n",
      "Epoch 171/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2774 - mse: 0.0890 - accuracy: 0.8653 - val_loss: 1.7880 - val_mse: 0.3865 - val_accuracy: 0.5337\n",
      "Epoch 172/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2539 - mse: 0.0821 - accuracy: 0.8799 - val_loss: 1.7333 - val_mse: 0.3844 - val_accuracy: 0.5467\n",
      "Epoch 173/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2575 - mse: 0.0834 - accuracy: 0.8769 - val_loss: 1.5458 - val_mse: 0.3650 - val_accuracy: 0.5576\n",
      "Epoch 174/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2565 - mse: 0.0825 - accuracy: 0.8748 - val_loss: 1.7891 - val_mse: 0.3948 - val_accuracy: 0.5228\n",
      "Epoch 175/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2507 - mse: 0.0806 - accuracy: 0.8797 - val_loss: 1.8249 - val_mse: 0.3999 - val_accuracy: 0.5315\n",
      "Epoch 176/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2559 - mse: 0.0827 - accuracy: 0.8734 - val_loss: 1.7269 - val_mse: 0.3930 - val_accuracy: 0.5359\n",
      "Epoch 177/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2500 - mse: 0.0809 - accuracy: 0.8723 - val_loss: 1.7872 - val_mse: 0.3791 - val_accuracy: 0.5457\n",
      "Epoch 178/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2639 - mse: 0.0848 - accuracy: 0.8666 - val_loss: 1.7229 - val_mse: 0.3877 - val_accuracy: 0.5337\n",
      "Epoch 179/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2490 - mse: 0.0800 - accuracy: 0.8807 - val_loss: 1.7082 - val_mse: 0.3834 - val_accuracy: 0.5304\n",
      "Epoch 180/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2480 - mse: 0.0807 - accuracy: 0.8758 - val_loss: 1.7775 - val_mse: 0.3923 - val_accuracy: 0.5380\n",
      "Epoch 181/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2550 - mse: 0.0823 - accuracy: 0.8731 - val_loss: 1.8246 - val_mse: 0.3913 - val_accuracy: 0.5370\n",
      "Epoch 182/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2463 - mse: 0.0798 - accuracy: 0.8764 - val_loss: 1.7029 - val_mse: 0.3836 - val_accuracy: 0.5435\n",
      "Epoch 183/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.2406 - mse: 0.0776 - accuracy: 0.8816 - val_loss: 1.8579 - val_mse: 0.3816 - val_accuracy: 0.5446\n",
      "Epoch 184/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.2635 - mse: 0.0850 - accuracy: 0.8748 - val_loss: 1.9904 - val_mse: 0.4163 - val_accuracy: 0.5000\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 6ms/step - loss: 0.2462 - mse: 0.0793 - accuracy: 0.8824 - val_loss: 1.8732 - val_mse: 0.4042 - val_accuracy: 0.5098\n",
      "Epoch 186/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2595 - mse: 0.0835 - accuracy: 0.8758 - val_loss: 1.9404 - val_mse: 0.4145 - val_accuracy: 0.4913\n",
      "Epoch 187/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2469 - mse: 0.0799 - accuracy: 0.8783 - val_loss: 1.6781 - val_mse: 0.3679 - val_accuracy: 0.5587\n",
      "Epoch 188/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2456 - mse: 0.0798 - accuracy: 0.8764 - val_loss: 1.8131 - val_mse: 0.3848 - val_accuracy: 0.5120\n",
      "Epoch 189/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2481 - mse: 0.0805 - accuracy: 0.8758 - val_loss: 2.0659 - val_mse: 0.4064 - val_accuracy: 0.5217\n",
      "Epoch 190/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2477 - mse: 0.0800 - accuracy: 0.8737 - val_loss: 1.7482 - val_mse: 0.3771 - val_accuracy: 0.5576\n",
      "Epoch 191/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2402 - mse: 0.0781 - accuracy: 0.8797 - val_loss: 1.8264 - val_mse: 0.3869 - val_accuracy: 0.5413\n",
      "Epoch 192/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2362 - mse: 0.0774 - accuracy: 0.8761 - val_loss: 1.8430 - val_mse: 0.3819 - val_accuracy: 0.5467\n",
      "Epoch 193/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2510 - mse: 0.0814 - accuracy: 0.8761 - val_loss: 1.7697 - val_mse: 0.3756 - val_accuracy: 0.5522\n",
      "Epoch 194/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2504 - mse: 0.0812 - accuracy: 0.8761 - val_loss: 1.7385 - val_mse: 0.3770 - val_accuracy: 0.5239\n",
      "Epoch 195/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2415 - mse: 0.0787 - accuracy: 0.8778 - val_loss: 1.7800 - val_mse: 0.3688 - val_accuracy: 0.5576\n",
      "Epoch 196/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2409 - mse: 0.0782 - accuracy: 0.8807 - val_loss: 1.7878 - val_mse: 0.3872 - val_accuracy: 0.5304\n",
      "Epoch 197/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2431 - mse: 0.0791 - accuracy: 0.8797 - val_loss: 1.9149 - val_mse: 0.4060 - val_accuracy: 0.5087\n",
      "Epoch 198/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2430 - mse: 0.0797 - accuracy: 0.8780 - val_loss: 1.8570 - val_mse: 0.3971 - val_accuracy: 0.5228\n",
      "Epoch 199/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2372 - mse: 0.0769 - accuracy: 0.8805 - val_loss: 1.9103 - val_mse: 0.3937 - val_accuracy: 0.5174\n",
      "Epoch 200/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2391 - mse: 0.0777 - accuracy: 0.8805 - val_loss: 1.9128 - val_mse: 0.4031 - val_accuracy: 0.5163\n",
      "Epoch 201/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2302 - mse: 0.0749 - accuracy: 0.8851 - val_loss: 1.8486 - val_mse: 0.3874 - val_accuracy: 0.5402\n",
      "Epoch 202/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2343 - mse: 0.0770 - accuracy: 0.8805 - val_loss: 1.8934 - val_mse: 0.3891 - val_accuracy: 0.5348\n",
      "Epoch 203/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2442 - mse: 0.0790 - accuracy: 0.8805 - val_loss: 1.9385 - val_mse: 0.3933 - val_accuracy: 0.5326\n",
      "Epoch 204/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2399 - mse: 0.0766 - accuracy: 0.8867 - val_loss: 1.7924 - val_mse: 0.3789 - val_accuracy: 0.5424\n",
      "Epoch 205/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2403 - mse: 0.0781 - accuracy: 0.8791 - val_loss: 1.9203 - val_mse: 0.4041 - val_accuracy: 0.5348\n",
      "Epoch 206/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2288 - mse: 0.0743 - accuracy: 0.8864 - val_loss: 1.8983 - val_mse: 0.3916 - val_accuracy: 0.5315\n",
      "Epoch 207/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2353 - mse: 0.0774 - accuracy: 0.8780 - val_loss: 2.1179 - val_mse: 0.4108 - val_accuracy: 0.4957\n",
      "Epoch 208/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2300 - mse: 0.0753 - accuracy: 0.8832 - val_loss: 1.9518 - val_mse: 0.4039 - val_accuracy: 0.5228\n",
      "Epoch 209/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2329 - mse: 0.0760 - accuracy: 0.8826 - val_loss: 1.9035 - val_mse: 0.3840 - val_accuracy: 0.5413\n",
      "Epoch 210/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2423 - mse: 0.0795 - accuracy: 0.8794 - val_loss: 1.9925 - val_mse: 0.3966 - val_accuracy: 0.5359\n",
      "Epoch 211/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2338 - mse: 0.0763 - accuracy: 0.8821 - val_loss: 1.9653 - val_mse: 0.3864 - val_accuracy: 0.5391\n",
      "Epoch 212/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2350 - mse: 0.0755 - accuracy: 0.8840 - val_loss: 1.9633 - val_mse: 0.3996 - val_accuracy: 0.5283\n",
      "Epoch 213/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2357 - mse: 0.0763 - accuracy: 0.8837 - val_loss: 2.2972 - val_mse: 0.4465 - val_accuracy: 0.4826\n",
      "Epoch 214/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2447 - mse: 0.0784 - accuracy: 0.8813 - val_loss: 1.9150 - val_mse: 0.3844 - val_accuracy: 0.5413\n",
      "Epoch 215/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2409 - mse: 0.0783 - accuracy: 0.8821 - val_loss: 2.1369 - val_mse: 0.4166 - val_accuracy: 0.5239\n",
      "Epoch 216/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2317 - mse: 0.0757 - accuracy: 0.8816 - val_loss: 1.7967 - val_mse: 0.3803 - val_accuracy: 0.5457\n",
      "Epoch 217/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2209 - mse: 0.0720 - accuracy: 0.8916 - val_loss: 1.8874 - val_mse: 0.3828 - val_accuracy: 0.5565\n",
      "Epoch 218/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2250 - mse: 0.0731 - accuracy: 0.8867 - val_loss: 1.9104 - val_mse: 0.3839 - val_accuracy: 0.5457\n",
      "Epoch 219/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2227 - mse: 0.0730 - accuracy: 0.8867 - val_loss: 2.1438 - val_mse: 0.4154 - val_accuracy: 0.4902\n",
      "Epoch 220/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2287 - mse: 0.0747 - accuracy: 0.8867 - val_loss: 2.0977 - val_mse: 0.4183 - val_accuracy: 0.5000\n",
      "Epoch 221/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2290 - mse: 0.0751 - accuracy: 0.8799 - val_loss: 1.8750 - val_mse: 0.3939 - val_accuracy: 0.5348\n",
      "Epoch 222/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2362 - mse: 0.0771 - accuracy: 0.8829 - val_loss: 1.7387 - val_mse: 0.3681 - val_accuracy: 0.5576\n",
      "Epoch 223/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2313 - mse: 0.0756 - accuracy: 0.8813 - val_loss: 2.0211 - val_mse: 0.4064 - val_accuracy: 0.5228\n",
      "Epoch 224/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2266 - mse: 0.0746 - accuracy: 0.8854 - val_loss: 2.0540 - val_mse: 0.3940 - val_accuracy: 0.5413\n",
      "Epoch 225/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2203 - mse: 0.0720 - accuracy: 0.8921 - val_loss: 2.2068 - val_mse: 0.4331 - val_accuracy: 0.4728\n",
      "Epoch 226/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2331 - mse: 0.0759 - accuracy: 0.8859 - val_loss: 1.9321 - val_mse: 0.3874 - val_accuracy: 0.5435\n",
      "Epoch 227/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2309 - mse: 0.0747 - accuracy: 0.8864 - val_loss: 1.9163 - val_mse: 0.3783 - val_accuracy: 0.5511\n",
      "Epoch 228/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2284 - mse: 0.0747 - accuracy: 0.8835 - val_loss: 1.9562 - val_mse: 0.3914 - val_accuracy: 0.5272\n",
      "Epoch 229/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2210 - mse: 0.0718 - accuracy: 0.8919 - val_loss: 2.0442 - val_mse: 0.4002 - val_accuracy: 0.5283\n",
      "Epoch 230/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2283 - mse: 0.0749 - accuracy: 0.8832 - val_loss: 1.8468 - val_mse: 0.3819 - val_accuracy: 0.5380\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2257 - mse: 0.0737 - accuracy: 0.8856 - val_loss: 1.9732 - val_mse: 0.3955 - val_accuracy: 0.5413\n",
      "Epoch 232/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2192 - mse: 0.0715 - accuracy: 0.8886 - val_loss: 1.7858 - val_mse: 0.3744 - val_accuracy: 0.5587\n",
      "Epoch 233/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2182 - mse: 0.0710 - accuracy: 0.8905 - val_loss: 1.9613 - val_mse: 0.4007 - val_accuracy: 0.5239\n",
      "Epoch 234/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2213 - mse: 0.0726 - accuracy: 0.8886 - val_loss: 2.1193 - val_mse: 0.4186 - val_accuracy: 0.5163\n",
      "Epoch 235/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2282 - mse: 0.0750 - accuracy: 0.8840 - val_loss: 1.9238 - val_mse: 0.3813 - val_accuracy: 0.5402\n",
      "Epoch 236/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2186 - mse: 0.0718 - accuracy: 0.8902 - val_loss: 2.2365 - val_mse: 0.3998 - val_accuracy: 0.5370\n",
      "Epoch 237/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2213 - mse: 0.0734 - accuracy: 0.8864 - val_loss: 1.9806 - val_mse: 0.3919 - val_accuracy: 0.5326\n",
      "Epoch 238/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2201 - mse: 0.0723 - accuracy: 0.8864 - val_loss: 1.8572 - val_mse: 0.3741 - val_accuracy: 0.5424\n",
      "Epoch 239/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2156 - mse: 0.0714 - accuracy: 0.8845 - val_loss: 2.0294 - val_mse: 0.3967 - val_accuracy: 0.5326\n",
      "Epoch 240/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2209 - mse: 0.0729 - accuracy: 0.8851 - val_loss: 1.9812 - val_mse: 0.3854 - val_accuracy: 0.5435\n",
      "Epoch 241/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2210 - mse: 0.0726 - accuracy: 0.8894 - val_loss: 2.5136 - val_mse: 0.4308 - val_accuracy: 0.5141\n",
      "Epoch 242/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2202 - mse: 0.0722 - accuracy: 0.8870 - val_loss: 1.9560 - val_mse: 0.3864 - val_accuracy: 0.5402\n",
      "Epoch 243/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2284 - mse: 0.0751 - accuracy: 0.8810 - val_loss: 1.9412 - val_mse: 0.3951 - val_accuracy: 0.5239\n",
      "Epoch 244/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2253 - mse: 0.0733 - accuracy: 0.8862 - val_loss: 2.0338 - val_mse: 0.3850 - val_accuracy: 0.5467\n",
      "Epoch 245/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2095 - mse: 0.0692 - accuracy: 0.8916 - val_loss: 2.2051 - val_mse: 0.4206 - val_accuracy: 0.5043\n",
      "Epoch 246/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2127 - mse: 0.0700 - accuracy: 0.8905 - val_loss: 2.4340 - val_mse: 0.4292 - val_accuracy: 0.5120\n",
      "Epoch 247/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2314 - mse: 0.0759 - accuracy: 0.8799 - val_loss: 2.1169 - val_mse: 0.4034 - val_accuracy: 0.5348\n",
      "Epoch 248/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2238 - mse: 0.0733 - accuracy: 0.8845 - val_loss: 1.8761 - val_mse: 0.3833 - val_accuracy: 0.5370\n",
      "Epoch 249/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2201 - mse: 0.0719 - accuracy: 0.8878 - val_loss: 2.0219 - val_mse: 0.4058 - val_accuracy: 0.5185\n",
      "Epoch 250/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2178 - mse: 0.0719 - accuracy: 0.8854 - val_loss: 1.9878 - val_mse: 0.3848 - val_accuracy: 0.5413\n",
      "Epoch 251/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2146 - mse: 0.0711 - accuracy: 0.8873 - val_loss: 1.9792 - val_mse: 0.3964 - val_accuracy: 0.5359\n",
      "Epoch 252/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2125 - mse: 0.0708 - accuracy: 0.8864 - val_loss: 2.0145 - val_mse: 0.3864 - val_accuracy: 0.5402\n",
      "Epoch 253/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2131 - mse: 0.0704 - accuracy: 0.8875 - val_loss: 2.0253 - val_mse: 0.3905 - val_accuracy: 0.5435\n",
      "Epoch 254/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2139 - mse: 0.0712 - accuracy: 0.8859 - val_loss: 1.9027 - val_mse: 0.3737 - val_accuracy: 0.5533\n",
      "Epoch 255/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2294 - mse: 0.0759 - accuracy: 0.8810 - val_loss: 1.7771 - val_mse: 0.3577 - val_accuracy: 0.5630\n",
      "Epoch 256/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2167 - mse: 0.0716 - accuracy: 0.8875 - val_loss: 1.9532 - val_mse: 0.3778 - val_accuracy: 0.5478\n",
      "Epoch 257/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2113 - mse: 0.0705 - accuracy: 0.8867 - val_loss: 2.0642 - val_mse: 0.3881 - val_accuracy: 0.5380\n",
      "Epoch 258/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2120 - mse: 0.0707 - accuracy: 0.8845 - val_loss: 1.9975 - val_mse: 0.3802 - val_accuracy: 0.5370\n",
      "Epoch 259/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2185 - mse: 0.0715 - accuracy: 0.8840 - val_loss: 2.2680 - val_mse: 0.4209 - val_accuracy: 0.4728\n",
      "Epoch 260/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2225 - mse: 0.0735 - accuracy: 0.8886 - val_loss: 2.0448 - val_mse: 0.3881 - val_accuracy: 0.5337\n",
      "Epoch 261/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2224 - mse: 0.0729 - accuracy: 0.8832 - val_loss: 1.9612 - val_mse: 0.3923 - val_accuracy: 0.5250\n",
      "Epoch 262/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2103 - mse: 0.0704 - accuracy: 0.8837 - val_loss: 2.2809 - val_mse: 0.4106 - val_accuracy: 0.5239\n",
      "Epoch 263/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2158 - mse: 0.0720 - accuracy: 0.8864 - val_loss: 2.2006 - val_mse: 0.4075 - val_accuracy: 0.5163\n",
      "Epoch 264/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2104 - mse: 0.0695 - accuracy: 0.8854 - val_loss: 2.1945 - val_mse: 0.3885 - val_accuracy: 0.5554\n",
      "Epoch 265/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2136 - mse: 0.0711 - accuracy: 0.8889 - val_loss: 2.0672 - val_mse: 0.3934 - val_accuracy: 0.5326\n",
      "Epoch 266/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2072 - mse: 0.0685 - accuracy: 0.8908 - val_loss: 2.4878 - val_mse: 0.4339 - val_accuracy: 0.4891\n",
      "Epoch 267/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2182 - mse: 0.0721 - accuracy: 0.8851 - val_loss: 1.9829 - val_mse: 0.3861 - val_accuracy: 0.5326\n",
      "Epoch 268/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2189 - mse: 0.0722 - accuracy: 0.8873 - val_loss: 2.1427 - val_mse: 0.4000 - val_accuracy: 0.5304\n",
      "Epoch 269/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2212 - mse: 0.0734 - accuracy: 0.8761 - val_loss: 2.2679 - val_mse: 0.3984 - val_accuracy: 0.5554\n",
      "Epoch 270/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2122 - mse: 0.0710 - accuracy: 0.8867 - val_loss: 2.0154 - val_mse: 0.3782 - val_accuracy: 0.5511\n",
      "Epoch 271/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2112 - mse: 0.0701 - accuracy: 0.8902 - val_loss: 2.2284 - val_mse: 0.3958 - val_accuracy: 0.5446\n",
      "Epoch 272/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2089 - mse: 0.0695 - accuracy: 0.8897 - val_loss: 2.3416 - val_mse: 0.4274 - val_accuracy: 0.4674\n",
      "Epoch 273/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2125 - mse: 0.0700 - accuracy: 0.8938 - val_loss: 2.2422 - val_mse: 0.3975 - val_accuracy: 0.5500\n",
      "Epoch 274/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2011 - mse: 0.0673 - accuracy: 0.8932 - val_loss: 2.3194 - val_mse: 0.4109 - val_accuracy: 0.5304\n",
      "Epoch 275/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2182 - mse: 0.0720 - accuracy: 0.8878 - val_loss: 2.1434 - val_mse: 0.4000 - val_accuracy: 0.5207\n",
      "Epoch 276/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2000 - mse: 0.0672 - accuracy: 0.8916 - val_loss: 2.3060 - val_mse: 0.4176 - val_accuracy: 0.5196\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2131 - mse: 0.0697 - accuracy: 0.8927 - val_loss: 2.1221 - val_mse: 0.3816 - val_accuracy: 0.5435\n",
      "Epoch 278/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2089 - mse: 0.0698 - accuracy: 0.8883 - val_loss: 2.1503 - val_mse: 0.3910 - val_accuracy: 0.5239\n",
      "Epoch 279/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2093 - mse: 0.0703 - accuracy: 0.8875 - val_loss: 2.1412 - val_mse: 0.3968 - val_accuracy: 0.5130\n",
      "Epoch 280/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2253 - mse: 0.0741 - accuracy: 0.8829 - val_loss: 2.1924 - val_mse: 0.4009 - val_accuracy: 0.5337\n",
      "Epoch 281/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2119 - mse: 0.0711 - accuracy: 0.8851 - val_loss: 2.0274 - val_mse: 0.3868 - val_accuracy: 0.5370\n",
      "Epoch 282/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2057 - mse: 0.0693 - accuracy: 0.8851 - val_loss: 2.3671 - val_mse: 0.4231 - val_accuracy: 0.5011\n",
      "Epoch 283/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2095 - mse: 0.0692 - accuracy: 0.8935 - val_loss: 2.4993 - val_mse: 0.4219 - val_accuracy: 0.5207\n",
      "Epoch 284/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2065 - mse: 0.0692 - accuracy: 0.8859 - val_loss: 2.1268 - val_mse: 0.3810 - val_accuracy: 0.5641\n",
      "Epoch 285/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2128 - mse: 0.0713 - accuracy: 0.8873 - val_loss: 2.2803 - val_mse: 0.4081 - val_accuracy: 0.5250\n",
      "Epoch 286/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.2110 - mse: 0.0701 - accuracy: 0.8916 - val_loss: 2.1494 - val_mse: 0.3963 - val_accuracy: 0.5239\n",
      "Epoch 287/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2060 - mse: 0.0694 - accuracy: 0.8856 - val_loss: 2.2982 - val_mse: 0.4047 - val_accuracy: 0.5120\n",
      "Epoch 288/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.2091 - mse: 0.0703 - accuracy: 0.8864 - val_loss: 2.1958 - val_mse: 0.4019 - val_accuracy: 0.5163\n",
      "Epoch 289/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2008 - mse: 0.0671 - accuracy: 0.8921 - val_loss: 2.3655 - val_mse: 0.4071 - val_accuracy: 0.5207\n",
      "Epoch 290/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2134 - mse: 0.0714 - accuracy: 0.8840 - val_loss: 2.1084 - val_mse: 0.3798 - val_accuracy: 0.5522\n",
      "Epoch 291/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2081 - mse: 0.0694 - accuracy: 0.8883 - val_loss: 2.2626 - val_mse: 0.3997 - val_accuracy: 0.5261\n",
      "Epoch 292/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1999 - mse: 0.0677 - accuracy: 0.8927 - val_loss: 2.3897 - val_mse: 0.4104 - val_accuracy: 0.5163\n",
      "Epoch 293/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2063 - mse: 0.0691 - accuracy: 0.8913 - val_loss: 2.1230 - val_mse: 0.3863 - val_accuracy: 0.5402\n",
      "Epoch 294/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2098 - mse: 0.0703 - accuracy: 0.8873 - val_loss: 2.6400 - val_mse: 0.4332 - val_accuracy: 0.4707\n",
      "Epoch 295/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2123 - mse: 0.0709 - accuracy: 0.8878 - val_loss: 2.5237 - val_mse: 0.4202 - val_accuracy: 0.5152\n",
      "Epoch 296/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2004 - mse: 0.0673 - accuracy: 0.8919 - val_loss: 2.4279 - val_mse: 0.4116 - val_accuracy: 0.5207\n",
      "Epoch 297/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2015 - mse: 0.0682 - accuracy: 0.8913 - val_loss: 2.3950 - val_mse: 0.4090 - val_accuracy: 0.5304\n",
      "Epoch 298/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1972 - mse: 0.0668 - accuracy: 0.8943 - val_loss: 2.3446 - val_mse: 0.4002 - val_accuracy: 0.5446\n",
      "Epoch 299/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2101 - mse: 0.0695 - accuracy: 0.8902 - val_loss: 2.4996 - val_mse: 0.4222 - val_accuracy: 0.5033\n",
      "Epoch 300/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2046 - mse: 0.0687 - accuracy: 0.8905 - val_loss: 2.3346 - val_mse: 0.4084 - val_accuracy: 0.5120\n",
      "Epoch 301/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2047 - mse: 0.0687 - accuracy: 0.8878 - val_loss: 2.5153 - val_mse: 0.4243 - val_accuracy: 0.5109\n",
      "Epoch 302/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2094 - mse: 0.0691 - accuracy: 0.8921 - val_loss: 2.2395 - val_mse: 0.3801 - val_accuracy: 0.5533\n",
      "Epoch 303/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2046 - mse: 0.0693 - accuracy: 0.8881 - val_loss: 2.2051 - val_mse: 0.3818 - val_accuracy: 0.5467\n",
      "Epoch 304/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2021 - mse: 0.0682 - accuracy: 0.8894 - val_loss: 2.6157 - val_mse: 0.4212 - val_accuracy: 0.5261\n",
      "Epoch 305/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1973 - mse: 0.0663 - accuracy: 0.8935 - val_loss: 2.3492 - val_mse: 0.3880 - val_accuracy: 0.5478\n",
      "Epoch 306/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2058 - mse: 0.0687 - accuracy: 0.8886 - val_loss: 2.3362 - val_mse: 0.3987 - val_accuracy: 0.5152\n",
      "Epoch 307/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2065 - mse: 0.0692 - accuracy: 0.8848 - val_loss: 2.2392 - val_mse: 0.3941 - val_accuracy: 0.5402\n",
      "Epoch 308/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2062 - mse: 0.0690 - accuracy: 0.8878 - val_loss: 2.3205 - val_mse: 0.3955 - val_accuracy: 0.5283\n",
      "Epoch 309/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2056 - mse: 0.0690 - accuracy: 0.8908 - val_loss: 2.3663 - val_mse: 0.3945 - val_accuracy: 0.5380\n",
      "Epoch 310/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1994 - mse: 0.0676 - accuracy: 0.8843 - val_loss: 2.5457 - val_mse: 0.4120 - val_accuracy: 0.5239\n",
      "Epoch 311/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2039 - mse: 0.0684 - accuracy: 0.8905 - val_loss: 2.5135 - val_mse: 0.4169 - val_accuracy: 0.5217\n",
      "Epoch 312/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2003 - mse: 0.0674 - accuracy: 0.8921 - val_loss: 2.3627 - val_mse: 0.3969 - val_accuracy: 0.5174\n",
      "Epoch 313/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2051 - mse: 0.0690 - accuracy: 0.8900 - val_loss: 2.1558 - val_mse: 0.3793 - val_accuracy: 0.5424\n",
      "Epoch 314/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2046 - mse: 0.0686 - accuracy: 0.8886 - val_loss: 2.3110 - val_mse: 0.3903 - val_accuracy: 0.5446\n",
      "Epoch 315/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2025 - mse: 0.0688 - accuracy: 0.8892 - val_loss: 2.3474 - val_mse: 0.4025 - val_accuracy: 0.5239\n",
      "Epoch 316/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1972 - mse: 0.0665 - accuracy: 0.8911 - val_loss: 2.5161 - val_mse: 0.4096 - val_accuracy: 0.5207\n",
      "Epoch 317/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2077 - mse: 0.0695 - accuracy: 0.8892 - val_loss: 2.4522 - val_mse: 0.4170 - val_accuracy: 0.5054\n",
      "Epoch 318/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2096 - mse: 0.0701 - accuracy: 0.8889 - val_loss: 2.4037 - val_mse: 0.4050 - val_accuracy: 0.5196\n",
      "Epoch 319/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1972 - mse: 0.0662 - accuracy: 0.8976 - val_loss: 2.2972 - val_mse: 0.4002 - val_accuracy: 0.5152\n",
      "Epoch 320/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1967 - mse: 0.0661 - accuracy: 0.8938 - val_loss: 2.4667 - val_mse: 0.3987 - val_accuracy: 0.5272\n",
      "Epoch 321/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1956 - mse: 0.0662 - accuracy: 0.8913 - val_loss: 2.2633 - val_mse: 0.3838 - val_accuracy: 0.5380\n",
      "Epoch 322/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1902 - mse: 0.0647 - accuracy: 0.8965 - val_loss: 2.5207 - val_mse: 0.4094 - val_accuracy: 0.5239\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1954 - mse: 0.0658 - accuracy: 0.8981 - val_loss: 2.5733 - val_mse: 0.4142 - val_accuracy: 0.5217\n",
      "Epoch 324/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2043 - mse: 0.0681 - accuracy: 0.8911 - val_loss: 2.4720 - val_mse: 0.4019 - val_accuracy: 0.5250\n",
      "Epoch 325/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1967 - mse: 0.0657 - accuracy: 0.8927 - val_loss: 2.2852 - val_mse: 0.3917 - val_accuracy: 0.5370\n",
      "Epoch 326/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1918 - mse: 0.0646 - accuracy: 0.8968 - val_loss: 2.5015 - val_mse: 0.3997 - val_accuracy: 0.5283\n",
      "Epoch 327/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1963 - mse: 0.0658 - accuracy: 0.8943 - val_loss: 2.3630 - val_mse: 0.4067 - val_accuracy: 0.5174\n",
      "Epoch 328/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1986 - mse: 0.0669 - accuracy: 0.8916 - val_loss: 2.5961 - val_mse: 0.4036 - val_accuracy: 0.5337\n",
      "Epoch 329/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2041 - mse: 0.0689 - accuracy: 0.8902 - val_loss: 2.3035 - val_mse: 0.3917 - val_accuracy: 0.5283\n",
      "Epoch 330/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1982 - mse: 0.0673 - accuracy: 0.8881 - val_loss: 2.5060 - val_mse: 0.4078 - val_accuracy: 0.5109\n",
      "Epoch 331/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1989 - mse: 0.0670 - accuracy: 0.8924 - val_loss: 2.3124 - val_mse: 0.3954 - val_accuracy: 0.5239\n",
      "Epoch 332/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1897 - mse: 0.0644 - accuracy: 0.8973 - val_loss: 2.5087 - val_mse: 0.4038 - val_accuracy: 0.5217\n",
      "Epoch 333/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2088 - mse: 0.0698 - accuracy: 0.8867 - val_loss: 2.4603 - val_mse: 0.4037 - val_accuracy: 0.5261\n",
      "Epoch 334/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1953 - mse: 0.0654 - accuracy: 0.8968 - val_loss: 2.5628 - val_mse: 0.4082 - val_accuracy: 0.5163\n",
      "Epoch 335/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1934 - mse: 0.0653 - accuracy: 0.8930 - val_loss: 2.7765 - val_mse: 0.4146 - val_accuracy: 0.5152\n",
      "Epoch 336/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1918 - mse: 0.0644 - accuracy: 0.8957 - val_loss: 2.6568 - val_mse: 0.4204 - val_accuracy: 0.4989\n",
      "Epoch 337/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1956 - mse: 0.0656 - accuracy: 0.8976 - val_loss: 2.3877 - val_mse: 0.3938 - val_accuracy: 0.5326\n",
      "Epoch 338/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1959 - mse: 0.0661 - accuracy: 0.8938 - val_loss: 2.5801 - val_mse: 0.4088 - val_accuracy: 0.5196\n",
      "Epoch 339/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1963 - mse: 0.0663 - accuracy: 0.8927 - val_loss: 2.3073 - val_mse: 0.3834 - val_accuracy: 0.5359\n",
      "Epoch 340/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1929 - mse: 0.0649 - accuracy: 0.8965 - val_loss: 2.7958 - val_mse: 0.4290 - val_accuracy: 0.5196\n",
      "Epoch 341/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1946 - mse: 0.0653 - accuracy: 0.8935 - val_loss: 2.5787 - val_mse: 0.4015 - val_accuracy: 0.5391\n",
      "Epoch 342/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1884 - mse: 0.0638 - accuracy: 0.8946 - val_loss: 2.6082 - val_mse: 0.4074 - val_accuracy: 0.5272\n",
      "Epoch 343/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1936 - mse: 0.0654 - accuracy: 0.8905 - val_loss: 2.7059 - val_mse: 0.4170 - val_accuracy: 0.5109\n",
      "Epoch 344/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1915 - mse: 0.0647 - accuracy: 0.8962 - val_loss: 2.5140 - val_mse: 0.4011 - val_accuracy: 0.5250\n",
      "Epoch 345/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1890 - mse: 0.0643 - accuracy: 0.8979 - val_loss: 2.8221 - val_mse: 0.4275 - val_accuracy: 0.5033\n",
      "Epoch 346/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1919 - mse: 0.0650 - accuracy: 0.8930 - val_loss: 2.5830 - val_mse: 0.4166 - val_accuracy: 0.5076\n",
      "Epoch 347/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1956 - mse: 0.0666 - accuracy: 0.8886 - val_loss: 2.5618 - val_mse: 0.4120 - val_accuracy: 0.5163\n",
      "Epoch 348/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1899 - mse: 0.0642 - accuracy: 0.8995 - val_loss: 2.6282 - val_mse: 0.3848 - val_accuracy: 0.5543\n",
      "Epoch 349/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1961 - mse: 0.0667 - accuracy: 0.8932 - val_loss: 2.6634 - val_mse: 0.4028 - val_accuracy: 0.5370\n",
      "Epoch 350/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1928 - mse: 0.0653 - accuracy: 0.8938 - val_loss: 2.6981 - val_mse: 0.4046 - val_accuracy: 0.5337\n",
      "Epoch 351/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1965 - mse: 0.0655 - accuracy: 0.8913 - val_loss: 2.5200 - val_mse: 0.4002 - val_accuracy: 0.5413\n",
      "Epoch 352/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1967 - mse: 0.0659 - accuracy: 0.8951 - val_loss: 2.6678 - val_mse: 0.4048 - val_accuracy: 0.5304\n",
      "Epoch 353/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2021 - mse: 0.0672 - accuracy: 0.8957 - val_loss: 2.6600 - val_mse: 0.3954 - val_accuracy: 0.5435\n",
      "Epoch 354/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1885 - mse: 0.0643 - accuracy: 0.8951 - val_loss: 2.4904 - val_mse: 0.3903 - val_accuracy: 0.5446\n",
      "Epoch 355/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1947 - mse: 0.0654 - accuracy: 0.8943 - val_loss: 2.8105 - val_mse: 0.4179 - val_accuracy: 0.5207\n",
      "Epoch 356/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1960 - mse: 0.0657 - accuracy: 0.8951 - val_loss: 2.7982 - val_mse: 0.4207 - val_accuracy: 0.5217\n",
      "Epoch 357/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1881 - mse: 0.0639 - accuracy: 0.8932 - val_loss: 2.7703 - val_mse: 0.4182 - val_accuracy: 0.5141\n",
      "Epoch 358/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1937 - mse: 0.0657 - accuracy: 0.8889 - val_loss: 2.7319 - val_mse: 0.4228 - val_accuracy: 0.5033\n",
      "Epoch 359/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1915 - mse: 0.0650 - accuracy: 0.8973 - val_loss: 2.6342 - val_mse: 0.3949 - val_accuracy: 0.5467\n",
      "Epoch 360/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1877 - mse: 0.0638 - accuracy: 0.8954 - val_loss: 2.8184 - val_mse: 0.4148 - val_accuracy: 0.5228\n",
      "Epoch 361/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1921 - mse: 0.0648 - accuracy: 0.8946 - val_loss: 2.7492 - val_mse: 0.4237 - val_accuracy: 0.5022\n",
      "Epoch 362/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1872 - mse: 0.0635 - accuracy: 0.8981 - val_loss: 2.7990 - val_mse: 0.4220 - val_accuracy: 0.5065\n",
      "Epoch 363/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1854 - mse: 0.0637 - accuracy: 0.8949 - val_loss: 2.4924 - val_mse: 0.3898 - val_accuracy: 0.5283\n",
      "Epoch 364/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2026 - mse: 0.0678 - accuracy: 0.8902 - val_loss: 2.5395 - val_mse: 0.3973 - val_accuracy: 0.5217\n",
      "Epoch 365/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1937 - mse: 0.0649 - accuracy: 0.8968 - val_loss: 2.6825 - val_mse: 0.4150 - val_accuracy: 0.5000\n",
      "Epoch 366/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1998 - mse: 0.0661 - accuracy: 0.8932 - val_loss: 2.5156 - val_mse: 0.3867 - val_accuracy: 0.5478\n",
      "Epoch 367/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1982 - mse: 0.0655 - accuracy: 0.9008 - val_loss: 2.9270 - val_mse: 0.4314 - val_accuracy: 0.5087\n",
      "Epoch 368/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.2007 - mse: 0.0675 - accuracy: 0.8892 - val_loss: 2.4652 - val_mse: 0.4133 - val_accuracy: 0.4978\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1883 - mse: 0.0642 - accuracy: 0.8954 - val_loss: 2.5476 - val_mse: 0.3868 - val_accuracy: 0.5576\n",
      "Epoch 370/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1877 - mse: 0.0637 - accuracy: 0.8943 - val_loss: 2.8994 - val_mse: 0.4178 - val_accuracy: 0.5152\n",
      "Epoch 371/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1857 - mse: 0.0632 - accuracy: 0.8962 - val_loss: 2.6991 - val_mse: 0.4073 - val_accuracy: 0.5326\n",
      "Epoch 372/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1860 - mse: 0.0623 - accuracy: 0.8992 - val_loss: 2.7676 - val_mse: 0.4094 - val_accuracy: 0.5272\n",
      "Epoch 373/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1867 - mse: 0.0636 - accuracy: 0.8960 - val_loss: 2.7070 - val_mse: 0.3969 - val_accuracy: 0.5380\n",
      "Epoch 374/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1920 - mse: 0.0645 - accuracy: 0.8970 - val_loss: 2.6900 - val_mse: 0.4099 - val_accuracy: 0.5185\n",
      "Epoch 375/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2016 - mse: 0.0675 - accuracy: 0.8916 - val_loss: 2.8889 - val_mse: 0.4167 - val_accuracy: 0.5293\n",
      "Epoch 376/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2110 - mse: 0.0679 - accuracy: 0.8905 - val_loss: 2.5865 - val_mse: 0.4098 - val_accuracy: 0.5174\n",
      "Epoch 377/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1896 - mse: 0.0640 - accuracy: 0.8962 - val_loss: 2.9158 - val_mse: 0.4392 - val_accuracy: 0.4989\n",
      "Epoch 378/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1943 - mse: 0.0661 - accuracy: 0.8908 - val_loss: 2.5988 - val_mse: 0.4028 - val_accuracy: 0.5326\n",
      "Epoch 379/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.0630 - accuracy: 0.9017 - val_loss: 2.7141 - val_mse: 0.4189 - val_accuracy: 0.5054\n",
      "Epoch 380/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1822 - mse: 0.0621 - accuracy: 0.8962 - val_loss: 2.6961 - val_mse: 0.4165 - val_accuracy: 0.5152\n",
      "Epoch 381/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1856 - mse: 0.0628 - accuracy: 0.8979 - val_loss: 2.7913 - val_mse: 0.4178 - val_accuracy: 0.5076\n",
      "Epoch 382/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1901 - mse: 0.0635 - accuracy: 0.8970 - val_loss: 2.7398 - val_mse: 0.4080 - val_accuracy: 0.5261\n",
      "Epoch 383/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1858 - mse: 0.0632 - accuracy: 0.8970 - val_loss: 2.6349 - val_mse: 0.4000 - val_accuracy: 0.5261\n",
      "Epoch 384/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1885 - mse: 0.0636 - accuracy: 0.8930 - val_loss: 2.4659 - val_mse: 0.3915 - val_accuracy: 0.5391\n",
      "Epoch 385/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1817 - mse: 0.0616 - accuracy: 0.9019 - val_loss: 2.7662 - val_mse: 0.4111 - val_accuracy: 0.5228\n",
      "Epoch 386/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1866 - mse: 0.0639 - accuracy: 0.8949 - val_loss: 2.8490 - val_mse: 0.4031 - val_accuracy: 0.5435\n",
      "Epoch 387/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1867 - mse: 0.0638 - accuracy: 0.8965 - val_loss: 2.9915 - val_mse: 0.4258 - val_accuracy: 0.5130\n",
      "Epoch 388/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2033 - mse: 0.0681 - accuracy: 0.8919 - val_loss: 2.8246 - val_mse: 0.4252 - val_accuracy: 0.5120\n",
      "Epoch 389/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1920 - mse: 0.0655 - accuracy: 0.8913 - val_loss: 2.8175 - val_mse: 0.4188 - val_accuracy: 0.5250\n",
      "Epoch 390/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1893 - mse: 0.0642 - accuracy: 0.8919 - val_loss: 2.7431 - val_mse: 0.4089 - val_accuracy: 0.5217\n",
      "Epoch 391/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1943 - mse: 0.0658 - accuracy: 0.8951 - val_loss: 2.7983 - val_mse: 0.4193 - val_accuracy: 0.5250\n",
      "Epoch 392/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1915 - mse: 0.0647 - accuracy: 0.8984 - val_loss: 3.0445 - val_mse: 0.4338 - val_accuracy: 0.5054\n",
      "Epoch 393/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1809 - mse: 0.0615 - accuracy: 0.8984 - val_loss: 2.9327 - val_mse: 0.4303 - val_accuracy: 0.5065\n",
      "Epoch 394/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1880 - mse: 0.0641 - accuracy: 0.8965 - val_loss: 2.9045 - val_mse: 0.4234 - val_accuracy: 0.4978\n",
      "Epoch 395/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1887 - mse: 0.0643 - accuracy: 0.8979 - val_loss: 2.8589 - val_mse: 0.4033 - val_accuracy: 0.5326\n",
      "Epoch 396/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1892 - mse: 0.0640 - accuracy: 0.8957 - val_loss: 2.6892 - val_mse: 0.4130 - val_accuracy: 0.5120\n",
      "Epoch 397/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1957 - mse: 0.0650 - accuracy: 0.8992 - val_loss: 2.5253 - val_mse: 0.3859 - val_accuracy: 0.5467\n",
      "Epoch 398/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1852 - mse: 0.0629 - accuracy: 0.8930 - val_loss: 2.8339 - val_mse: 0.4054 - val_accuracy: 0.5293\n",
      "Epoch 399/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1781 - mse: 0.0611 - accuracy: 0.9003 - val_loss: 2.6550 - val_mse: 0.4077 - val_accuracy: 0.5217\n",
      "Epoch 400/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1906 - mse: 0.0646 - accuracy: 0.8943 - val_loss: 2.8622 - val_mse: 0.4213 - val_accuracy: 0.5098\n",
      "Epoch 401/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1922 - mse: 0.0653 - accuracy: 0.8943 - val_loss: 2.4980 - val_mse: 0.3948 - val_accuracy: 0.5185\n",
      "Epoch 402/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1817 - mse: 0.0618 - accuracy: 0.9019 - val_loss: 2.8070 - val_mse: 0.4208 - val_accuracy: 0.4978\n",
      "Epoch 403/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1878 - mse: 0.0636 - accuracy: 0.8965 - val_loss: 3.0883 - val_mse: 0.4320 - val_accuracy: 0.5022\n",
      "Epoch 404/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2007 - mse: 0.0666 - accuracy: 0.8941 - val_loss: 2.6309 - val_mse: 0.3994 - val_accuracy: 0.5207\n",
      "Epoch 405/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1864 - mse: 0.0642 - accuracy: 0.8908 - val_loss: 2.3960 - val_mse: 0.3949 - val_accuracy: 0.5207\n",
      "Epoch 406/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1850 - mse: 0.0631 - accuracy: 0.8954 - val_loss: 2.5509 - val_mse: 0.3832 - val_accuracy: 0.5402\n",
      "Epoch 407/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1839 - mse: 0.0627 - accuracy: 0.8987 - val_loss: 2.9839 - val_mse: 0.4114 - val_accuracy: 0.5239\n",
      "Epoch 408/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1813 - mse: 0.0615 - accuracy: 0.8984 - val_loss: 2.9379 - val_mse: 0.4127 - val_accuracy: 0.5272\n",
      "Epoch 409/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1915 - mse: 0.0653 - accuracy: 0.8954 - val_loss: 3.0307 - val_mse: 0.4267 - val_accuracy: 0.5076\n",
      "Epoch 410/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1769 - mse: 0.0606 - accuracy: 0.9003 - val_loss: 2.9380 - val_mse: 0.4150 - val_accuracy: 0.5207\n",
      "Epoch 411/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1920 - mse: 0.0647 - accuracy: 0.9006 - val_loss: 3.0976 - val_mse: 0.3914 - val_accuracy: 0.5620\n",
      "Epoch 412/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1973 - mse: 0.0643 - accuracy: 0.8973 - val_loss: 2.7111 - val_mse: 0.3899 - val_accuracy: 0.5457\n",
      "Epoch 413/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1797 - mse: 0.0618 - accuracy: 0.8954 - val_loss: 2.8836 - val_mse: 0.4307 - val_accuracy: 0.5011\n",
      "Epoch 414/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1869 - mse: 0.0634 - accuracy: 0.8941 - val_loss: 2.5884 - val_mse: 0.3963 - val_accuracy: 0.5250\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1774 - mse: 0.0604 - accuracy: 0.8976 - val_loss: 2.7707 - val_mse: 0.3992 - val_accuracy: 0.5348\n",
      "Epoch 416/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1861 - mse: 0.0631 - accuracy: 0.8981 - val_loss: 3.0665 - val_mse: 0.4192 - val_accuracy: 0.5174\n",
      "Epoch 417/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1782 - mse: 0.0615 - accuracy: 0.8962 - val_loss: 2.7641 - val_mse: 0.4023 - val_accuracy: 0.5163\n",
      "Epoch 418/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1837 - mse: 0.0630 - accuracy: 0.8960 - val_loss: 2.8175 - val_mse: 0.4041 - val_accuracy: 0.5207\n",
      "Epoch 419/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1966 - mse: 0.0660 - accuracy: 0.8951 - val_loss: 2.8904 - val_mse: 0.4204 - val_accuracy: 0.5043\n",
      "Epoch 420/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1991 - mse: 0.0665 - accuracy: 0.8962 - val_loss: 2.8286 - val_mse: 0.3967 - val_accuracy: 0.5326\n",
      "Epoch 421/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1844 - mse: 0.0626 - accuracy: 0.8973 - val_loss: 2.7723 - val_mse: 0.4078 - val_accuracy: 0.5261\n",
      "Epoch 422/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1783 - mse: 0.0614 - accuracy: 0.8968 - val_loss: 2.9188 - val_mse: 0.4093 - val_accuracy: 0.5228\n",
      "Epoch 423/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1783 - mse: 0.0611 - accuracy: 0.8998 - val_loss: 3.0482 - val_mse: 0.4055 - val_accuracy: 0.5315\n",
      "Epoch 424/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1892 - mse: 0.0628 - accuracy: 0.8987 - val_loss: 2.8375 - val_mse: 0.3979 - val_accuracy: 0.5370\n",
      "Epoch 425/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1805 - mse: 0.0617 - accuracy: 0.8979 - val_loss: 2.9544 - val_mse: 0.4043 - val_accuracy: 0.5359\n",
      "Epoch 426/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1873 - mse: 0.0640 - accuracy: 0.8951 - val_loss: 2.9050 - val_mse: 0.4164 - val_accuracy: 0.5054\n",
      "Epoch 427/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1815 - mse: 0.0613 - accuracy: 0.9014 - val_loss: 2.9359 - val_mse: 0.4189 - val_accuracy: 0.5130\n",
      "Epoch 428/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1969 - mse: 0.0658 - accuracy: 0.8962 - val_loss: 2.6690 - val_mse: 0.4207 - val_accuracy: 0.4924\n",
      "Epoch 429/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1827 - mse: 0.0624 - accuracy: 0.8954 - val_loss: 2.9836 - val_mse: 0.4378 - val_accuracy: 0.4891\n",
      "Epoch 430/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1795 - mse: 0.0609 - accuracy: 0.8989 - val_loss: 3.1167 - val_mse: 0.4221 - val_accuracy: 0.5174\n",
      "Epoch 431/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1813 - mse: 0.0618 - accuracy: 0.9003 - val_loss: 2.6432 - val_mse: 0.4115 - val_accuracy: 0.5065\n",
      "Epoch 432/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1753 - mse: 0.0601 - accuracy: 0.9030 - val_loss: 3.0589 - val_mse: 0.4175 - val_accuracy: 0.5304\n",
      "Epoch 433/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1780 - mse: 0.0610 - accuracy: 0.9000 - val_loss: 2.9938 - val_mse: 0.4045 - val_accuracy: 0.5337\n",
      "Epoch 434/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1834 - mse: 0.0626 - accuracy: 0.8984 - val_loss: 3.1753 - val_mse: 0.4291 - val_accuracy: 0.5152\n",
      "Epoch 435/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1777 - mse: 0.0609 - accuracy: 0.9049 - val_loss: 2.9849 - val_mse: 0.4181 - val_accuracy: 0.5141\n",
      "Epoch 436/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1817 - mse: 0.0626 - accuracy: 0.8935 - val_loss: 3.0598 - val_mse: 0.4171 - val_accuracy: 0.5098\n",
      "Epoch 437/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.0629 - accuracy: 0.8984 - val_loss: 3.0439 - val_mse: 0.4033 - val_accuracy: 0.5261\n",
      "Epoch 438/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2012 - mse: 0.0670 - accuracy: 0.8927 - val_loss: 2.8595 - val_mse: 0.3837 - val_accuracy: 0.5739\n",
      "Epoch 439/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1989 - mse: 0.0657 - accuracy: 0.8962 - val_loss: 2.7684 - val_mse: 0.4070 - val_accuracy: 0.5185\n",
      "Epoch 440/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1816 - mse: 0.0617 - accuracy: 0.9017 - val_loss: 2.7499 - val_mse: 0.4030 - val_accuracy: 0.5359\n",
      "Epoch 441/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1802 - mse: 0.0614 - accuracy: 0.8992 - val_loss: 2.9308 - val_mse: 0.4180 - val_accuracy: 0.5043\n",
      "Epoch 442/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1800 - mse: 0.0602 - accuracy: 0.9008 - val_loss: 2.8701 - val_mse: 0.4096 - val_accuracy: 0.5293\n",
      "Epoch 443/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1854 - mse: 0.0630 - accuracy: 0.8935 - val_loss: 2.8500 - val_mse: 0.4106 - val_accuracy: 0.5272\n",
      "Epoch 444/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1789 - mse: 0.0611 - accuracy: 0.8989 - val_loss: 2.7955 - val_mse: 0.4051 - val_accuracy: 0.5283\n",
      "Epoch 445/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1829 - mse: 0.0619 - accuracy: 0.8946 - val_loss: 2.8253 - val_mse: 0.4134 - val_accuracy: 0.5152\n",
      "Epoch 446/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1881 - mse: 0.0637 - accuracy: 0.8965 - val_loss: 2.9316 - val_mse: 0.4114 - val_accuracy: 0.5185\n",
      "Epoch 447/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1733 - mse: 0.0599 - accuracy: 0.8949 - val_loss: 2.8656 - val_mse: 0.3972 - val_accuracy: 0.5370\n",
      "Epoch 448/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1825 - mse: 0.0625 - accuracy: 0.8965 - val_loss: 2.9136 - val_mse: 0.4162 - val_accuracy: 0.5098\n",
      "Epoch 449/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1775 - mse: 0.0609 - accuracy: 0.8973 - val_loss: 2.9028 - val_mse: 0.4046 - val_accuracy: 0.5250\n",
      "Epoch 450/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1774 - mse: 0.0610 - accuracy: 0.8970 - val_loss: 2.7693 - val_mse: 0.4024 - val_accuracy: 0.5141\n",
      "Epoch 451/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1733 - mse: 0.0597 - accuracy: 0.8979 - val_loss: 3.0582 - val_mse: 0.4093 - val_accuracy: 0.5261\n",
      "Epoch 452/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1764 - mse: 0.0609 - accuracy: 0.9003 - val_loss: 3.0220 - val_mse: 0.4142 - val_accuracy: 0.5098\n",
      "Epoch 453/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1769 - mse: 0.0609 - accuracy: 0.8970 - val_loss: 3.0450 - val_mse: 0.4181 - val_accuracy: 0.5141\n",
      "Epoch 454/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1909 - mse: 0.0649 - accuracy: 0.8941 - val_loss: 3.1192 - val_mse: 0.4329 - val_accuracy: 0.5033\n",
      "Epoch 455/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1818 - mse: 0.0621 - accuracy: 0.8976 - val_loss: 3.2295 - val_mse: 0.4295 - val_accuracy: 0.4978\n",
      "Epoch 456/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1827 - mse: 0.0619 - accuracy: 0.8995 - val_loss: 2.7565 - val_mse: 0.3854 - val_accuracy: 0.5522\n",
      "Epoch 457/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1805 - mse: 0.0617 - accuracy: 0.8984 - val_loss: 2.9528 - val_mse: 0.4146 - val_accuracy: 0.5130\n",
      "Epoch 458/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1845 - mse: 0.0628 - accuracy: 0.8995 - val_loss: 2.7556 - val_mse: 0.4203 - val_accuracy: 0.4859\n",
      "Epoch 459/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1861 - mse: 0.0629 - accuracy: 0.8935 - val_loss: 3.1242 - val_mse: 0.4201 - val_accuracy: 0.5185\n",
      "Epoch 460/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1867 - mse: 0.0634 - accuracy: 0.9003 - val_loss: 3.2409 - val_mse: 0.4107 - val_accuracy: 0.5380\n",
      "Epoch 461/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1969 - mse: 0.0655 - accuracy: 0.8919 - val_loss: 2.3862 - val_mse: 0.3862 - val_accuracy: 0.5337\n",
      "Epoch 462/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1948 - mse: 0.0662 - accuracy: 0.8913 - val_loss: 3.0839 - val_mse: 0.4193 - val_accuracy: 0.5152\n",
      "Epoch 463/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1753 - mse: 0.0602 - accuracy: 0.9041 - val_loss: 2.8846 - val_mse: 0.4068 - val_accuracy: 0.5228\n",
      "Epoch 464/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1867 - mse: 0.0628 - accuracy: 0.8973 - val_loss: 3.2139 - val_mse: 0.4338 - val_accuracy: 0.5022\n",
      "Epoch 465/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1694 - mse: 0.0584 - accuracy: 0.9055 - val_loss: 2.8746 - val_mse: 0.4139 - val_accuracy: 0.5120\n",
      "Epoch 466/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1758 - mse: 0.0600 - accuracy: 0.9019 - val_loss: 2.9536 - val_mse: 0.3999 - val_accuracy: 0.5457\n",
      "Epoch 467/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1719 - mse: 0.0596 - accuracy: 0.9030 - val_loss: 2.9367 - val_mse: 0.4005 - val_accuracy: 0.5348\n",
      "Epoch 468/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1692 - mse: 0.0583 - accuracy: 0.9044 - val_loss: 3.1873 - val_mse: 0.4179 - val_accuracy: 0.5163\n",
      "Epoch 469/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1748 - mse: 0.0602 - accuracy: 0.8998 - val_loss: 2.8821 - val_mse: 0.4130 - val_accuracy: 0.5348\n",
      "Epoch 470/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1795 - mse: 0.0611 - accuracy: 0.8992 - val_loss: 3.0274 - val_mse: 0.4229 - val_accuracy: 0.5196\n",
      "Epoch 471/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1794 - mse: 0.0613 - accuracy: 0.9008 - val_loss: 2.8795 - val_mse: 0.3873 - val_accuracy: 0.5467\n",
      "Epoch 472/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1881 - mse: 0.0640 - accuracy: 0.8987 - val_loss: 3.0065 - val_mse: 0.4079 - val_accuracy: 0.5402\n",
      "Epoch 473/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1824 - mse: 0.0621 - accuracy: 0.9025 - val_loss: 2.6208 - val_mse: 0.3854 - val_accuracy: 0.5435\n",
      "Epoch 474/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1718 - mse: 0.0593 - accuracy: 0.8995 - val_loss: 2.9511 - val_mse: 0.4056 - val_accuracy: 0.5315\n",
      "Epoch 475/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1788 - mse: 0.0609 - accuracy: 0.9022 - val_loss: 3.1592 - val_mse: 0.4171 - val_accuracy: 0.5217\n",
      "Epoch 476/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1769 - mse: 0.0602 - accuracy: 0.9027 - val_loss: 3.2533 - val_mse: 0.4144 - val_accuracy: 0.5380\n",
      "Epoch 477/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1784 - mse: 0.0610 - accuracy: 0.9011 - val_loss: 3.1366 - val_mse: 0.4258 - val_accuracy: 0.5130\n",
      "Epoch 478/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1759 - mse: 0.0603 - accuracy: 0.9044 - val_loss: 2.8534 - val_mse: 0.4195 - val_accuracy: 0.4967\n",
      "Epoch 479/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1896 - mse: 0.0642 - accuracy: 0.8973 - val_loss: 3.0364 - val_mse: 0.4097 - val_accuracy: 0.5261\n",
      "Epoch 480/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1790 - mse: 0.0613 - accuracy: 0.8987 - val_loss: 3.0909 - val_mse: 0.4173 - val_accuracy: 0.5293\n",
      "Epoch 481/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1810 - mse: 0.0620 - accuracy: 0.8984 - val_loss: 2.9170 - val_mse: 0.3998 - val_accuracy: 0.5293\n",
      "Epoch 482/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1664 - mse: 0.0578 - accuracy: 0.9011 - val_loss: 3.0929 - val_mse: 0.3980 - val_accuracy: 0.5446\n",
      "Epoch 483/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2059 - mse: 0.0696 - accuracy: 0.8864 - val_loss: 3.1463 - val_mse: 0.4043 - val_accuracy: 0.5467\n",
      "Epoch 484/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1808 - mse: 0.0617 - accuracy: 0.8998 - val_loss: 3.0248 - val_mse: 0.4162 - val_accuracy: 0.5207\n",
      "Epoch 485/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1700 - mse: 0.0584 - accuracy: 0.9027 - val_loss: 3.2773 - val_mse: 0.4313 - val_accuracy: 0.5120\n",
      "Epoch 486/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1698 - mse: 0.0581 - accuracy: 0.9027 - val_loss: 3.3016 - val_mse: 0.4245 - val_accuracy: 0.5207\n",
      "Epoch 487/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1757 - mse: 0.0603 - accuracy: 0.9055 - val_loss: 3.0564 - val_mse: 0.4092 - val_accuracy: 0.5337\n",
      "Epoch 488/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1768 - mse: 0.0600 - accuracy: 0.9030 - val_loss: 3.3795 - val_mse: 0.4317 - val_accuracy: 0.5120\n",
      "Epoch 489/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2002 - mse: 0.0666 - accuracy: 0.8927 - val_loss: 3.1001 - val_mse: 0.4185 - val_accuracy: 0.5239\n",
      "Epoch 490/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1741 - mse: 0.0599 - accuracy: 0.9025 - val_loss: 2.6697 - val_mse: 0.3970 - val_accuracy: 0.5272\n",
      "Epoch 491/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1757 - mse: 0.0594 - accuracy: 0.9022 - val_loss: 3.0625 - val_mse: 0.4143 - val_accuracy: 0.5228\n",
      "Epoch 492/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1682 - mse: 0.0581 - accuracy: 0.8992 - val_loss: 3.0554 - val_mse: 0.3934 - val_accuracy: 0.5576\n",
      "Epoch 493/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1750 - mse: 0.0601 - accuracy: 0.9033 - val_loss: 3.0049 - val_mse: 0.4181 - val_accuracy: 0.5174\n",
      "Epoch 494/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1732 - mse: 0.0595 - accuracy: 0.9011 - val_loss: 2.9059 - val_mse: 0.3861 - val_accuracy: 0.5533\n",
      "Epoch 495/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1797 - mse: 0.0610 - accuracy: 0.9027 - val_loss: 3.2371 - val_mse: 0.4246 - val_accuracy: 0.5326\n",
      "Epoch 496/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1828 - mse: 0.0625 - accuracy: 0.8957 - val_loss: 2.9153 - val_mse: 0.4036 - val_accuracy: 0.5424\n",
      "Epoch 497/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1747 - mse: 0.0601 - accuracy: 0.8995 - val_loss: 3.0991 - val_mse: 0.4160 - val_accuracy: 0.5174\n",
      "Epoch 498/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1751 - mse: 0.0595 - accuracy: 0.9041 - val_loss: 3.3265 - val_mse: 0.4388 - val_accuracy: 0.5043\n",
      "Epoch 499/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1934 - mse: 0.0655 - accuracy: 0.8908 - val_loss: 2.7048 - val_mse: 0.3847 - val_accuracy: 0.5620\n",
      "Epoch 500/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1775 - mse: 0.0605 - accuracy: 0.9008 - val_loss: 2.9699 - val_mse: 0.4119 - val_accuracy: 0.5326\n",
      "Epoch 501/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1796 - mse: 0.0611 - accuracy: 0.9033 - val_loss: 2.7666 - val_mse: 0.4004 - val_accuracy: 0.5250\n",
      "Epoch 502/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1748 - mse: 0.0596 - accuracy: 0.9052 - val_loss: 2.9586 - val_mse: 0.4065 - val_accuracy: 0.5283\n",
      "Epoch 503/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1739 - mse: 0.0587 - accuracy: 0.9038 - val_loss: 3.1080 - val_mse: 0.4142 - val_accuracy: 0.5250\n",
      "Epoch 504/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1828 - mse: 0.0613 - accuracy: 0.9036 - val_loss: 2.8635 - val_mse: 0.3958 - val_accuracy: 0.5620\n",
      "Epoch 505/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1750 - mse: 0.0590 - accuracy: 0.9014 - val_loss: 3.2907 - val_mse: 0.4173 - val_accuracy: 0.5283\n",
      "Epoch 506/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1747 - mse: 0.0597 - accuracy: 0.9041 - val_loss: 3.1496 - val_mse: 0.4382 - val_accuracy: 0.4946\n",
      "Epoch 507/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1746 - mse: 0.0595 - accuracy: 0.9027 - val_loss: 2.9715 - val_mse: 0.4092 - val_accuracy: 0.5217\n",
      "Epoch 508/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1825 - mse: 0.0610 - accuracy: 0.8979 - val_loss: 3.1318 - val_mse: 0.4192 - val_accuracy: 0.5196\n",
      "Epoch 509/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1707 - mse: 0.0587 - accuracy: 0.9003 - val_loss: 3.2793 - val_mse: 0.4266 - val_accuracy: 0.5315\n",
      "Epoch 510/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1710 - mse: 0.0591 - accuracy: 0.9017 - val_loss: 3.1862 - val_mse: 0.4142 - val_accuracy: 0.5370\n",
      "Epoch 511/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1720 - mse: 0.0592 - accuracy: 0.8989 - val_loss: 3.2055 - val_mse: 0.4098 - val_accuracy: 0.5283\n",
      "Epoch 512/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1732 - mse: 0.0596 - accuracy: 0.9030 - val_loss: 3.0177 - val_mse: 0.3949 - val_accuracy: 0.5543\n",
      "Epoch 513/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1693 - mse: 0.0584 - accuracy: 0.9036 - val_loss: 3.3348 - val_mse: 0.4249 - val_accuracy: 0.5207\n",
      "Epoch 514/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1781 - mse: 0.0609 - accuracy: 0.9000 - val_loss: 3.1675 - val_mse: 0.3972 - val_accuracy: 0.5457\n",
      "Epoch 515/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1836 - mse: 0.0620 - accuracy: 0.9003 - val_loss: 2.5854 - val_mse: 0.3957 - val_accuracy: 0.5141\n",
      "Epoch 516/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1833 - mse: 0.0613 - accuracy: 0.9022 - val_loss: 2.9378 - val_mse: 0.4001 - val_accuracy: 0.5348\n",
      "Epoch 517/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1712 - mse: 0.0587 - accuracy: 0.9014 - val_loss: 3.1392 - val_mse: 0.4081 - val_accuracy: 0.5435\n",
      "Epoch 518/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1720 - mse: 0.0587 - accuracy: 0.9027 - val_loss: 3.2433 - val_mse: 0.4221 - val_accuracy: 0.5283\n",
      "Epoch 519/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1794 - mse: 0.0604 - accuracy: 0.9011 - val_loss: 3.0533 - val_mse: 0.4105 - val_accuracy: 0.5446\n",
      "Epoch 520/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1826 - mse: 0.0624 - accuracy: 0.8957 - val_loss: 2.9046 - val_mse: 0.3851 - val_accuracy: 0.5587\n",
      "Epoch 521/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1842 - mse: 0.0620 - accuracy: 0.9008 - val_loss: 2.9591 - val_mse: 0.3927 - val_accuracy: 0.5435\n",
      "Epoch 522/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1717 - mse: 0.0582 - accuracy: 0.9011 - val_loss: 3.1666 - val_mse: 0.4270 - val_accuracy: 0.5098\n",
      "Epoch 523/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1844 - mse: 0.0619 - accuracy: 0.8970 - val_loss: 3.0297 - val_mse: 0.4171 - val_accuracy: 0.5174\n",
      "Epoch 524/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1840 - mse: 0.0629 - accuracy: 0.8962 - val_loss: 2.9444 - val_mse: 0.4018 - val_accuracy: 0.5348\n",
      "Epoch 525/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1752 - mse: 0.0593 - accuracy: 0.8995 - val_loss: 3.1865 - val_mse: 0.4195 - val_accuracy: 0.5304\n",
      "Epoch 526/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1661 - mse: 0.0581 - accuracy: 0.9025 - val_loss: 3.2159 - val_mse: 0.4079 - val_accuracy: 0.5283\n",
      "Epoch 527/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1704 - mse: 0.0587 - accuracy: 0.9006 - val_loss: 3.3404 - val_mse: 0.4317 - val_accuracy: 0.5043\n",
      "Epoch 528/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1740 - mse: 0.0595 - accuracy: 0.9041 - val_loss: 2.9435 - val_mse: 0.3994 - val_accuracy: 0.5413\n",
      "Epoch 529/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1891 - mse: 0.0633 - accuracy: 0.8992 - val_loss: 3.2428 - val_mse: 0.4373 - val_accuracy: 0.4946\n",
      "Epoch 530/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2031 - mse: 0.0665 - accuracy: 0.8962 - val_loss: 3.2886 - val_mse: 0.4363 - val_accuracy: 0.5000\n",
      "Epoch 531/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1828 - mse: 0.0608 - accuracy: 0.8998 - val_loss: 2.8883 - val_mse: 0.4019 - val_accuracy: 0.5337\n",
      "Epoch 532/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1837 - mse: 0.0625 - accuracy: 0.8998 - val_loss: 3.1885 - val_mse: 0.4137 - val_accuracy: 0.5348\n",
      "Epoch 533/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1657 - mse: 0.0572 - accuracy: 0.9025 - val_loss: 3.3491 - val_mse: 0.4252 - val_accuracy: 0.5196\n",
      "Epoch 534/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1778 - mse: 0.0601 - accuracy: 0.9030 - val_loss: 3.0609 - val_mse: 0.4330 - val_accuracy: 0.5022\n",
      "Epoch 535/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1790 - mse: 0.0581 - accuracy: 0.9055 - val_loss: 2.8095 - val_mse: 0.3993 - val_accuracy: 0.5391\n",
      "Epoch 536/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1731 - mse: 0.0594 - accuracy: 0.9011 - val_loss: 3.1005 - val_mse: 0.4140 - val_accuracy: 0.5293\n",
      "Epoch 537/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1739 - mse: 0.0595 - accuracy: 0.9006 - val_loss: 2.9548 - val_mse: 0.3947 - val_accuracy: 0.5554\n",
      "Epoch 538/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1686 - mse: 0.0585 - accuracy: 0.9030 - val_loss: 2.8832 - val_mse: 0.4011 - val_accuracy: 0.5359\n",
      "Epoch 539/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1726 - mse: 0.0589 - accuracy: 0.9036 - val_loss: 3.2032 - val_mse: 0.4181 - val_accuracy: 0.5293\n",
      "Epoch 540/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1761 - mse: 0.0598 - accuracy: 0.9027 - val_loss: 3.0534 - val_mse: 0.4033 - val_accuracy: 0.5446\n",
      "Epoch 541/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1657 - mse: 0.0570 - accuracy: 0.9063 - val_loss: 3.0081 - val_mse: 0.3939 - val_accuracy: 0.5533\n",
      "Epoch 542/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1711 - mse: 0.0585 - accuracy: 0.9057 - val_loss: 3.4834 - val_mse: 0.4343 - val_accuracy: 0.4946\n",
      "Epoch 543/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1986 - mse: 0.0653 - accuracy: 0.8943 - val_loss: 3.1370 - val_mse: 0.4122 - val_accuracy: 0.5337\n",
      "Epoch 544/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1871 - mse: 0.0639 - accuracy: 0.8976 - val_loss: 3.1396 - val_mse: 0.4044 - val_accuracy: 0.5467\n",
      "Epoch 545/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1931 - mse: 0.0643 - accuracy: 0.8976 - val_loss: 3.0247 - val_mse: 0.4228 - val_accuracy: 0.5152\n",
      "Epoch 546/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1715 - mse: 0.0582 - accuracy: 0.9057 - val_loss: 2.8425 - val_mse: 0.4047 - val_accuracy: 0.5261\n",
      "Epoch 547/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1712 - mse: 0.0587 - accuracy: 0.9041 - val_loss: 3.1140 - val_mse: 0.4110 - val_accuracy: 0.5380\n",
      "Epoch 548/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1757 - mse: 0.0595 - accuracy: 0.9049 - val_loss: 3.2541 - val_mse: 0.4347 - val_accuracy: 0.5022\n",
      "Epoch 549/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1632 - mse: 0.0567 - accuracy: 0.9057 - val_loss: 3.0537 - val_mse: 0.4076 - val_accuracy: 0.5348\n",
      "Epoch 550/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1652 - mse: 0.0570 - accuracy: 0.9008 - val_loss: 3.1028 - val_mse: 0.4035 - val_accuracy: 0.5522\n",
      "Epoch 551/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1726 - mse: 0.0592 - accuracy: 0.9065 - val_loss: 3.0372 - val_mse: 0.4090 - val_accuracy: 0.5207\n",
      "Epoch 552/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1773 - mse: 0.0598 - accuracy: 0.9022 - val_loss: 3.2846 - val_mse: 0.4346 - val_accuracy: 0.5033\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1799 - mse: 0.0611 - accuracy: 0.8957 - val_loss: 2.8913 - val_mse: 0.3919 - val_accuracy: 0.5446\n",
      "Epoch 554/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1729 - mse: 0.0592 - accuracy: 0.9014 - val_loss: 3.3629 - val_mse: 0.4234 - val_accuracy: 0.5250\n",
      "Epoch 555/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1637 - mse: 0.0567 - accuracy: 0.9041 - val_loss: 3.4201 - val_mse: 0.4300 - val_accuracy: 0.5185\n",
      "Epoch 556/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1638 - mse: 0.0567 - accuracy: 0.9084 - val_loss: 3.2619 - val_mse: 0.4120 - val_accuracy: 0.5293\n",
      "Epoch 557/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1709 - mse: 0.0584 - accuracy: 0.9052 - val_loss: 3.3241 - val_mse: 0.4109 - val_accuracy: 0.5326\n",
      "Epoch 558/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1789 - mse: 0.0609 - accuracy: 0.9022 - val_loss: 3.0892 - val_mse: 0.4015 - val_accuracy: 0.5446\n",
      "Epoch 559/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1679 - mse: 0.0582 - accuracy: 0.9038 - val_loss: 3.4197 - val_mse: 0.4202 - val_accuracy: 0.5283\n",
      "Epoch 560/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1706 - mse: 0.0586 - accuracy: 0.9027 - val_loss: 2.9777 - val_mse: 0.4021 - val_accuracy: 0.5304\n",
      "Epoch 561/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1758 - mse: 0.0596 - accuracy: 0.9019 - val_loss: 3.1724 - val_mse: 0.3984 - val_accuracy: 0.5543\n",
      "Epoch 562/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1727 - mse: 0.0594 - accuracy: 0.9006 - val_loss: 2.7653 - val_mse: 0.3942 - val_accuracy: 0.5283\n",
      "Epoch 563/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1698 - mse: 0.0581 - accuracy: 0.9038 - val_loss: 3.3234 - val_mse: 0.4109 - val_accuracy: 0.5370\n",
      "Epoch 564/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1841 - mse: 0.0625 - accuracy: 0.9006 - val_loss: 2.8424 - val_mse: 0.3851 - val_accuracy: 0.5522\n",
      "Epoch 565/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1763 - mse: 0.0590 - accuracy: 0.9011 - val_loss: 2.9255 - val_mse: 0.4109 - val_accuracy: 0.5239\n",
      "Epoch 566/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1730 - mse: 0.0581 - accuracy: 0.9046 - val_loss: 3.3212 - val_mse: 0.4270 - val_accuracy: 0.5174\n",
      "Epoch 567/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1712 - mse: 0.0584 - accuracy: 0.9052 - val_loss: 3.0805 - val_mse: 0.4076 - val_accuracy: 0.5370\n",
      "Epoch 568/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1757 - mse: 0.0598 - accuracy: 0.9025 - val_loss: 2.8488 - val_mse: 0.3880 - val_accuracy: 0.5533\n",
      "Epoch 569/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1960 - mse: 0.0657 - accuracy: 0.8938 - val_loss: 2.9757 - val_mse: 0.4112 - val_accuracy: 0.5239\n",
      "Epoch 570/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1769 - mse: 0.0592 - accuracy: 0.9022 - val_loss: 3.0142 - val_mse: 0.3997 - val_accuracy: 0.5489\n",
      "Epoch 571/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1902 - mse: 0.0633 - accuracy: 0.8965 - val_loss: 2.7734 - val_mse: 0.3967 - val_accuracy: 0.5272\n",
      "Epoch 572/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1646 - mse: 0.0567 - accuracy: 0.9093 - val_loss: 2.9851 - val_mse: 0.4294 - val_accuracy: 0.5054\n",
      "Epoch 573/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1679 - mse: 0.0571 - accuracy: 0.9065 - val_loss: 3.2751 - val_mse: 0.4332 - val_accuracy: 0.5076\n",
      "Epoch 574/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1634 - mse: 0.0560 - accuracy: 0.9052 - val_loss: 3.1081 - val_mse: 0.4188 - val_accuracy: 0.5087\n",
      "Epoch 575/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1646 - mse: 0.0568 - accuracy: 0.9041 - val_loss: 3.1810 - val_mse: 0.4271 - val_accuracy: 0.5163\n",
      "Epoch 576/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1631 - mse: 0.0567 - accuracy: 0.9076 - val_loss: 2.9472 - val_mse: 0.4072 - val_accuracy: 0.5424\n",
      "Epoch 577/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1722 - mse: 0.0588 - accuracy: 0.9030 - val_loss: 3.1839 - val_mse: 0.4069 - val_accuracy: 0.5478\n",
      "Epoch 578/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1792 - mse: 0.0615 - accuracy: 0.8992 - val_loss: 3.0457 - val_mse: 0.4033 - val_accuracy: 0.5326\n",
      "Epoch 579/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1805 - mse: 0.0615 - accuracy: 0.9017 - val_loss: 3.2371 - val_mse: 0.4213 - val_accuracy: 0.5185\n",
      "Epoch 580/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1769 - mse: 0.0589 - accuracy: 0.9019 - val_loss: 2.8896 - val_mse: 0.4215 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1743 - mse: 0.0598 - accuracy: 0.9046 - val_loss: 3.0442 - val_mse: 0.4176 - val_accuracy: 0.5130\n",
      "Epoch 582/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1748 - mse: 0.0596 - accuracy: 0.9003 - val_loss: 3.1191 - val_mse: 0.4091 - val_accuracy: 0.5380\n",
      "Epoch 583/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1711 - mse: 0.0584 - accuracy: 0.9057 - val_loss: 3.3156 - val_mse: 0.4182 - val_accuracy: 0.5239\n",
      "Epoch 584/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1668 - mse: 0.0575 - accuracy: 0.9057 - val_loss: 3.1432 - val_mse: 0.4169 - val_accuracy: 0.5293\n",
      "Epoch 585/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1724 - mse: 0.0592 - accuracy: 0.9008 - val_loss: 3.3607 - val_mse: 0.4402 - val_accuracy: 0.4989\n",
      "Epoch 586/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1707 - mse: 0.0589 - accuracy: 0.9044 - val_loss: 3.1915 - val_mse: 0.4375 - val_accuracy: 0.4967\n",
      "Epoch 587/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1730 - mse: 0.0587 - accuracy: 0.9046 - val_loss: 3.1497 - val_mse: 0.4212 - val_accuracy: 0.5250\n",
      "Epoch 588/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1671 - mse: 0.0577 - accuracy: 0.9049 - val_loss: 3.1672 - val_mse: 0.4134 - val_accuracy: 0.5326\n",
      "Epoch 589/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1605 - mse: 0.0561 - accuracy: 0.9052 - val_loss: 3.3737 - val_mse: 0.4241 - val_accuracy: 0.5261\n",
      "Epoch 590/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1718 - mse: 0.0592 - accuracy: 0.9003 - val_loss: 3.1405 - val_mse: 0.4052 - val_accuracy: 0.5337\n",
      "Epoch 591/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1719 - mse: 0.0592 - accuracy: 0.9025 - val_loss: 3.3910 - val_mse: 0.4304 - val_accuracy: 0.5141\n",
      "Epoch 592/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1702 - mse: 0.0580 - accuracy: 0.9025 - val_loss: 2.9691 - val_mse: 0.3991 - val_accuracy: 0.5391\n",
      "Epoch 593/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1724 - mse: 0.0585 - accuracy: 0.9071 - val_loss: 2.8664 - val_mse: 0.3886 - val_accuracy: 0.5467\n",
      "Epoch 594/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1773 - mse: 0.0603 - accuracy: 0.9022 - val_loss: 3.3975 - val_mse: 0.4221 - val_accuracy: 0.5196\n",
      "Epoch 595/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1751 - mse: 0.0601 - accuracy: 0.9017 - val_loss: 3.2547 - val_mse: 0.3971 - val_accuracy: 0.5576\n",
      "Epoch 596/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1694 - mse: 0.0579 - accuracy: 0.9036 - val_loss: 3.3897 - val_mse: 0.4118 - val_accuracy: 0.5457\n",
      "Epoch 597/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1661 - mse: 0.0577 - accuracy: 0.9036 - val_loss: 3.1055 - val_mse: 0.3971 - val_accuracy: 0.5380\n",
      "Epoch 598/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1890 - mse: 0.0635 - accuracy: 0.8979 - val_loss: 3.3211 - val_mse: 0.4130 - val_accuracy: 0.5272\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1775 - mse: 0.0610 - accuracy: 0.9006 - val_loss: 3.3544 - val_mse: 0.4088 - val_accuracy: 0.5359\n",
      "Epoch 600/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1686 - mse: 0.0584 - accuracy: 0.9014 - val_loss: 3.2213 - val_mse: 0.4332 - val_accuracy: 0.5065\n",
      "Epoch 601/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1995 - mse: 0.0667 - accuracy: 0.8900 - val_loss: 3.5230 - val_mse: 0.4335 - val_accuracy: 0.5076\n",
      "Epoch 602/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1674 - mse: 0.0570 - accuracy: 0.9065 - val_loss: 2.9836 - val_mse: 0.4078 - val_accuracy: 0.5293\n",
      "Epoch 603/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1697 - mse: 0.0581 - accuracy: 0.9033 - val_loss: 3.2076 - val_mse: 0.4016 - val_accuracy: 0.5435\n",
      "Epoch 604/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1712 - mse: 0.0581 - accuracy: 0.9027 - val_loss: 3.4666 - val_mse: 0.4230 - val_accuracy: 0.5304\n",
      "Epoch 605/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1614 - mse: 0.0555 - accuracy: 0.9065 - val_loss: 3.2601 - val_mse: 0.4293 - val_accuracy: 0.5043\n",
      "Epoch 606/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1615 - mse: 0.0559 - accuracy: 0.9057 - val_loss: 3.0852 - val_mse: 0.4141 - val_accuracy: 0.5261\n",
      "Epoch 607/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1644 - mse: 0.0564 - accuracy: 0.9090 - val_loss: 3.5334 - val_mse: 0.4220 - val_accuracy: 0.5402\n",
      "Epoch 608/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1714 - mse: 0.0581 - accuracy: 0.9044 - val_loss: 3.0104 - val_mse: 0.4166 - val_accuracy: 0.5337\n",
      "Epoch 609/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1749 - mse: 0.0593 - accuracy: 0.9041 - val_loss: 3.3603 - val_mse: 0.4130 - val_accuracy: 0.5424\n",
      "Epoch 610/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1713 - mse: 0.0589 - accuracy: 0.9038 - val_loss: 3.1910 - val_mse: 0.3981 - val_accuracy: 0.5457\n",
      "Epoch 611/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1719 - mse: 0.0586 - accuracy: 0.9011 - val_loss: 3.3898 - val_mse: 0.4307 - val_accuracy: 0.5239\n",
      "Epoch 612/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1721 - mse: 0.0586 - accuracy: 0.9008 - val_loss: 3.2170 - val_mse: 0.4013 - val_accuracy: 0.5478\n",
      "Epoch 613/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1805 - mse: 0.0611 - accuracy: 0.9027 - val_loss: 2.9738 - val_mse: 0.4285 - val_accuracy: 0.5130\n",
      "Epoch 614/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1754 - mse: 0.0598 - accuracy: 0.9025 - val_loss: 3.0455 - val_mse: 0.3850 - val_accuracy: 0.5652\n",
      "Epoch 615/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1646 - mse: 0.0558 - accuracy: 0.9065 - val_loss: 3.4231 - val_mse: 0.4146 - val_accuracy: 0.5446\n",
      "Epoch 616/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1673 - mse: 0.0577 - accuracy: 0.9033 - val_loss: 3.1859 - val_mse: 0.4280 - val_accuracy: 0.5076\n",
      "Epoch 617/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1675 - mse: 0.0575 - accuracy: 0.9057 - val_loss: 3.5920 - val_mse: 0.4425 - val_accuracy: 0.5076\n",
      "Epoch 618/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1676 - mse: 0.0575 - accuracy: 0.9055 - val_loss: 3.4669 - val_mse: 0.4361 - val_accuracy: 0.5109\n",
      "Epoch 619/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1606 - mse: 0.0556 - accuracy: 0.9071 - val_loss: 3.2261 - val_mse: 0.3976 - val_accuracy: 0.5565\n",
      "Epoch 620/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1651 - mse: 0.0568 - accuracy: 0.9060 - val_loss: 3.4745 - val_mse: 0.4370 - val_accuracy: 0.5109\n",
      "Epoch 621/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1687 - mse: 0.0577 - accuracy: 0.9049 - val_loss: 3.1093 - val_mse: 0.4050 - val_accuracy: 0.5326\n",
      "Epoch 622/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1681 - mse: 0.0573 - accuracy: 0.9060 - val_loss: 2.9107 - val_mse: 0.3892 - val_accuracy: 0.5543\n",
      "Epoch 623/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1800 - mse: 0.0610 - accuracy: 0.9074 - val_loss: 3.1204 - val_mse: 0.4052 - val_accuracy: 0.5380\n",
      "Epoch 624/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1782 - mse: 0.0607 - accuracy: 0.9017 - val_loss: 3.5807 - val_mse: 0.4329 - val_accuracy: 0.5359\n",
      "Epoch 625/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1722 - mse: 0.0589 - accuracy: 0.9027 - val_loss: 3.0573 - val_mse: 0.4152 - val_accuracy: 0.5283\n",
      "Epoch 626/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1654 - mse: 0.0566 - accuracy: 0.9065 - val_loss: 3.2944 - val_mse: 0.4271 - val_accuracy: 0.5239\n",
      "Epoch 627/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1615 - mse: 0.0557 - accuracy: 0.9076 - val_loss: 3.2853 - val_mse: 0.4119 - val_accuracy: 0.5380\n",
      "Epoch 628/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1699 - mse: 0.0585 - accuracy: 0.9027 - val_loss: 3.1775 - val_mse: 0.3985 - val_accuracy: 0.5511\n",
      "Epoch 629/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1608 - mse: 0.0559 - accuracy: 0.9052 - val_loss: 3.6480 - val_mse: 0.4399 - val_accuracy: 0.5130\n",
      "Epoch 630/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1760 - mse: 0.0589 - accuracy: 0.9055 - val_loss: 3.1438 - val_mse: 0.3993 - val_accuracy: 0.5500\n",
      "Epoch 631/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1666 - mse: 0.0572 - accuracy: 0.9065 - val_loss: 3.0880 - val_mse: 0.4096 - val_accuracy: 0.5402\n",
      "Epoch 632/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1752 - mse: 0.0596 - accuracy: 0.9033 - val_loss: 3.1129 - val_mse: 0.3910 - val_accuracy: 0.5783\n",
      "Epoch 633/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1689 - mse: 0.0579 - accuracy: 0.9006 - val_loss: 3.1256 - val_mse: 0.3955 - val_accuracy: 0.5522\n",
      "Epoch 634/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1812 - mse: 0.0609 - accuracy: 0.9033 - val_loss: 3.4066 - val_mse: 0.4174 - val_accuracy: 0.5304\n",
      "Epoch 635/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1794 - mse: 0.0598 - accuracy: 0.9022 - val_loss: 3.3486 - val_mse: 0.4283 - val_accuracy: 0.5272\n",
      "Epoch 636/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1654 - mse: 0.0571 - accuracy: 0.9036 - val_loss: 3.5751 - val_mse: 0.4536 - val_accuracy: 0.4957\n",
      "Epoch 637/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1851 - mse: 0.0617 - accuracy: 0.9003 - val_loss: 3.1369 - val_mse: 0.4287 - val_accuracy: 0.5054\n",
      "Epoch 638/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1667 - mse: 0.0577 - accuracy: 0.9044 - val_loss: 3.3575 - val_mse: 0.4279 - val_accuracy: 0.5174\n",
      "Epoch 639/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1694 - mse: 0.0576 - accuracy: 0.9041 - val_loss: 3.4149 - val_mse: 0.4266 - val_accuracy: 0.5185\n",
      "Epoch 640/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1593 - mse: 0.0552 - accuracy: 0.9076 - val_loss: 3.3451 - val_mse: 0.4160 - val_accuracy: 0.5315\n",
      "Epoch 641/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1543 - mse: 0.0534 - accuracy: 0.9133 - val_loss: 3.4575 - val_mse: 0.4081 - val_accuracy: 0.5478\n",
      "Epoch 642/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1601 - mse: 0.0558 - accuracy: 0.9027 - val_loss: 3.0484 - val_mse: 0.3929 - val_accuracy: 0.5446\n",
      "Epoch 643/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1658 - mse: 0.0570 - accuracy: 0.9071 - val_loss: 3.3023 - val_mse: 0.4250 - val_accuracy: 0.5304\n",
      "Epoch 644/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1943 - mse: 0.0644 - accuracy: 0.8960 - val_loss: 3.4092 - val_mse: 0.4261 - val_accuracy: 0.5185\n",
      "Epoch 645/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1845 - mse: 0.0627 - accuracy: 0.8957 - val_loss: 3.0409 - val_mse: 0.4313 - val_accuracy: 0.5033\n",
      "Epoch 646/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1804 - mse: 0.0603 - accuracy: 0.9036 - val_loss: 3.2230 - val_mse: 0.4055 - val_accuracy: 0.5370\n",
      "Epoch 647/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1631 - mse: 0.0564 - accuracy: 0.9052 - val_loss: 3.3391 - val_mse: 0.4143 - val_accuracy: 0.5370\n",
      "Epoch 648/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1591 - mse: 0.0545 - accuracy: 0.9093 - val_loss: 3.9060 - val_mse: 0.4520 - val_accuracy: 0.5141\n",
      "Epoch 649/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1622 - mse: 0.0559 - accuracy: 0.9095 - val_loss: 3.3547 - val_mse: 0.4212 - val_accuracy: 0.5207\n",
      "Epoch 650/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1590 - mse: 0.0553 - accuracy: 0.9082 - val_loss: 3.3667 - val_mse: 0.4089 - val_accuracy: 0.5413\n",
      "Epoch 651/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1588 - mse: 0.0555 - accuracy: 0.9036 - val_loss: 3.4052 - val_mse: 0.4133 - val_accuracy: 0.5315\n",
      "Epoch 652/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1574 - mse: 0.0542 - accuracy: 0.9090 - val_loss: 3.4526 - val_mse: 0.4327 - val_accuracy: 0.5054\n",
      "Epoch 653/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1634 - mse: 0.0554 - accuracy: 0.9074 - val_loss: 3.3424 - val_mse: 0.4152 - val_accuracy: 0.5380\n",
      "Epoch 654/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1595 - mse: 0.0551 - accuracy: 0.9065 - val_loss: 3.1832 - val_mse: 0.3994 - val_accuracy: 0.5457\n",
      "Epoch 655/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1861 - mse: 0.0625 - accuracy: 0.9006 - val_loss: 3.3415 - val_mse: 0.4211 - val_accuracy: 0.5250\n",
      "Epoch 656/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1842 - mse: 0.0617 - accuracy: 0.9003 - val_loss: 3.5171 - val_mse: 0.4252 - val_accuracy: 0.5359\n",
      "Epoch 657/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1754 - mse: 0.0601 - accuracy: 0.8998 - val_loss: 3.1194 - val_mse: 0.4152 - val_accuracy: 0.5283\n",
      "Epoch 658/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1698 - mse: 0.0580 - accuracy: 0.9052 - val_loss: 3.2979 - val_mse: 0.4384 - val_accuracy: 0.5065\n",
      "Epoch 659/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1901 - mse: 0.0637 - accuracy: 0.8979 - val_loss: 3.0648 - val_mse: 0.4096 - val_accuracy: 0.5304\n",
      "Epoch 660/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1643 - mse: 0.0563 - accuracy: 0.9082 - val_loss: 3.4444 - val_mse: 0.4279 - val_accuracy: 0.5370\n",
      "Epoch 661/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1615 - mse: 0.0556 - accuracy: 0.9106 - val_loss: 3.1464 - val_mse: 0.4117 - val_accuracy: 0.5315\n",
      "Epoch 662/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1601 - mse: 0.0552 - accuracy: 0.9095 - val_loss: 3.2883 - val_mse: 0.4115 - val_accuracy: 0.5261\n",
      "Epoch 663/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1618 - mse: 0.0557 - accuracy: 0.9052 - val_loss: 3.6189 - val_mse: 0.4425 - val_accuracy: 0.5087\n",
      "Epoch 664/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1692 - mse: 0.0574 - accuracy: 0.9025 - val_loss: 3.2749 - val_mse: 0.4098 - val_accuracy: 0.5348\n",
      "Epoch 665/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1588 - mse: 0.0549 - accuracy: 0.9090 - val_loss: 3.6204 - val_mse: 0.4248 - val_accuracy: 0.5380\n",
      "Epoch 666/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1639 - mse: 0.0566 - accuracy: 0.9074 - val_loss: 3.5942 - val_mse: 0.4432 - val_accuracy: 0.5098\n",
      "Epoch 667/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1798 - mse: 0.0604 - accuracy: 0.9017 - val_loss: 3.4071 - val_mse: 0.4256 - val_accuracy: 0.5239\n",
      "Epoch 668/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1694 - mse: 0.0578 - accuracy: 0.9036 - val_loss: 3.6449 - val_mse: 0.4248 - val_accuracy: 0.5337\n",
      "Epoch 669/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1606 - mse: 0.0553 - accuracy: 0.9060 - val_loss: 3.2992 - val_mse: 0.4187 - val_accuracy: 0.5261\n",
      "Epoch 670/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1623 - mse: 0.0559 - accuracy: 0.9049 - val_loss: 3.0447 - val_mse: 0.4075 - val_accuracy: 0.5304\n",
      "Epoch 671/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1638 - mse: 0.0562 - accuracy: 0.9093 - val_loss: 3.4662 - val_mse: 0.4311 - val_accuracy: 0.5217\n",
      "Epoch 672/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1731 - mse: 0.0594 - accuracy: 0.9036 - val_loss: 3.1503 - val_mse: 0.4020 - val_accuracy: 0.5370\n",
      "Epoch 673/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1688 - mse: 0.0578 - accuracy: 0.9076 - val_loss: 3.1398 - val_mse: 0.4301 - val_accuracy: 0.5065\n",
      "Epoch 674/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1785 - mse: 0.0610 - accuracy: 0.9055 - val_loss: 3.1009 - val_mse: 0.4211 - val_accuracy: 0.5141\n",
      "Epoch 675/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1642 - mse: 0.0571 - accuracy: 0.9052 - val_loss: 3.2655 - val_mse: 0.4205 - val_accuracy: 0.5250\n",
      "Epoch 676/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1594 - mse: 0.0553 - accuracy: 0.9052 - val_loss: 3.5072 - val_mse: 0.4248 - val_accuracy: 0.5261\n",
      "Epoch 677/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1598 - mse: 0.0553 - accuracy: 0.9098 - val_loss: 3.4893 - val_mse: 0.4274 - val_accuracy: 0.5239\n",
      "Epoch 678/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1706 - mse: 0.0582 - accuracy: 0.9022 - val_loss: 3.5387 - val_mse: 0.4260 - val_accuracy: 0.5337\n",
      "Epoch 679/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1683 - mse: 0.0579 - accuracy: 0.9030 - val_loss: 3.2171 - val_mse: 0.4143 - val_accuracy: 0.5283\n",
      "Epoch 680/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1671 - mse: 0.0571 - accuracy: 0.9079 - val_loss: 3.4977 - val_mse: 0.4280 - val_accuracy: 0.5196\n",
      "Epoch 681/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1627 - mse: 0.0562 - accuracy: 0.9068 - val_loss: 3.7231 - val_mse: 0.4414 - val_accuracy: 0.5185\n",
      "Epoch 682/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1867 - mse: 0.0627 - accuracy: 0.9008 - val_loss: 3.3005 - val_mse: 0.4203 - val_accuracy: 0.5250\n",
      "Epoch 683/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1670 - mse: 0.0571 - accuracy: 0.9046 - val_loss: 3.3740 - val_mse: 0.4144 - val_accuracy: 0.5348\n",
      "Epoch 684/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1576 - mse: 0.0547 - accuracy: 0.9095 - val_loss: 3.3822 - val_mse: 0.4099 - val_accuracy: 0.5380\n",
      "Epoch 685/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1562 - mse: 0.0541 - accuracy: 0.9095 - val_loss: 3.4157 - val_mse: 0.3980 - val_accuracy: 0.5543\n",
      "Epoch 686/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1621 - mse: 0.0561 - accuracy: 0.9038 - val_loss: 3.4870 - val_mse: 0.4229 - val_accuracy: 0.5250\n",
      "Epoch 687/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1685 - mse: 0.0573 - accuracy: 0.9071 - val_loss: 3.1883 - val_mse: 0.4015 - val_accuracy: 0.5402\n",
      "Epoch 688/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1613 - mse: 0.0559 - accuracy: 0.9055 - val_loss: 3.3991 - val_mse: 0.4104 - val_accuracy: 0.5413\n",
      "Epoch 689/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1672 - mse: 0.0579 - accuracy: 0.9052 - val_loss: 3.5833 - val_mse: 0.4268 - val_accuracy: 0.5239\n",
      "Epoch 690/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1776 - mse: 0.0602 - accuracy: 0.9014 - val_loss: 3.3374 - val_mse: 0.4122 - val_accuracy: 0.5413\n",
      "Epoch 691/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1637 - mse: 0.0565 - accuracy: 0.9057 - val_loss: 3.3061 - val_mse: 0.4144 - val_accuracy: 0.5293\n",
      "Epoch 692/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1573 - mse: 0.0546 - accuracy: 0.9082 - val_loss: 3.4599 - val_mse: 0.4323 - val_accuracy: 0.5130\n",
      "Epoch 693/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1598 - mse: 0.0555 - accuracy: 0.9095 - val_loss: 3.4585 - val_mse: 0.4266 - val_accuracy: 0.5196\n",
      "Epoch 694/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1683 - mse: 0.0571 - accuracy: 0.9068 - val_loss: 3.5237 - val_mse: 0.4400 - val_accuracy: 0.5130\n",
      "Epoch 695/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1692 - mse: 0.0568 - accuracy: 0.9049 - val_loss: 3.3220 - val_mse: 0.3959 - val_accuracy: 0.5576\n",
      "Epoch 696/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1680 - mse: 0.0574 - accuracy: 0.9095 - val_loss: 3.4076 - val_mse: 0.4189 - val_accuracy: 0.5207\n",
      "Epoch 697/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1611 - mse: 0.0558 - accuracy: 0.9076 - val_loss: 3.5676 - val_mse: 0.4208 - val_accuracy: 0.5370\n",
      "Epoch 698/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1624 - mse: 0.0558 - accuracy: 0.9068 - val_loss: 3.5126 - val_mse: 0.4392 - val_accuracy: 0.4978\n",
      "Epoch 699/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1830 - mse: 0.0608 - accuracy: 0.9011 - val_loss: 3.5328 - val_mse: 0.4314 - val_accuracy: 0.5174\n",
      "Epoch 700/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1624 - mse: 0.0564 - accuracy: 0.9084 - val_loss: 3.2130 - val_mse: 0.4151 - val_accuracy: 0.5304\n",
      "Epoch 701/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1664 - mse: 0.0576 - accuracy: 0.9025 - val_loss: 3.6127 - val_mse: 0.4240 - val_accuracy: 0.5239\n",
      "Epoch 702/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1664 - mse: 0.0563 - accuracy: 0.9057 - val_loss: 3.5605 - val_mse: 0.4227 - val_accuracy: 0.5326\n",
      "Epoch 703/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1633 - mse: 0.0557 - accuracy: 0.9079 - val_loss: 3.5520 - val_mse: 0.4256 - val_accuracy: 0.5337\n",
      "Epoch 704/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1575 - mse: 0.0544 - accuracy: 0.9084 - val_loss: 3.4493 - val_mse: 0.4192 - val_accuracy: 0.5304\n",
      "Epoch 705/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1698 - mse: 0.0578 - accuracy: 0.9030 - val_loss: 3.4579 - val_mse: 0.4200 - val_accuracy: 0.5207\n",
      "Epoch 706/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1839 - mse: 0.0619 - accuracy: 0.8965 - val_loss: 3.0648 - val_mse: 0.3831 - val_accuracy: 0.5576\n",
      "Epoch 707/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1764 - mse: 0.0589 - accuracy: 0.9036 - val_loss: 3.3064 - val_mse: 0.4278 - val_accuracy: 0.5163\n",
      "Epoch 708/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1603 - mse: 0.0553 - accuracy: 0.9052 - val_loss: 3.1812 - val_mse: 0.4019 - val_accuracy: 0.5478\n",
      "Epoch 709/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1592 - mse: 0.0555 - accuracy: 0.9046 - val_loss: 3.4549 - val_mse: 0.4125 - val_accuracy: 0.5413\n",
      "Epoch 710/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1599 - mse: 0.0552 - accuracy: 0.9117 - val_loss: 3.4970 - val_mse: 0.4407 - val_accuracy: 0.4989\n",
      "Epoch 711/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1602 - mse: 0.0555 - accuracy: 0.9060 - val_loss: 3.4591 - val_mse: 0.4473 - val_accuracy: 0.4957\n",
      "Epoch 712/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1610 - mse: 0.0558 - accuracy: 0.9041 - val_loss: 3.5971 - val_mse: 0.4193 - val_accuracy: 0.5391\n",
      "Epoch 713/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1575 - mse: 0.0545 - accuracy: 0.9098 - val_loss: 3.5092 - val_mse: 0.4271 - val_accuracy: 0.5174\n",
      "Epoch 714/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1667 - mse: 0.0571 - accuracy: 0.9049 - val_loss: 3.6077 - val_mse: 0.4250 - val_accuracy: 0.5141\n",
      "Epoch 715/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1748 - mse: 0.0580 - accuracy: 0.9014 - val_loss: 3.3995 - val_mse: 0.4298 - val_accuracy: 0.5022\n",
      "Epoch 716/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1572 - mse: 0.0546 - accuracy: 0.9049 - val_loss: 3.3915 - val_mse: 0.4273 - val_accuracy: 0.5120\n",
      "Epoch 717/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1543 - mse: 0.0537 - accuracy: 0.9093 - val_loss: 3.4266 - val_mse: 0.4143 - val_accuracy: 0.5261\n",
      "Epoch 718/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1641 - mse: 0.0568 - accuracy: 0.9055 - val_loss: 3.2139 - val_mse: 0.3955 - val_accuracy: 0.5533\n",
      "Epoch 719/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1783 - mse: 0.0601 - accuracy: 0.9049 - val_loss: 3.2892 - val_mse: 0.4017 - val_accuracy: 0.5424\n",
      "Epoch 720/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1625 - mse: 0.0559 - accuracy: 0.9060 - val_loss: 3.4437 - val_mse: 0.4164 - val_accuracy: 0.5359\n",
      "Epoch 721/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1678 - mse: 0.0574 - accuracy: 0.9101 - val_loss: 3.0875 - val_mse: 0.4153 - val_accuracy: 0.5130\n",
      "Epoch 722/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1740 - mse: 0.0582 - accuracy: 0.9063 - val_loss: 3.3943 - val_mse: 0.4097 - val_accuracy: 0.5413\n",
      "Epoch 723/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1614 - mse: 0.0557 - accuracy: 0.9055 - val_loss: 3.6090 - val_mse: 0.4061 - val_accuracy: 0.5554\n",
      "Epoch 724/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1692 - mse: 0.0575 - accuracy: 0.9052 - val_loss: 3.3889 - val_mse: 0.4130 - val_accuracy: 0.5293\n",
      "Epoch 725/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1601 - mse: 0.0556 - accuracy: 0.9079 - val_loss: 3.3285 - val_mse: 0.4168 - val_accuracy: 0.5283\n",
      "Epoch 726/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1547 - mse: 0.0536 - accuracy: 0.9114 - val_loss: 3.4644 - val_mse: 0.4113 - val_accuracy: 0.5380\n",
      "Epoch 727/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1536 - mse: 0.0535 - accuracy: 0.9117 - val_loss: 3.5548 - val_mse: 0.3968 - val_accuracy: 0.5630\n",
      "Epoch 728/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1624 - mse: 0.0563 - accuracy: 0.9044 - val_loss: 3.6526 - val_mse: 0.4316 - val_accuracy: 0.5185\n",
      "Epoch 729/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1669 - mse: 0.0561 - accuracy: 0.9038 - val_loss: 3.6366 - val_mse: 0.4278 - val_accuracy: 0.5250\n",
      "Epoch 730/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1674 - mse: 0.0573 - accuracy: 0.9071 - val_loss: 3.4685 - val_mse: 0.4006 - val_accuracy: 0.5533\n",
      "Epoch 731/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1743 - mse: 0.0584 - accuracy: 0.9055 - val_loss: 3.3834 - val_mse: 0.4088 - val_accuracy: 0.5413\n",
      "Epoch 732/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1676 - mse: 0.0577 - accuracy: 0.9027 - val_loss: 3.0729 - val_mse: 0.3924 - val_accuracy: 0.5402\n",
      "Epoch 733/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1640 - mse: 0.0563 - accuracy: 0.9055 - val_loss: 3.3982 - val_mse: 0.4343 - val_accuracy: 0.5065\n",
      "Epoch 734/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1800 - mse: 0.0589 - accuracy: 0.9055 - val_loss: 3.5196 - val_mse: 0.4495 - val_accuracy: 0.4891\n",
      "Epoch 735/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1854 - mse: 0.0616 - accuracy: 0.9006 - val_loss: 3.1499 - val_mse: 0.4092 - val_accuracy: 0.5348\n",
      "Epoch 736/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1672 - mse: 0.0574 - accuracy: 0.9044 - val_loss: 3.3083 - val_mse: 0.4069 - val_accuracy: 0.5413\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1697 - mse: 0.0582 - accuracy: 0.9017 - val_loss: 3.3874 - val_mse: 0.4031 - val_accuracy: 0.5478\n",
      "Epoch 738/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1739 - mse: 0.0599 - accuracy: 0.9000 - val_loss: 3.3049 - val_mse: 0.4111 - val_accuracy: 0.5348\n",
      "Epoch 739/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1601 - mse: 0.0557 - accuracy: 0.9071 - val_loss: 3.7228 - val_mse: 0.4407 - val_accuracy: 0.5185\n",
      "Epoch 740/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1688 - mse: 0.0581 - accuracy: 0.9052 - val_loss: 3.1403 - val_mse: 0.4102 - val_accuracy: 0.5337\n",
      "Epoch 741/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1624 - mse: 0.0565 - accuracy: 0.9041 - val_loss: 3.5262 - val_mse: 0.4388 - val_accuracy: 0.5087\n",
      "Epoch 742/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1638 - mse: 0.0568 - accuracy: 0.9046 - val_loss: 3.4957 - val_mse: 0.4169 - val_accuracy: 0.5304\n",
      "Epoch 743/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1892 - mse: 0.0622 - accuracy: 0.9014 - val_loss: 2.8549 - val_mse: 0.3960 - val_accuracy: 0.5272\n",
      "Epoch 744/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1727 - mse: 0.0586 - accuracy: 0.9008 - val_loss: 3.4263 - val_mse: 0.4101 - val_accuracy: 0.5522\n",
      "Epoch 745/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1628 - mse: 0.0566 - accuracy: 0.9087 - val_loss: 2.7933 - val_mse: 0.3875 - val_accuracy: 0.5446\n",
      "Epoch 746/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1721 - mse: 0.0588 - accuracy: 0.8998 - val_loss: 3.1372 - val_mse: 0.4205 - val_accuracy: 0.5185\n",
      "Epoch 747/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1704 - mse: 0.0579 - accuracy: 0.9030 - val_loss: 3.3535 - val_mse: 0.4472 - val_accuracy: 0.4924\n",
      "Epoch 748/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1780 - mse: 0.0602 - accuracy: 0.9038 - val_loss: 3.1200 - val_mse: 0.4211 - val_accuracy: 0.5250\n",
      "Epoch 749/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1576 - mse: 0.0546 - accuracy: 0.9074 - val_loss: 3.2796 - val_mse: 0.4136 - val_accuracy: 0.5380\n",
      "Epoch 750/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1616 - mse: 0.0560 - accuracy: 0.9071 - val_loss: 3.3711 - val_mse: 0.4186 - val_accuracy: 0.5250\n",
      "Epoch 751/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1550 - mse: 0.0539 - accuracy: 0.9084 - val_loss: 3.1862 - val_mse: 0.4138 - val_accuracy: 0.5272\n",
      "Epoch 752/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1595 - mse: 0.0550 - accuracy: 0.9052 - val_loss: 3.5367 - val_mse: 0.4188 - val_accuracy: 0.5315\n",
      "Epoch 753/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1562 - mse: 0.0542 - accuracy: 0.9079 - val_loss: 3.5992 - val_mse: 0.4180 - val_accuracy: 0.5337\n",
      "Epoch 754/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1581 - mse: 0.0545 - accuracy: 0.9082 - val_loss: 3.5133 - val_mse: 0.4340 - val_accuracy: 0.5152\n",
      "Epoch 755/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1632 - mse: 0.0564 - accuracy: 0.9046 - val_loss: 3.3996 - val_mse: 0.4182 - val_accuracy: 0.5239\n",
      "Epoch 756/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1637 - mse: 0.0564 - accuracy: 0.9101 - val_loss: 3.0837 - val_mse: 0.4080 - val_accuracy: 0.5359\n",
      "Epoch 757/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1640 - mse: 0.0556 - accuracy: 0.9095 - val_loss: 3.5382 - val_mse: 0.4006 - val_accuracy: 0.5489\n",
      "Epoch 758/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1641 - mse: 0.0559 - accuracy: 0.9084 - val_loss: 3.4066 - val_mse: 0.4269 - val_accuracy: 0.5196\n",
      "Epoch 759/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1606 - mse: 0.0558 - accuracy: 0.9041 - val_loss: 3.4544 - val_mse: 0.4269 - val_accuracy: 0.5283\n",
      "Epoch 760/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1604 - mse: 0.0555 - accuracy: 0.9027 - val_loss: 3.0996 - val_mse: 0.3898 - val_accuracy: 0.5489\n",
      "Epoch 761/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1714 - mse: 0.0586 - accuracy: 0.9030 - val_loss: 3.1079 - val_mse: 0.3927 - val_accuracy: 0.5533\n",
      "Epoch 762/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1784 - mse: 0.0598 - accuracy: 0.9041 - val_loss: 3.4863 - val_mse: 0.4207 - val_accuracy: 0.5337\n",
      "Epoch 763/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1724 - mse: 0.0584 - accuracy: 0.9030 - val_loss: 3.3483 - val_mse: 0.4334 - val_accuracy: 0.5109\n",
      "Epoch 764/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1632 - mse: 0.0556 - accuracy: 0.9060 - val_loss: 3.3565 - val_mse: 0.4209 - val_accuracy: 0.5326\n",
      "Epoch 765/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1612 - mse: 0.0555 - accuracy: 0.9095 - val_loss: 3.2689 - val_mse: 0.4116 - val_accuracy: 0.5315\n",
      "Epoch 766/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1571 - mse: 0.0541 - accuracy: 0.9114 - val_loss: 3.2845 - val_mse: 0.4248 - val_accuracy: 0.5196\n",
      "Epoch 767/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1639 - mse: 0.0556 - accuracy: 0.9082 - val_loss: 3.7858 - val_mse: 0.4358 - val_accuracy: 0.5217\n",
      "Epoch 768/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1597 - mse: 0.0553 - accuracy: 0.9076 - val_loss: 3.3616 - val_mse: 0.4325 - val_accuracy: 0.5207\n",
      "Epoch 769/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1634 - mse: 0.0557 - accuracy: 0.9057 - val_loss: 3.6154 - val_mse: 0.4199 - val_accuracy: 0.5478\n",
      "Epoch 770/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1965 - mse: 0.0640 - accuracy: 0.8976 - val_loss: 3.6133 - val_mse: 0.4506 - val_accuracy: 0.4935\n",
      "Epoch 771/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1655 - mse: 0.0570 - accuracy: 0.9055 - val_loss: 3.5800 - val_mse: 0.4222 - val_accuracy: 0.5304\n",
      "Epoch 772/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1611 - mse: 0.0552 - accuracy: 0.9106 - val_loss: 3.3743 - val_mse: 0.4262 - val_accuracy: 0.5196\n",
      "Epoch 773/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1586 - mse: 0.0550 - accuracy: 0.9109 - val_loss: 3.2143 - val_mse: 0.4186 - val_accuracy: 0.5196\n",
      "Epoch 774/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1617 - mse: 0.0557 - accuracy: 0.9101 - val_loss: 3.5175 - val_mse: 0.4220 - val_accuracy: 0.5283\n",
      "Epoch 775/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1570 - mse: 0.0545 - accuracy: 0.9106 - val_loss: 3.4646 - val_mse: 0.4277 - val_accuracy: 0.5239\n",
      "Epoch 776/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1529 - mse: 0.0532 - accuracy: 0.9084 - val_loss: 3.5222 - val_mse: 0.4144 - val_accuracy: 0.5402\n",
      "Epoch 777/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1741 - mse: 0.0597 - accuracy: 0.9030 - val_loss: 2.8517 - val_mse: 0.4025 - val_accuracy: 0.5326\n",
      "Epoch 778/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1695 - mse: 0.0570 - accuracy: 0.9065 - val_loss: 3.3066 - val_mse: 0.3969 - val_accuracy: 0.5522\n",
      "Epoch 779/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1665 - mse: 0.0569 - accuracy: 0.9065 - val_loss: 3.2346 - val_mse: 0.4209 - val_accuracy: 0.5207\n",
      "Epoch 780/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1721 - mse: 0.0577 - accuracy: 0.9055 - val_loss: 3.5876 - val_mse: 0.4460 - val_accuracy: 0.5076\n",
      "Epoch 781/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1694 - mse: 0.0574 - accuracy: 0.9036 - val_loss: 3.2784 - val_mse: 0.4122 - val_accuracy: 0.5380\n",
      "Epoch 782/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1584 - mse: 0.0551 - accuracy: 0.9104 - val_loss: 3.3241 - val_mse: 0.4178 - val_accuracy: 0.5315\n",
      "Epoch 783/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1579 - mse: 0.0546 - accuracy: 0.9109 - val_loss: 3.1802 - val_mse: 0.4233 - val_accuracy: 0.5185\n",
      "Epoch 784/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1560 - mse: 0.0542 - accuracy: 0.9079 - val_loss: 3.3854 - val_mse: 0.4226 - val_accuracy: 0.5293\n",
      "Epoch 785/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1540 - mse: 0.0531 - accuracy: 0.9112 - val_loss: 3.5995 - val_mse: 0.4401 - val_accuracy: 0.5120\n",
      "Epoch 786/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1581 - mse: 0.0549 - accuracy: 0.9084 - val_loss: 3.4528 - val_mse: 0.4294 - val_accuracy: 0.5228\n",
      "Epoch 787/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1585 - mse: 0.0550 - accuracy: 0.9084 - val_loss: 3.4245 - val_mse: 0.4111 - val_accuracy: 0.5380\n",
      "Epoch 788/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1725 - mse: 0.0579 - accuracy: 0.9060 - val_loss: 3.1742 - val_mse: 0.4054 - val_accuracy: 0.5413\n",
      "Epoch 789/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1613 - mse: 0.0555 - accuracy: 0.9060 - val_loss: 3.4706 - val_mse: 0.4110 - val_accuracy: 0.5370\n",
      "Epoch 790/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1635 - mse: 0.0558 - accuracy: 0.9074 - val_loss: 3.0533 - val_mse: 0.4235 - val_accuracy: 0.5207\n",
      "Epoch 791/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1743 - mse: 0.0592 - accuracy: 0.9052 - val_loss: 3.8710 - val_mse: 0.4534 - val_accuracy: 0.5065\n",
      "Epoch 792/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1585 - mse: 0.0548 - accuracy: 0.9095 - val_loss: 3.4065 - val_mse: 0.4211 - val_accuracy: 0.5261\n",
      "Epoch 793/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1667 - mse: 0.0562 - accuracy: 0.9071 - val_loss: 3.5938 - val_mse: 0.4339 - val_accuracy: 0.5174\n",
      "Epoch 794/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1652 - mse: 0.0565 - accuracy: 0.9055 - val_loss: 3.3838 - val_mse: 0.4174 - val_accuracy: 0.5424\n",
      "Epoch 795/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1602 - mse: 0.0546 - accuracy: 0.9109 - val_loss: 3.0566 - val_mse: 0.4167 - val_accuracy: 0.5293\n",
      "Epoch 796/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1615 - mse: 0.0554 - accuracy: 0.9087 - val_loss: 3.2042 - val_mse: 0.4061 - val_accuracy: 0.5435\n",
      "Epoch 797/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1595 - mse: 0.0546 - accuracy: 0.9109 - val_loss: 3.5608 - val_mse: 0.4236 - val_accuracy: 0.5326\n",
      "Epoch 798/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1629 - mse: 0.0549 - accuracy: 0.9087 - val_loss: 3.2777 - val_mse: 0.4114 - val_accuracy: 0.5326\n",
      "Epoch 799/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1568 - mse: 0.0539 - accuracy: 0.9074 - val_loss: 3.2563 - val_mse: 0.4325 - val_accuracy: 0.5141\n",
      "Epoch 800/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1800 - mse: 0.0598 - accuracy: 0.9006 - val_loss: 3.0735 - val_mse: 0.4116 - val_accuracy: 0.5293\n",
      "Epoch 801/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1576 - mse: 0.0545 - accuracy: 0.9093 - val_loss: 3.3363 - val_mse: 0.4117 - val_accuracy: 0.5402\n",
      "Epoch 802/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1602 - mse: 0.0548 - accuracy: 0.9052 - val_loss: 3.5078 - val_mse: 0.3952 - val_accuracy: 0.5717\n",
      "Epoch 803/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1605 - mse: 0.0548 - accuracy: 0.9093 - val_loss: 3.0682 - val_mse: 0.3993 - val_accuracy: 0.5391\n",
      "Epoch 804/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1565 - mse: 0.0542 - accuracy: 0.9123 - val_loss: 3.4927 - val_mse: 0.4202 - val_accuracy: 0.5293\n",
      "Epoch 805/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1578 - mse: 0.0546 - accuracy: 0.9109 - val_loss: 3.2840 - val_mse: 0.4092 - val_accuracy: 0.5370\n",
      "Epoch 806/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1554 - mse: 0.0539 - accuracy: 0.9109 - val_loss: 3.4152 - val_mse: 0.4094 - val_accuracy: 0.5424\n",
      "Epoch 807/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1645 - mse: 0.0568 - accuracy: 0.9044 - val_loss: 3.3370 - val_mse: 0.4189 - val_accuracy: 0.5326\n",
      "Epoch 808/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1635 - mse: 0.0561 - accuracy: 0.9082 - val_loss: 3.5893 - val_mse: 0.4084 - val_accuracy: 0.5576\n",
      "Epoch 809/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1669 - mse: 0.0567 - accuracy: 0.9071 - val_loss: 3.2608 - val_mse: 0.4177 - val_accuracy: 0.5337\n",
      "Epoch 810/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1685 - mse: 0.0574 - accuracy: 0.9068 - val_loss: 3.0341 - val_mse: 0.4028 - val_accuracy: 0.5304\n",
      "Epoch 811/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1716 - mse: 0.0584 - accuracy: 0.9057 - val_loss: 3.2005 - val_mse: 0.4195 - val_accuracy: 0.5228\n",
      "Epoch 812/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1598 - mse: 0.0541 - accuracy: 0.9079 - val_loss: 3.4375 - val_mse: 0.4224 - val_accuracy: 0.5391\n",
      "Epoch 813/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1504 - mse: 0.0525 - accuracy: 0.9109 - val_loss: 3.9833 - val_mse: 0.4442 - val_accuracy: 0.5283\n",
      "Epoch 814/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1637 - mse: 0.0556 - accuracy: 0.9068 - val_loss: 3.4654 - val_mse: 0.4119 - val_accuracy: 0.5478\n",
      "Epoch 815/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1553 - mse: 0.0543 - accuracy: 0.9074 - val_loss: 3.4933 - val_mse: 0.4248 - val_accuracy: 0.5261\n",
      "Epoch 816/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1604 - mse: 0.0542 - accuracy: 0.9117 - val_loss: 3.4591 - val_mse: 0.4266 - val_accuracy: 0.5141\n",
      "Epoch 817/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1540 - mse: 0.0535 - accuracy: 0.9079 - val_loss: 3.2701 - val_mse: 0.4019 - val_accuracy: 0.5478\n",
      "Epoch 818/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1673 - mse: 0.0565 - accuracy: 0.9068 - val_loss: 3.0885 - val_mse: 0.3832 - val_accuracy: 0.5630\n",
      "Epoch 819/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1727 - mse: 0.0574 - accuracy: 0.9087 - val_loss: 3.2037 - val_mse: 0.4211 - val_accuracy: 0.5239\n",
      "Epoch 820/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1696 - mse: 0.0573 - accuracy: 0.9079 - val_loss: 3.4665 - val_mse: 0.4260 - val_accuracy: 0.5283\n",
      "Epoch 821/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1679 - mse: 0.0568 - accuracy: 0.9065 - val_loss: 3.3863 - val_mse: 0.4219 - val_accuracy: 0.5250\n",
      "Epoch 822/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1767 - mse: 0.0585 - accuracy: 0.9049 - val_loss: 3.2513 - val_mse: 0.4059 - val_accuracy: 0.5467\n",
      "Epoch 823/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1691 - mse: 0.0579 - accuracy: 0.9036 - val_loss: 3.3533 - val_mse: 0.4134 - val_accuracy: 0.5380\n",
      "Epoch 824/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1638 - mse: 0.0567 - accuracy: 0.9057 - val_loss: 3.3590 - val_mse: 0.4144 - val_accuracy: 0.5359\n",
      "Epoch 825/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1534 - mse: 0.0532 - accuracy: 0.9139 - val_loss: 3.2398 - val_mse: 0.4142 - val_accuracy: 0.5293\n",
      "Epoch 826/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1533 - mse: 0.0532 - accuracy: 0.9109 - val_loss: 3.4595 - val_mse: 0.4169 - val_accuracy: 0.5380\n",
      "Epoch 827/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1545 - mse: 0.0531 - accuracy: 0.9098 - val_loss: 3.6138 - val_mse: 0.4215 - val_accuracy: 0.5413\n",
      "Epoch 828/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1542 - mse: 0.0532 - accuracy: 0.9098 - val_loss: 3.6660 - val_mse: 0.4270 - val_accuracy: 0.5315\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1528 - mse: 0.0531 - accuracy: 0.9120 - val_loss: 3.7660 - val_mse: 0.4337 - val_accuracy: 0.5283\n",
      "Epoch 830/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1622 - mse: 0.0561 - accuracy: 0.9074 - val_loss: 3.5505 - val_mse: 0.4348 - val_accuracy: 0.5130\n",
      "Epoch 831/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1576 - mse: 0.0542 - accuracy: 0.9101 - val_loss: 3.5830 - val_mse: 0.4118 - val_accuracy: 0.5402\n",
      "Epoch 832/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.2095 - mse: 0.0674 - accuracy: 0.8962 - val_loss: 2.9263 - val_mse: 0.3984 - val_accuracy: 0.5467\n",
      "Epoch 833/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1607 - mse: 0.0550 - accuracy: 0.9117 - val_loss: 3.4715 - val_mse: 0.4011 - val_accuracy: 0.5674\n",
      "Epoch 834/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1582 - mse: 0.0545 - accuracy: 0.9087 - val_loss: 3.3444 - val_mse: 0.4138 - val_accuracy: 0.5380\n",
      "Epoch 835/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1545 - mse: 0.0537 - accuracy: 0.9106 - val_loss: 3.4557 - val_mse: 0.4171 - val_accuracy: 0.5402\n",
      "Epoch 836/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1522 - mse: 0.0532 - accuracy: 0.9109 - val_loss: 3.6091 - val_mse: 0.4260 - val_accuracy: 0.5293\n",
      "Epoch 837/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1551 - mse: 0.0539 - accuracy: 0.9120 - val_loss: 3.3648 - val_mse: 0.4157 - val_accuracy: 0.5326\n",
      "Epoch 838/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1664 - mse: 0.0559 - accuracy: 0.9084 - val_loss: 3.3815 - val_mse: 0.4143 - val_accuracy: 0.5315\n",
      "Epoch 839/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1614 - mse: 0.0551 - accuracy: 0.9074 - val_loss: 3.1650 - val_mse: 0.4199 - val_accuracy: 0.5185\n",
      "Epoch 840/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1545 - mse: 0.0534 - accuracy: 0.9120 - val_loss: 3.3716 - val_mse: 0.4227 - val_accuracy: 0.5250\n",
      "Epoch 841/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1577 - mse: 0.0537 - accuracy: 0.9095 - val_loss: 3.3564 - val_mse: 0.4233 - val_accuracy: 0.5261\n",
      "Epoch 842/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1671 - mse: 0.0576 - accuracy: 0.9046 - val_loss: 3.4945 - val_mse: 0.4270 - val_accuracy: 0.5261\n",
      "Epoch 843/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1816 - mse: 0.0602 - accuracy: 0.9017 - val_loss: 3.2268 - val_mse: 0.4219 - val_accuracy: 0.5239\n",
      "Epoch 844/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1568 - mse: 0.0544 - accuracy: 0.9087 - val_loss: 3.1660 - val_mse: 0.4043 - val_accuracy: 0.5457\n",
      "Epoch 845/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1587 - mse: 0.0541 - accuracy: 0.9120 - val_loss: 3.0501 - val_mse: 0.4101 - val_accuracy: 0.5326\n",
      "Epoch 846/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1560 - mse: 0.0535 - accuracy: 0.9120 - val_loss: 3.2054 - val_mse: 0.4110 - val_accuracy: 0.5359\n",
      "Epoch 847/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1569 - mse: 0.0543 - accuracy: 0.9093 - val_loss: 3.4539 - val_mse: 0.4140 - val_accuracy: 0.5424\n",
      "Epoch 848/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1532 - mse: 0.0533 - accuracy: 0.9117 - val_loss: 3.5089 - val_mse: 0.4212 - val_accuracy: 0.5326\n",
      "Epoch 849/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1546 - mse: 0.0539 - accuracy: 0.9087 - val_loss: 3.2504 - val_mse: 0.4107 - val_accuracy: 0.5413\n",
      "Epoch 850/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1571 - mse: 0.0544 - accuracy: 0.9093 - val_loss: 3.4503 - val_mse: 0.4153 - val_accuracy: 0.5402\n",
      "Epoch 851/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1527 - mse: 0.0533 - accuracy: 0.9112 - val_loss: 3.5615 - val_mse: 0.4171 - val_accuracy: 0.5380\n",
      "Epoch 852/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1526 - mse: 0.0531 - accuracy: 0.9117 - val_loss: 3.5147 - val_mse: 0.4041 - val_accuracy: 0.5576\n",
      "Epoch 853/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1575 - mse: 0.0538 - accuracy: 0.9117 - val_loss: 3.8443 - val_mse: 0.4337 - val_accuracy: 0.5239\n",
      "Epoch 854/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1582 - mse: 0.0545 - accuracy: 0.9090 - val_loss: 3.6577 - val_mse: 0.4278 - val_accuracy: 0.5228\n",
      "Epoch 855/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1588 - mse: 0.0552 - accuracy: 0.9060 - val_loss: 3.7773 - val_mse: 0.4170 - val_accuracy: 0.5522\n",
      "Epoch 856/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1842 - mse: 0.0614 - accuracy: 0.8979 - val_loss: 3.1758 - val_mse: 0.4069 - val_accuracy: 0.5380\n",
      "Epoch 857/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1605 - mse: 0.0556 - accuracy: 0.9044 - val_loss: 3.3075 - val_mse: 0.4102 - val_accuracy: 0.5446\n",
      "Epoch 858/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1678 - mse: 0.0568 - accuracy: 0.9049 - val_loss: 3.3343 - val_mse: 0.4177 - val_accuracy: 0.5359\n",
      "Epoch 859/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1554 - mse: 0.0532 - accuracy: 0.9101 - val_loss: 3.3144 - val_mse: 0.4102 - val_accuracy: 0.5380\n",
      "Epoch 860/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1555 - mse: 0.0535 - accuracy: 0.9109 - val_loss: 3.5400 - val_mse: 0.4367 - val_accuracy: 0.5163\n",
      "Epoch 861/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1567 - mse: 0.0539 - accuracy: 0.9120 - val_loss: 3.3891 - val_mse: 0.4293 - val_accuracy: 0.5152\n",
      "Epoch 862/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1576 - mse: 0.0546 - accuracy: 0.9076 - val_loss: 3.4331 - val_mse: 0.4330 - val_accuracy: 0.5239\n",
      "Epoch 863/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1617 - mse: 0.0551 - accuracy: 0.9109 - val_loss: 3.3656 - val_mse: 0.4188 - val_accuracy: 0.5391\n",
      "Epoch 864/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1679 - mse: 0.0567 - accuracy: 0.9093 - val_loss: 3.6406 - val_mse: 0.4242 - val_accuracy: 0.5359\n",
      "Epoch 865/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1624 - mse: 0.0561 - accuracy: 0.9049 - val_loss: 3.5126 - val_mse: 0.4220 - val_accuracy: 0.5359\n",
      "Epoch 866/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1634 - mse: 0.0561 - accuracy: 0.9079 - val_loss: 3.1162 - val_mse: 0.4028 - val_accuracy: 0.5402\n",
      "Epoch 867/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1623 - mse: 0.0554 - accuracy: 0.9101 - val_loss: 3.4001 - val_mse: 0.4171 - val_accuracy: 0.5380\n",
      "Epoch 868/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1645 - mse: 0.0567 - accuracy: 0.9055 - val_loss: 3.4432 - val_mse: 0.4287 - val_accuracy: 0.5239\n",
      "Epoch 869/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1568 - mse: 0.0543 - accuracy: 0.9093 - val_loss: 3.3769 - val_mse: 0.4082 - val_accuracy: 0.5370\n",
      "Epoch 870/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1581 - mse: 0.0549 - accuracy: 0.9098 - val_loss: 3.2325 - val_mse: 0.4030 - val_accuracy: 0.5391\n",
      "Epoch 871/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1550 - mse: 0.0539 - accuracy: 0.9095 - val_loss: 3.3856 - val_mse: 0.4223 - val_accuracy: 0.5272\n",
      "Epoch 872/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1638 - mse: 0.0560 - accuracy: 0.9068 - val_loss: 3.2430 - val_mse: 0.4045 - val_accuracy: 0.5435\n",
      "Epoch 873/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1746 - mse: 0.0588 - accuracy: 0.9041 - val_loss: 3.7897 - val_mse: 0.4404 - val_accuracy: 0.5304\n",
      "Epoch 874/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1764 - mse: 0.0591 - accuracy: 0.9017 - val_loss: 3.3597 - val_mse: 0.4068 - val_accuracy: 0.5511\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1558 - mse: 0.0537 - accuracy: 0.9101 - val_loss: 3.3663 - val_mse: 0.4295 - val_accuracy: 0.5163\n",
      "Epoch 876/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1566 - mse: 0.0534 - accuracy: 0.9120 - val_loss: 3.6017 - val_mse: 0.4432 - val_accuracy: 0.4978\n",
      "Epoch 877/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1905 - mse: 0.0633 - accuracy: 0.8998 - val_loss: 3.2640 - val_mse: 0.4153 - val_accuracy: 0.5413\n",
      "Epoch 878/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1571 - mse: 0.0546 - accuracy: 0.9063 - val_loss: 3.4233 - val_mse: 0.4300 - val_accuracy: 0.5261\n",
      "Epoch 879/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1505 - mse: 0.0525 - accuracy: 0.9093 - val_loss: 3.2588 - val_mse: 0.4066 - val_accuracy: 0.5467\n",
      "Epoch 880/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1497 - mse: 0.0520 - accuracy: 0.9128 - val_loss: 3.4767 - val_mse: 0.4127 - val_accuracy: 0.5402\n",
      "Epoch 881/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1501 - mse: 0.0526 - accuracy: 0.9109 - val_loss: 3.4399 - val_mse: 0.4217 - val_accuracy: 0.5207\n",
      "Epoch 882/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1518 - mse: 0.0526 - accuracy: 0.9112 - val_loss: 3.4709 - val_mse: 0.4242 - val_accuracy: 0.5250\n",
      "Epoch 883/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1497 - mse: 0.0520 - accuracy: 0.9136 - val_loss: 3.4847 - val_mse: 0.4315 - val_accuracy: 0.5130\n",
      "Epoch 884/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1545 - mse: 0.0531 - accuracy: 0.9098 - val_loss: 3.4052 - val_mse: 0.4169 - val_accuracy: 0.5293\n",
      "Epoch 885/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1583 - mse: 0.0549 - accuracy: 0.9065 - val_loss: 3.2233 - val_mse: 0.3998 - val_accuracy: 0.5435\n",
      "Epoch 886/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1511 - mse: 0.0526 - accuracy: 0.9098 - val_loss: 3.4821 - val_mse: 0.4216 - val_accuracy: 0.5261\n",
      "Epoch 887/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1612 - mse: 0.0547 - accuracy: 0.9101 - val_loss: 3.4985 - val_mse: 0.4215 - val_accuracy: 0.5304\n",
      "Epoch 888/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1569 - mse: 0.0547 - accuracy: 0.9055 - val_loss: 3.5597 - val_mse: 0.4276 - val_accuracy: 0.5293\n",
      "Epoch 889/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1677 - mse: 0.0569 - accuracy: 0.9093 - val_loss: 3.6138 - val_mse: 0.4166 - val_accuracy: 0.5413\n",
      "Epoch 890/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1569 - mse: 0.0539 - accuracy: 0.9101 - val_loss: 3.3680 - val_mse: 0.4005 - val_accuracy: 0.5500\n",
      "Epoch 891/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2086 - mse: 0.0666 - accuracy: 0.8930 - val_loss: 3.2459 - val_mse: 0.4122 - val_accuracy: 0.5326\n",
      "Epoch 892/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1845 - mse: 0.0611 - accuracy: 0.9025 - val_loss: 3.1023 - val_mse: 0.4280 - val_accuracy: 0.5130\n",
      "Epoch 893/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1547 - mse: 0.0533 - accuracy: 0.9123 - val_loss: 3.2665 - val_mse: 0.4295 - val_accuracy: 0.5217\n",
      "Epoch 894/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1506 - mse: 0.0525 - accuracy: 0.9125 - val_loss: 3.3435 - val_mse: 0.4297 - val_accuracy: 0.5250\n",
      "Epoch 895/1000\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.1473 - mse: 0.0514 - accuracy: 0.9133 - val_loss: 3.4460 - val_mse: 0.4353 - val_accuracy: 0.5207\n",
      "Epoch 896/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1486 - mse: 0.0518 - accuracy: 0.9166 - val_loss: 3.4704 - val_mse: 0.4385 - val_accuracy: 0.5109\n",
      "Epoch 897/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1496 - mse: 0.0519 - accuracy: 0.9123 - val_loss: 3.9265 - val_mse: 0.4428 - val_accuracy: 0.5174\n",
      "Epoch 898/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1544 - mse: 0.0534 - accuracy: 0.9117 - val_loss: 3.4362 - val_mse: 0.4118 - val_accuracy: 0.5500\n",
      "Epoch 899/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1621 - mse: 0.0554 - accuracy: 0.9098 - val_loss: 3.4402 - val_mse: 0.4275 - val_accuracy: 0.5196\n",
      "Epoch 900/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1632 - mse: 0.0563 - accuracy: 0.9055 - val_loss: 3.5489 - val_mse: 0.4131 - val_accuracy: 0.5457\n",
      "Epoch 901/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1592 - mse: 0.0547 - accuracy: 0.9101 - val_loss: 2.9360 - val_mse: 0.4087 - val_accuracy: 0.5315\n",
      "Epoch 902/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1572 - mse: 0.0544 - accuracy: 0.9090 - val_loss: 3.4018 - val_mse: 0.4286 - val_accuracy: 0.5196\n",
      "Epoch 903/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1527 - mse: 0.0532 - accuracy: 0.9095 - val_loss: 3.5109 - val_mse: 0.4046 - val_accuracy: 0.5489\n",
      "Epoch 904/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1561 - mse: 0.0536 - accuracy: 0.9087 - val_loss: 3.5616 - val_mse: 0.4232 - val_accuracy: 0.5380\n",
      "Epoch 905/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1517 - mse: 0.0527 - accuracy: 0.9117 - val_loss: 3.7508 - val_mse: 0.4339 - val_accuracy: 0.5250\n",
      "Epoch 906/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1690 - mse: 0.0571 - accuracy: 0.9068 - val_loss: 3.0411 - val_mse: 0.4023 - val_accuracy: 0.5391\n",
      "Epoch 907/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1654 - mse: 0.0563 - accuracy: 0.9065 - val_loss: 3.1376 - val_mse: 0.4295 - val_accuracy: 0.5054\n",
      "Epoch 908/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1567 - mse: 0.0534 - accuracy: 0.9109 - val_loss: 3.4829 - val_mse: 0.4332 - val_accuracy: 0.5163\n",
      "Epoch 909/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1502 - mse: 0.0522 - accuracy: 0.9177 - val_loss: 3.6652 - val_mse: 0.4077 - val_accuracy: 0.5533\n",
      "Epoch 910/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1549 - mse: 0.0538 - accuracy: 0.9131 - val_loss: 3.5899 - val_mse: 0.4110 - val_accuracy: 0.5435\n",
      "Epoch 911/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1586 - mse: 0.0546 - accuracy: 0.9082 - val_loss: 3.4926 - val_mse: 0.4166 - val_accuracy: 0.5348\n",
      "Epoch 912/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1558 - mse: 0.0537 - accuracy: 0.9098 - val_loss: 3.4524 - val_mse: 0.4186 - val_accuracy: 0.5337\n",
      "Epoch 913/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1639 - mse: 0.0559 - accuracy: 0.9068 - val_loss: 3.2746 - val_mse: 0.3798 - val_accuracy: 0.5696\n",
      "Epoch 914/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1713 - mse: 0.0572 - accuracy: 0.9060 - val_loss: 3.3617 - val_mse: 0.4257 - val_accuracy: 0.5261\n",
      "Epoch 915/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1628 - mse: 0.0554 - accuracy: 0.9071 - val_loss: 3.4288 - val_mse: 0.4225 - val_accuracy: 0.5337\n",
      "Epoch 916/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1515 - mse: 0.0529 - accuracy: 0.9114 - val_loss: 3.4963 - val_mse: 0.4195 - val_accuracy: 0.5326\n",
      "Epoch 917/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1516 - mse: 0.0528 - accuracy: 0.9082 - val_loss: 3.7933 - val_mse: 0.4100 - val_accuracy: 0.5587\n",
      "Epoch 918/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1592 - mse: 0.0537 - accuracy: 0.9120 - val_loss: 3.5909 - val_mse: 0.4222 - val_accuracy: 0.5304\n",
      "Epoch 919/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1609 - mse: 0.0548 - accuracy: 0.9076 - val_loss: 3.4693 - val_mse: 0.4111 - val_accuracy: 0.5424\n",
      "Epoch 920/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1655 - mse: 0.0567 - accuracy: 0.9068 - val_loss: 3.4506 - val_mse: 0.4204 - val_accuracy: 0.5304\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1693 - mse: 0.0571 - accuracy: 0.9082 - val_loss: 3.3473 - val_mse: 0.4042 - val_accuracy: 0.5533\n",
      "Epoch 922/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1598 - mse: 0.0548 - accuracy: 0.9093 - val_loss: 3.4571 - val_mse: 0.4370 - val_accuracy: 0.5109\n",
      "Epoch 923/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1625 - mse: 0.0555 - accuracy: 0.9104 - val_loss: 3.4918 - val_mse: 0.4353 - val_accuracy: 0.5239\n",
      "Epoch 924/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1593 - mse: 0.0543 - accuracy: 0.9098 - val_loss: 3.2852 - val_mse: 0.4094 - val_accuracy: 0.5348\n",
      "Epoch 925/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1556 - mse: 0.0539 - accuracy: 0.9117 - val_loss: 3.2180 - val_mse: 0.4009 - val_accuracy: 0.5489\n",
      "Epoch 926/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1555 - mse: 0.0536 - accuracy: 0.9112 - val_loss: 3.7469 - val_mse: 0.4384 - val_accuracy: 0.5272\n",
      "Epoch 927/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1595 - mse: 0.0548 - accuracy: 0.9076 - val_loss: 3.4534 - val_mse: 0.4115 - val_accuracy: 0.5467\n",
      "Epoch 928/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1501 - mse: 0.0523 - accuracy: 0.9106 - val_loss: 3.8485 - val_mse: 0.4355 - val_accuracy: 0.5315\n",
      "Epoch 929/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1530 - mse: 0.0533 - accuracy: 0.9112 - val_loss: 3.5432 - val_mse: 0.4240 - val_accuracy: 0.5337\n",
      "Epoch 930/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1564 - mse: 0.0541 - accuracy: 0.9068 - val_loss: 3.3349 - val_mse: 0.4279 - val_accuracy: 0.5141\n",
      "Epoch 931/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1521 - mse: 0.0530 - accuracy: 0.9106 - val_loss: 3.7589 - val_mse: 0.4217 - val_accuracy: 0.5402\n",
      "Epoch 932/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1584 - mse: 0.0541 - accuracy: 0.9095 - val_loss: 3.6428 - val_mse: 0.4327 - val_accuracy: 0.5293\n",
      "Epoch 933/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1586 - mse: 0.0543 - accuracy: 0.9074 - val_loss: 3.3696 - val_mse: 0.4164 - val_accuracy: 0.5315\n",
      "Epoch 934/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1645 - mse: 0.0562 - accuracy: 0.9065 - val_loss: 3.5228 - val_mse: 0.4269 - val_accuracy: 0.5283\n",
      "Epoch 935/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1599 - mse: 0.0547 - accuracy: 0.9087 - val_loss: 3.3705 - val_mse: 0.4177 - val_accuracy: 0.5326\n",
      "Epoch 936/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1578 - mse: 0.0545 - accuracy: 0.9076 - val_loss: 3.3861 - val_mse: 0.3996 - val_accuracy: 0.5522\n",
      "Epoch 937/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1570 - mse: 0.0547 - accuracy: 0.9076 - val_loss: 3.2809 - val_mse: 0.3897 - val_accuracy: 0.5641\n",
      "Epoch 938/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1563 - mse: 0.0539 - accuracy: 0.9079 - val_loss: 3.4641 - val_mse: 0.4265 - val_accuracy: 0.5283\n",
      "Epoch 939/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1556 - mse: 0.0538 - accuracy: 0.9095 - val_loss: 3.5689 - val_mse: 0.4242 - val_accuracy: 0.5283\n",
      "Epoch 940/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1647 - mse: 0.0549 - accuracy: 0.9101 - val_loss: 3.0922 - val_mse: 0.4047 - val_accuracy: 0.5391\n",
      "Epoch 941/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1510 - mse: 0.0527 - accuracy: 0.9133 - val_loss: 3.6050 - val_mse: 0.4176 - val_accuracy: 0.5424\n",
      "Epoch 942/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1544 - mse: 0.0535 - accuracy: 0.9117 - val_loss: 3.2928 - val_mse: 0.3961 - val_accuracy: 0.5576\n",
      "Epoch 943/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1539 - mse: 0.0535 - accuracy: 0.9098 - val_loss: 3.7890 - val_mse: 0.4241 - val_accuracy: 0.5326\n",
      "Epoch 944/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1634 - mse: 0.0555 - accuracy: 0.9055 - val_loss: 3.4638 - val_mse: 0.4199 - val_accuracy: 0.5337\n",
      "Epoch 945/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1546 - mse: 0.0536 - accuracy: 0.9142 - val_loss: 3.6998 - val_mse: 0.4288 - val_accuracy: 0.5348\n",
      "Epoch 946/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1575 - mse: 0.0543 - accuracy: 0.9093 - val_loss: 3.5272 - val_mse: 0.4164 - val_accuracy: 0.5391\n",
      "Epoch 947/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1673 - mse: 0.0563 - accuracy: 0.9052 - val_loss: 3.2965 - val_mse: 0.4188 - val_accuracy: 0.5239\n",
      "Epoch 948/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1703 - mse: 0.0572 - accuracy: 0.9060 - val_loss: 3.5676 - val_mse: 0.4305 - val_accuracy: 0.5326\n",
      "Epoch 949/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1760 - mse: 0.0587 - accuracy: 0.9041 - val_loss: 2.7535 - val_mse: 0.4126 - val_accuracy: 0.5098\n",
      "Epoch 950/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1566 - mse: 0.0535 - accuracy: 0.9104 - val_loss: 3.3555 - val_mse: 0.4167 - val_accuracy: 0.5391\n",
      "Epoch 951/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1499 - mse: 0.0522 - accuracy: 0.9139 - val_loss: 3.5943 - val_mse: 0.4086 - val_accuracy: 0.5533\n",
      "Epoch 952/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1489 - mse: 0.0518 - accuracy: 0.9079 - val_loss: 3.5235 - val_mse: 0.4163 - val_accuracy: 0.5402\n",
      "Epoch 953/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1513 - mse: 0.0519 - accuracy: 0.9136 - val_loss: 3.4685 - val_mse: 0.4087 - val_accuracy: 0.5533\n",
      "Epoch 954/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1495 - mse: 0.0520 - accuracy: 0.9117 - val_loss: 3.6486 - val_mse: 0.4259 - val_accuracy: 0.5337\n",
      "Epoch 955/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1683 - mse: 0.0575 - accuracy: 0.9068 - val_loss: 3.1865 - val_mse: 0.4216 - val_accuracy: 0.5196\n",
      "Epoch 956/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1556 - mse: 0.0537 - accuracy: 0.9101 - val_loss: 3.4932 - val_mse: 0.4253 - val_accuracy: 0.5283\n",
      "Epoch 957/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1546 - mse: 0.0533 - accuracy: 0.9117 - val_loss: 3.5625 - val_mse: 0.4310 - val_accuracy: 0.5217\n",
      "Epoch 958/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1666 - mse: 0.0543 - accuracy: 0.9093 - val_loss: 3.1908 - val_mse: 0.4158 - val_accuracy: 0.5304\n",
      "Epoch 959/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1591 - mse: 0.0534 - accuracy: 0.9104 - val_loss: 3.4449 - val_mse: 0.4136 - val_accuracy: 0.5370\n",
      "Epoch 960/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1550 - mse: 0.0533 - accuracy: 0.9104 - val_loss: 3.5658 - val_mse: 0.4234 - val_accuracy: 0.5337\n",
      "Epoch 961/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1519 - mse: 0.0527 - accuracy: 0.9106 - val_loss: 3.5784 - val_mse: 0.4251 - val_accuracy: 0.5283\n",
      "Epoch 962/1000\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.1565 - mse: 0.0539 - accuracy: 0.9079 - val_loss: 3.3189 - val_mse: 0.4244 - val_accuracy: 0.5207\n",
      "Epoch 963/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1658 - mse: 0.0566 - accuracy: 0.9036 - val_loss: 3.3532 - val_mse: 0.4233 - val_accuracy: 0.5163\n",
      "Epoch 964/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1722 - mse: 0.0577 - accuracy: 0.9041 - val_loss: 3.7092 - val_mse: 0.4419 - val_accuracy: 0.5120\n",
      "Epoch 965/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1552 - mse: 0.0534 - accuracy: 0.9087 - val_loss: 3.3998 - val_mse: 0.4157 - val_accuracy: 0.5402\n",
      "Epoch 966/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1569 - mse: 0.0539 - accuracy: 0.9117 - val_loss: 3.3246 - val_mse: 0.4129 - val_accuracy: 0.5380\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1546 - mse: 0.0537 - accuracy: 0.9087 - val_loss: 3.4155 - val_mse: 0.4274 - val_accuracy: 0.5174\n",
      "Epoch 968/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1570 - mse: 0.0540 - accuracy: 0.9098 - val_loss: 3.5037 - val_mse: 0.4286 - val_accuracy: 0.5207\n",
      "Epoch 969/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1525 - mse: 0.0528 - accuracy: 0.9147 - val_loss: 3.2626 - val_mse: 0.3954 - val_accuracy: 0.5609\n",
      "Epoch 970/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1519 - mse: 0.0528 - accuracy: 0.9090 - val_loss: 3.9246 - val_mse: 0.4437 - val_accuracy: 0.5163\n",
      "Epoch 971/1000\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.1678 - mse: 0.0569 - accuracy: 0.9090 - val_loss: 3.7766 - val_mse: 0.4376 - val_accuracy: 0.5120\n",
      "Epoch 972/1000\n",
      "148/148 [==============================] - 1s 3ms/step - loss: 0.1555 - mse: 0.0537 - accuracy: 0.9098 - val_loss: 3.7555 - val_mse: 0.4360 - val_accuracy: 0.5174\n",
      "Epoch 973/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1516 - mse: 0.0529 - accuracy: 0.9136 - val_loss: 3.4713 - val_mse: 0.4103 - val_accuracy: 0.5446\n",
      "Epoch 974/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1548 - mse: 0.0532 - accuracy: 0.9104 - val_loss: 3.2958 - val_mse: 0.4099 - val_accuracy: 0.5348\n",
      "Epoch 975/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1514 - mse: 0.0525 - accuracy: 0.9109 - val_loss: 3.3887 - val_mse: 0.4223 - val_accuracy: 0.5228\n",
      "Epoch 976/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1554 - mse: 0.0533 - accuracy: 0.9125 - val_loss: 3.3990 - val_mse: 0.4241 - val_accuracy: 0.5293\n",
      "Epoch 977/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1527 - mse: 0.0530 - accuracy: 0.9131 - val_loss: 3.6078 - val_mse: 0.4081 - val_accuracy: 0.5576\n",
      "Epoch 978/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1593 - mse: 0.0541 - accuracy: 0.9087 - val_loss: 3.2883 - val_mse: 0.4243 - val_accuracy: 0.5207\n",
      "Epoch 979/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1849 - mse: 0.0611 - accuracy: 0.8979 - val_loss: 3.2406 - val_mse: 0.4102 - val_accuracy: 0.5272\n",
      "Epoch 980/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1615 - mse: 0.0552 - accuracy: 0.9065 - val_loss: 3.4971 - val_mse: 0.4103 - val_accuracy: 0.5511\n",
      "Epoch 981/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1558 - mse: 0.0539 - accuracy: 0.9101 - val_loss: 3.4062 - val_mse: 0.4182 - val_accuracy: 0.5337\n",
      "Epoch 982/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1491 - mse: 0.0518 - accuracy: 0.9169 - val_loss: 3.6133 - val_mse: 0.4262 - val_accuracy: 0.5283\n",
      "Epoch 983/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1497 - mse: 0.0520 - accuracy: 0.9123 - val_loss: 3.4053 - val_mse: 0.4206 - val_accuracy: 0.5304\n",
      "Epoch 984/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1512 - mse: 0.0525 - accuracy: 0.9076 - val_loss: 3.5674 - val_mse: 0.4207 - val_accuracy: 0.5315\n",
      "Epoch 985/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1544 - mse: 0.0533 - accuracy: 0.9098 - val_loss: 3.6337 - val_mse: 0.4168 - val_accuracy: 0.5402\n",
      "Epoch 986/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1583 - mse: 0.0546 - accuracy: 0.9101 - val_loss: 3.7553 - val_mse: 0.4381 - val_accuracy: 0.5152\n",
      "Epoch 987/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1674 - mse: 0.0562 - accuracy: 0.9055 - val_loss: 3.2541 - val_mse: 0.4188 - val_accuracy: 0.5250\n",
      "Epoch 988/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1543 - mse: 0.0537 - accuracy: 0.9114 - val_loss: 3.5641 - val_mse: 0.4105 - val_accuracy: 0.5446\n",
      "Epoch 989/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1547 - mse: 0.0538 - accuracy: 0.9084 - val_loss: 3.7274 - val_mse: 0.4127 - val_accuracy: 0.5489\n",
      "Epoch 990/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1707 - mse: 0.0572 - accuracy: 0.9065 - val_loss: 3.5644 - val_mse: 0.4279 - val_accuracy: 0.5370\n",
      "Epoch 991/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1746 - mse: 0.0585 - accuracy: 0.9074 - val_loss: 3.4943 - val_mse: 0.4088 - val_accuracy: 0.5587\n",
      "Epoch 992/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1557 - mse: 0.0537 - accuracy: 0.9063 - val_loss: 3.5563 - val_mse: 0.4083 - val_accuracy: 0.5478\n",
      "Epoch 993/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1576 - mse: 0.0544 - accuracy: 0.9142 - val_loss: 3.6782 - val_mse: 0.4405 - val_accuracy: 0.5207\n",
      "Epoch 994/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1514 - mse: 0.0529 - accuracy: 0.9082 - val_loss: 3.5038 - val_mse: 0.4272 - val_accuracy: 0.5228\n",
      "Epoch 995/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1503 - mse: 0.0523 - accuracy: 0.9123 - val_loss: 3.7100 - val_mse: 0.4189 - val_accuracy: 0.5413\n",
      "Epoch 996/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1489 - mse: 0.0516 - accuracy: 0.9152 - val_loss: 3.6852 - val_mse: 0.4290 - val_accuracy: 0.5283\n",
      "Epoch 997/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1506 - mse: 0.0521 - accuracy: 0.9120 - val_loss: 3.8440 - val_mse: 0.4364 - val_accuracy: 0.5207\n",
      "Epoch 998/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1504 - mse: 0.0523 - accuracy: 0.9112 - val_loss: 3.8002 - val_mse: 0.4235 - val_accuracy: 0.5326\n",
      "Epoch 999/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1516 - mse: 0.0524 - accuracy: 0.9144 - val_loss: 3.4741 - val_mse: 0.4291 - val_accuracy: 0.5250\n",
      "Epoch 1000/1000\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1531 - mse: 0.0532 - accuracy: 0.9125 - val_loss: 3.6622 - val_mse: 0.4257 - val_accuracy: 0.5217\n"
     ]
    }
   ],
   "source": [
    "hist =  model.fit(x=train_x, y=train_y,\n",
    "                  epochs=1000, batch_size=25,\n",
    "                  validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ef8b97d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlQAAAEvCAYAAACDlV+2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAB7WElEQVR4nO2dZ5gUVdaA39s9OQFDHBgQEJCcBRRRQEVgVRQTxg8MGDCsadXdNe66q66rmDOuuiqogLqKCcyCkiQHCRKGOIQZhsk9fb8f1T1dnaa7Z3o6zJz3efqpqlu3qk6nW6fOPUFprREEQRAEQRBqjyXaAgiCIAiCIMQ7olAJgiAIgiDUEVGoBEEQBEEQ6ogoVIIgCIIgCHVEFCpBEARBEIQ6IgqVIAiCIAhCHUmI1oVbtGihO3bsGK3LC4IQBZYtW3ZAa90y2nKEAxnDBKFxEWj8ippC1bFjR5YuXRqtywuCEAWUUtujLUO4kDFMEBoXgcYvmfITBEEQBEGoI6JQCYIgCIIg1BFRqARBEARBEOqIKFSCIAiCIAh1RBQqQRAEQRCEOhK0QqWUsiqlflVKfeJjn1JKPa2U2qyUWqWUGhheMQVBEARBEGKXUCxUtwDr/ewbB3R1vKYCL9RRLkEQBEEQhLghKIVKKZUL/AF41U+XCcCb2uBnoKlSKidMMgqCIAiCIMQ0wVqopgN/Aux+9rcDdpq28xxtgiAIgiAIDZ6ACpVS6kxgv9Z6WU3dfLRpH+eaqpRaqpRamp+fH4KYgtBIKNoHe1dHW4q4RCk1Vim10eHLeXcN/Y5XSlUppc43tW1TSq1WSq1QSkn6cyE22fYTVJZGWwoDreHglmhLEVMEY6EaDpytlNoGzARGK6X+69EnD2hv2s4FdnueSGv9stZ6sNZ6cMuWDaKclyCEl6f6wYsnRVuKuEMpZQWew/Dn7AlcrJTq6affo8AXPk4zSmvdX2s9uF6FFYTacOh3+M94+ORWqKqE33z9hCPIklfhmYGwc3F05YghAipUWut7tNa5WuuOwCTga631ZR7dPgaucET7DQMKtdZ7wi+uIDRwbDHy9Bl/DAE2a623aq0rMB7+JvjodxMwG9gfSeEEoc6UHzGW+9bAt4/AOxfClm8ic227HRY+A+VFrra8Jcby0NbIyBAH1DoPlVLqOqXUdY7NecBWYDPwCnBDGGQTBEEIloB+nEqpdsC5wIs+jtfAl0qpZUqpqfUmpSDUFQ0c3masFx8IzznXzoVnBoG9yvf+TV/Cl3+FL/5sksPLq6fRE5JCpbX+Vmt9pmP9Ra31i451rbWeprU+VmvdR2stPgiCEG0qiuGjaVByqPbnKD4IPzwRD4NnMH6c04G7tNa+7hrDtdYDMaYMpymlTvZ5EfEDFWKKWvwvf/8Bdi5xb5t7PRzcDLYyY7zwtHw5LeelBT5O6Ouv1ziRTOlC4+TwNtjvL61aA2H5m/Drf+G7R2t/jk/+CAsehG0/hk2seiIYP87BwEyHP+j5wPNKqXMAtNa7Hcv9wFyMKUQvGq0f6Muj4BlxLYsZVB2UmDfOhNdOc2+z21zr71wIb50DFSXmC7pWFz0PGz+r/fUbMKJQCY2Tp/rB88OiLUX9Eg6rUqVjUI2VyCL/LAG6KqU6KaWSMPw9PzZ30Fp30lp3dPiDfgDcoLX+UCmVrpTKBFBKpQNjgDWRFT/G2b0cDm6KthQCuBuEwmU5dipU2u560DQrWWa+uAfeneR7X2UZLPhbbI0X+9ZC+dGIXEoUKkGIFrYKYwCKZSyJxtJeGV05AqC1tgE3YkTvrQfe01qv9fD19Edr4Eel1EpgMfCp1vrz+pVYEAJweBss+49r20158rBQ/fIyPNAEtn5Xy4s5zq3tpnPXQllb/DL88Dgsejb0Y988x9sK+v2/YO2HoZ8LDEf6on3wwomG1S0CJETkKoIgePPsYCjYDg8URlsS/1gdQ0RVbCtUAFrreRgBMuY2Xw7oaK0nm9a3Av3qVThB8IWtApTF9T8z89ZEOLQFep8PyRkOZQcPPcex8dmdxnLZ69D5FPj0dsNh/cI3QpNn5SzXuj8Hdc9rm6cfbY4HxFDHi6pK2OojYvHrvxvLXrUYI3/4N3zjOH77T+77juZDVQU0CW/+cbFQCUK0KNheu+MqS+ueg0Zr+Op+OLC55n7VFiof5v9NX4GtvG5yCEJd2Dw/sr6QBzZDWRgfgP7eEmac4XtfWYGxLC+CmZfCq6f57ueLJa/Cug+N9f+caViv8pZBlZ9pPCef3QkVjtQIPhUqkza3+n0fu53FVEL08frqPu82u7/CLEHyWw1+Xo93gSe90tTVGVGoBCHe+Pxuw4S9e0WQB/gY3Ap2wE/T4e3zvfeZsfpRqPasMo797E9ByiAI9cB/zwvNF3LxK7Dl69pf79lB8OII+FtL2OgxK5y/0Ui+GSq7/ATFJ6QYy+L9sOETMAenOq1CdpuhLNXEth+M5auj/ftF+cLcN1gneOe0pApRtdj5i3db6eEa+i823vf6/wWWxUz+b/UaXCEKlSDEG85Bu6YBJxDmAbkmLH6m/Jw+Vbt/rb0MghBp5t0Bb51bt3MUbDemi779p3v7c0Pg6f51O7eZhGRj+ZKvDB6O/6/N0wczgOJTW4Vqx881dDRd02mhCkYBW/2BoRT5S+tS7CctSVkhvHa6sb7oOf/n1z4sXD9Ndw+u+OGJwHKGgChUghBvOJ/+fA0Ybvh4QquyOSJwVHDncCpUnk7pzqlAc+ZkIX4oL4LP7qq/aKyKksDTyeGmygaFeXU7R8mh4Kf0alIafv8elr1hWEO+uq920XjKGvjaoZ7XZwo2P+xfB0ccBU9+ft7/9ZxTk0YHp4DGIn8j/Pd873GivMhwYAfHlK2Pz9KpUCWkGtnYnb9V8292x6Ia3kAQn82CBwP3CQFRqAShvqksgy/+Ej7lw6lQmX0c5lwLH/opUGAe+P97LjzcxntA/uUleNtHJIxzys/T98JpsRIfqvjkxyfhlxcNX5tQ+fyewCVP3rvcmB7z9IOxV8ELw2ueqqkt3z0CT/YylCpbRRBO1Q60hm/+AUd2w2Od4NGO/vu54UehWvwKvHEW/O9mwxry01PulqTFr8Cnd3gft30h/LMD7FlpbAcTWetUSqpFCmShCkGheudCeKI7vHJqzf3m3eGKLvS0UL0/BTZ/BfvWmWSwwz9zXdN8m7/Cp/LjVKhSm8LTA4xxq7TA+z1s+8nzSHdZ3KjfJKSiUAlCfbPsP0YY8ff/Cv3YPavgqEfZOedgNfNiV9uqmbDi7cDn+/1750kcS2eU0J9gkw9Hd2uSsfScWqiqcJymhqdoIXZxKsSh3GCd/Py8kfgRDCVj+yJvZcPpp+R5U6soNmrRzbk29Os6qSyF2Ve7rCdOti80lge3GM7eb5xlWJz2b6j5fAd+M5LfzrzUt8wf32RMTR34zb3drLzkb3Stz/OhLJmZdwcsecW9zVYOa+ZAeaExvXZwCxTt9XMCDSvfdcluZs1sKNzl2s5b5r7f1/c9++qa5fXn42XmzbMNq2S1D5Xjs3G6JVhM44TntOOPT7pv//c82LXMVVYnKcO17/fvvK1s/xnvWi8+aChsGz71/n1EAFGoBKG+cT5pBoqw8cVLI+C5oe5t1RaqIM9nKzOioXzJVLSn5tI0mTnG8rDDb+u3L4wM7NUKlZSdaNSseBteH2tYY8yZtZ03Vk/lxPnbrQrCslllg8M+ImHXfWxEmHlGhqU2M5aljt/z9p/gldHwvMf/B9wL+jqntZ318TxZ/qaxXPGOxw7Tb3/1B76PdRIoeOPvrVz/55XvwjMDffhHOQg0JWmOXvP0QzIrI04roa9oPX/U5CJgt+FKpeD4np0la5zjhacM1Zg+y83z4eObYd9qYzsxxbUvrYX/h4DCPPhXZ5h/P8y8BEo86hza7fVeJUcUKkGod+r4Ly71UHhCtQotnWE89e1d7WqbY6r/u3u5/2OdU34lB43lOxcaT+xOhcwiFqr4JEwZtg86/KSWvwmf3+W9f89K94AG5w05mIeBr+6Fp/oayorZAubPhzAxzViak+U6HwTA/RxPD3CtO2/2FcXeMpiPMSsFZjmMjj7fQjVOpawmgg30KNxZ834zSenu23mmGn6zLgv+PE42zvO/T1d5p02o9JGXypdC5GkF27fGpcCaxy1ron+l7slextJL8TXJ54vNC3y31wJRqATBE63hx+mhO7huXwgbahhwQpXBn8Npba1CZh8uc5hyTUn4nDJ4DoJLXzeWFh8JCYX4IZwWRl8pA147Db78q2s7YCCFCaef1uyrYNV7rvZq/z/Tb7Ks0KVoVPgpM+LPsuFUlJwPD04KdriPAZ7+gnmLDSva8jeDm87f/at7ioM1s93310cB8jfOdN+ujRIVLFU213uYf7+R2sBpofr9O3h/svH+g7Ws++pXsMO3L+qbE1zrnpYpJ7Yyo7apJ57TpnVARkNB8OTw78aAsHYOXPt94P5OXh9nLP1mPg9hwNR2/wNPbbOW+7NsuZnjteuGtXKmy1fDc7Df8EnN5xQaJjXd9N0UElO/PJP1waxQbf3OyOrtD7Oyd2iLqd2HheqLv7givtyizkx4Wpic2BztntbW6X3ct31Zcl8dTdAWaM+Cwp7JeUNJaRCL2G3u34kztQEYWcud+PsegmH2Vb4f4rZ+G/jY18f7bvdlmawlYqESBE+cT7Jh/KOFjLb7D2kPtq6e583PnzXJrKAtN5WqmHst7F3lOJc/5+V6eKoW6p/aWkNqsjBZk/3vWzkL1n/ift03z4aCGqavzFNqVRWGBWR6H/hgitFmtjiZp22K/Vgo/P1vnDd48//jVx8BHr6m4pwReUHhoXh5fge1CRCIJYIdl/x9P0Ffp5aKp3Ms82RA+Kx2olAJgifVA12YpkNqM62itX+n1No4twNY/PzdzQqVv0Kk/gZ7S6LvdiFOCPG3WdNNP8EREXpwi/e+uVNh1qXeCtnvNVmATbJVVcL3jxlTPr5kSTZFgu3y4xPoz7LrdJA3/5Y/8pOCxBd7VgTf18zq99y31wRwbA834Z6ut9uCsz45c1rFAmktILNN2E4nCpUgeFKdSyXIv0co+W5CkaGyxPe+2prMXx5Z+/P5s0zsWw3lfnxWhIZHjRaqJCNS7pmBwR/vT3HZ8o0ryguMm/V3j7r3MVtEnA7pYPg2efJAE/8lZ5yK1lF/aQrChGfOqGgT7un6pwcYaV4C8etb4b1uXeh/SVhPJwqV0PCpssGsywNHz/zykpG7JJTyCfvXw0PZRqFgv9TGQmWHsiO+97XoZiwtCcYTe51N6OYIHJtRTNUzWV4oGZaF2MczX1CwmMP/35kEC58x7VTeOdPAvXhxsE7pbufFt3VpuylLttly5Y8v/uy+vXKmkSgyUslpPaN1o02wU3ShsLOmEjUxSNMOYT2dKFRCw+fQVlj/cc0J7A5vM24Wsy7FK5dKTTjDxn95sa5SuqPtLufahFT3fZmtjWWviYZPyb+Ordu1zDergh1GMdW513nL4w/P6CghjjApVGWF3gV/PTH72P32mYc/i8bnw0OlyRfR1+/otTOMKK15d7raPP0Xfd38zecNRlnxzMk091ojX9HWAFnfGyItuhnfxZf3Bn/MqfcF7hNvDL4qrKcThUoQDm+Hp/oZ66UF3rlUwHjydibvs1cZyTDtVa4n42Ai70Ip86HtrizDSenupRuc8tWk5Cx+xUjaGdS1fOTa8fS3KjvinXXZifhRxSE+pp8/vAHevShER2vzKe2BLV6+frM7fzaitBa/DEX7jDbP1AcVfqa/68r2n4w8bY2NDMdD2cKngz+mSQdIbhK4X7yQlevfr7SWiEIlNFzKi4zEcoEG+XUfutaV8j0d8t4VRshu0T54ZpBR8+vLe13TCJ4Onoe2GqHCZmXFXmkoXlrDN6ZK9T59q7TLN6nkALxwgsuBt9pny8dxOxcb+YDm3WGUuwkGs6+WUwnz9K/Ys8IRIu6DMA9KQi3Q2rtuXjCYf+POTOEvnVx7GQL2CSDjv7sZU4TlHtPd/lIhCMFj9jNLSPHfryYaUiLfUHKiBYmMhELD5Z+5RtmJNXOMbX83Hc8bgTmb8zf/MJ6OnZnCSw+5si+bnVw9Faq3zoUFDxnHmW9au5bBg02NQq5OnMnmXjXlbdF272kOZ+LEmixUs68O/ebjywdLfKbii8/vgYea1e0c/m6WweY903YC+gsGcxMrzPNO3ui01grBccl73m0TTU7xiane+wOiQ1eozNbrs0KwhoWDcY/VvF8UKkEIkcPb4Nt/GOuHthg3nUo/6QgAUC5lIn+DEVn0xT2ubLr+HMU9FSpnfTzPnCm+pv2cRV3N0Ulae6dHcA5mTuXOl0VAqdDzZ/kK+/ZX10yITX55wVgGG0nqq5+vh42j++FvLYIUIohreya39EViqrdCFSnH8VgnWMtS7vHebeY8YclZNR/fujecdKt7W6dTXONc867BydHWVOKn5XHBHWNmSIAi2r3P979v6LVw8p3+94tCJQhhwDMdgduUoA8r1rL/uNbNdbTMypLntJfTF6myFK98Op6sfMfbP8mXhco5DVedvdzXgKBC9zfZsShwHyE+cP4mKoph2RtBKFim36Yvx+8ju0O7dqCgwS/uCXyekoPeDyLhSnrZrFN4zhMt/OWm8yTFh6+TM08YQEoAhWrfGveHxLOeMoJhnG39JgUnR5JpmjEpw38/fwy8oub9p3gUnU7zUP49A4t6nQun3m+sJ9Zy2rMGAipUSqkUpdRipdRKpdRapdSDPvqMVEoVKqVWOF4NMBxAiBs2zXeVk/CFp0+Vm59TVc1Oqns9cuM48bRQORWnBQ+5t/vL8utpJdLaW/nyNLev/9j3uSp81LoSGge/f2csP78H/ndzcCU5nJh/m3ZH2o5QfG3CVYvuPR830XCVZYk1S9cFbwTuEwx/3Q8TTAkzfU3NhWKhAvfpOufDnFNBSQ/Samm+plm5cjL6r95tZhJqyL5vlsfJea8Yy8nOmqqOsd6pSI//N5xwo2E5O8VHMe86EoyFqhwYrbXuB/QHxiqlhvno94PWur/j9ZCP/YJQv+z4xQi/fvs8WOCl9/vmwGYoMiX0s1cZFiN/mKOPzE/N5rxNe1ZSPf2xdo778c4aeIHwZaEKxn9BWfxPSzZwlFJjlVIblVKblVJ319DveKVUlVLq/FCPjUnMisysy42lM0WAv+SwvqbnzL/nF4fDI+39F5r1xYZP6i/J68FN4TmPr8K60eRYP4EeoZKQHDhJpTUECxW4W3CcD4zOpaclyB8tu7nWfaWh6X9pzcdbk3xb2/yds3lXo5Zqx+GO/Q6Fqs8FRnt6c8NSN/XbsJaccRJQodIGzn9JouMlBbyE2GPGGNcT+aGt/vuZb0DPDnL5n4CRi6cmzMqK+am52JTQcNHz7oNXMA7en97mIaPde5pDWWHDpzWfR6nA76EBopSyAs8B44CewMVKqZ5++j0KfBHqsTHLb6bcUdUBC0EO0WZrbarJqX2/I03Hf/4QmiyhTBFGA5uf+pjRwpoIxwyv3bGXvO++HSia2TzlF4yFymyddD7MORWqlCzDx2rqd3CTn1I/4JpeA/cxEeCMf0BqtnubZ2H5hGToc2FgWT3lrMb5mURGZQnKh0opZVVKrQD2A19prX/x0e0Ex7TgZ0qpXn7OM1UptVQptTQ/P99XF0EwKD5YxymEGgaXmpwRywMoI+b6W/4UpaLd7qburd/VfE5fHNjoPeX3/v8ZiQhrwl5lpE5ofAwBNmutt2qtK4CZwAQf/W4CZmOMZaEeG5uYAwg8f9s7fQ3VuP5bK952KeBdTq27LPXg6BteFNwQA9m8LQmAMsaJk24L2N0n3caE1t9t+i09cH9zJKCnQmVJhNMegLb9obmfxMKdTnFP+pvVFq6aD3/eDWc+aTicm/cPm+ZD5iQY51FyqMdZrnXPKVxP1wunkhmu6egABKVQaa2rtNb9gVxgiFKqt0eX5cAxjmnBZ4AP/ZznZa31YK314JYtW9ZeaqFhk/8b/KtzaIkwQyFcg74/v46qSvenwU1f+O5XE5/dXbvSEId/h40BrFjhoOc59X+N0GgHmCIGyHO0VaOUagecC3imtQ94bEzzuWmG0vO3/dNTULjLyJ92cAt8/mf4cTrVT+x7V8O7FxsFhcPxvwiXr1MotBtsLM99KXA2b4sVmh5T/zIBNOsIo/7ie9/gK+GBAiOYJZx53E65G8Y87HufeUxKy/bdJ9ukHCVnutadPlTOaUB/1rCbf4XzXzfWff2e2h9vKHODrwRrgvF93LgUbt8IY/7u3V9ZjD6XzYFBU4w2SyJ0P9O1361/HFionGitC4BvgbEe7Uec04Ja63lAolIq2FhbQXDHWc5l84L6OX+4MiP7vXkob/N2qOSvN26GscqgyTDijlhSrHyN8J6j6HTgLq29TIvBHGt0jHUre1WF91RxWaGRMPOZgfDzczD/fvf923+CV0aFx2E7Ghaq7M6m6we4cSpL3f+bwVJl8y+P2bfNrAS06QPX+Cni7I/Mtq71UffAiTe673dO75nft/OaVg+nb/OUmVNpAZflxxmp5y81S3Znl7IWrFWoRVfIbONSLJ0K8sl/cvlPdTkVOp7kOEDDOS/AxFehVXcP+aObuCAhUAelVEugUmtdoJRKBU7D8EEw92kD7NNaa6XUEAxF7WB9CCw0JurpqeLbfwbuEwz+fJVUGBSqWMeSAKeGUAes/skD2pu2cwFPh57BwExlPF23AMYrpWxBHgsYVnbgZYDBgwfHpi/pW+e4Z8UO1moUDt+7yiB9lLqNdff9qgtOy0tVBQHHjC6nBg7uGPsofO6IAMtqB0d2BSfH5HmGVepJh/udvdK/POZAGM9ItqwQjKPXfANN2tfcx6nYmKfDnOkXkjOhxKxIm54trInQeZRR69D5mTmtVp6lgcw4lTWnct1uMLT26QXkmys/N6z8vqICnaRkQd8LfF3c92YMTfnlAN8opVYBSzB8qD5RSl2nlHJWUD0fWKOUWgk8DUzSOkLvQGh4eM57B5up2Y0o/vy2/9Q4FKrYYgnQVSnVSSmVBEwC3PJKaK07aa07aq07Ah8AN2itPwzm2LjCWaLIiS+FytfwHI7yLsHkmQICJ6wKkiHXuv5rVRU1/+2PPRUmvuI+XXX+6zDhOfd+ZgVn2i9wx+bgZOk4HJqYlCFnmSlwV3ABep9nup7J+fvsZwxrzZnT3fuPfQSftBsIGX7cZ+7YBHdudclkHpOcClVrj9gLs7UPcBWKdyhJw/9o/Pfb+wr0d2DxUKiuWQBnh5Al3ZroW5kK5HRvvrbrIMcyMveDgKOi1noVMMBH+4um9WeBIAuHCUIgTH+cg1uMqQqA//sEOo0I7hQb5wXuU58kiEIVSbTWNqXUjRjRe1ZghtZ6rfOhzzxeBXtsJOSOCL6m4UoP+WgrqHdRws74x+AzhzWpqtL/lKNn9JiT3hON5Ucmh2jzjTs503j1PMe95ufEV2D+AzVbr8wPgpk5RqUGJ+YUB07n76bHuDKLmyMuoXb/t4xWxvLyD2HHQnefqC6nGVnGT38QmuTCA46ptXNfhEdNPmbV1i2HotL+eLjPx+TTMcNd78Pp11Rf07/+bDWXf+j+HsFIjbD6Axh8Vf3I4kFsjYqC4IaG3b+6Njd/5VuhOpoP3/hxxIwWDd5CFXtFFhz+m/M82nwqUlrryYGOjWvM02m+LFRrZnu3bfuh/uQJF51OcSUvdeJUNoKZ8gsKH5aQfhe7K1R9L4ReE43reZbmuW29ESgw7AZXvc/eE+H7f/m+nNNCVZMl3hwNFypZOYZFzKyIJKbC+a95901t6r7tVIp85ZAyM8X016k3hSqAherYUd5tmW1gWuSiOmNvVBQaHgc2e09D1IR5ys8tMaGfP9TjXWDZ67UWL2Q8c6f4JExTGrFKjFmohBqIRuRdXenjyz8G34lKcx1OzC27u5SGhNoU/3Xga2rpuLHebdYE34pOVlu48E3oMMwVtGGe4vPEadlxlqsCvBRD5wNaZlu4dS3cvML/+fxR05TZqffDFB8+bUcd2UWCzYwO9W+hiuE0mDIqCvXPs4OMpT+zuxemP77ZydXXgODvqa8+SW/he8rEzK6lkZElWniFJwsRZ+VMaDcocD+3G3Uc8Jd9hgKx+n3vfUOvg7wl7m29zoU2fY18SHmO/11CkiuJZ/Mu9StvTbTuGXjcq/YBM1moPKe1ElON0jKdTjam6MLNCD+5sHIHGznxQkk1Uf1AHKGIz+QmgfMHRghRqITYwVlHL8sZBqw9Qrk9FKrfvoCvfeQuqW+UBdJbusp7NEaCKYMj1C9zryUoS+juFfUtSejUZC3xV7TWqZh8eANUeaR4qE4u6VBEnEpKnwuNJJKhCRdi/zriTEUw0kc+sc6jDL+q7mcZFrFI84cn4OQ7gitV46TeLVQe3LIiPAEVYUAUKiF6rJ1rmLA7DIV5f4LFLxnt5lIMNd248zfWr3x+UcT3lJ6izmbzQD4VQoQI4nsMtq5lODlmuBHt6g+nw3RtOGEa/PiE733Ogr7OqLrEVEjOCO383XxM74UTz+k6a4J/K1ZqMzjtft/76osz/gG5Q4z1xBQfkX8BqFaowjw1508JT8v2n6g0wsioKESOjZ8b0SRORej9yUb9PXApU+DKh6O1u6/Oj0/Al6bq5NGsGxZMCG+scp3J+bim8OeaEIWq4dMqhNxBnowOkKNsgKOIczA368wcj3P/FW7bAPf5mHY/8UY44UZD6YLg/ccGTTGSSF70tpGGoNs4l1LhZNK7/o9v3jXwNZIdkXTZnQL3beEoKtzp5MB9w80J04xovtoSrSi/GEAsVELkWDvXWO5aBi2P89+vWlnR3jfuhc+4ShSYixpHkvz1kG56wvYMqY51Upq61i99Dx7pEPo5RKFq+JinmHL6w54VwR8b6GZa/fsxPZh0OME03Y/ht1OwHa79wT09gcVqRK75IikdzngYtv1obLfq4btfZo67L9JZ042Xk0tmeh/TfbxRJsXTJ+2u7d7JOX1x+waCtgzn9DXKsWS0Dq5/KISSOLQ2OFM+5Abh3xcSsf8QKwqVUL/sW+dad1b8WP0+lNSQSN9sMo7atJ6J816D2R55TMw3jFCnFMJJoKkVX5hDoxP8+KsEOnc8W+gaApF4SreYItgmfwr/rOFGfPdOI9L2K0ctvUAZ053/H3OU3JUeUWY3/GwoL6lN/Sev9EfHk4wSLjleKRQNbt8Q2vmctPBhifJMNeCPmjJ/+yKzTWj9g2Hqd/WvUDXJhWu/N6Iu64XYtVDJY6ZQvxz4zbXurDG25Wv3qTsvTBaqJa947/70dti+KFwSBqbP+d5ttSlcXB8kBggP96UwJZoqzdeYL8tchsLjCVwsVNElEgqVWdkJZIFJyXK/UZszht+03HgNmWpsZ+a4fpd9L/J/zqS04JUVX7QbFJP50qJK2/6hK6e1IadfcFa7UEhrbiwjVdy6FoiFSqgfbOVGdJH5SdWrJq0fnNYPf9apJa8ar2hiCzEUXVmiUzg2Kd1VZgLgpFvdbzJKGVMtOxZB24Gwe7n7PiddToONn5r2yY0qohzaaigszptUffyWLv0A3jY9PFQUG3XYmnYwlKv7DsFDNTj/mhWwVj0grQWUHHBF4I3/l5GPqVknyGwN05YYFp9WPYz3Jwg10WkETHoHupwebUn8IqOiED6WznAlgvv8HsPh/OAm1/79630ft+wN3+1Fe8IrXzixBVkE1slf99ePHJ44K7U7MVuWlBVOe8D7mJpM8zcug8tmu8KmWzlqfzmfFoX6p/woPD3AvTxKsA8nTlrU4LPopKvHjWrvKqMO2wWOpLnmiNtmHb2Pd04ROi1V1y80pt3MdBhmKFMALbsZSvtx41xO5IJQE93/ENNlvcRCJdSdon3wzCCoKII1c2DyJ66SMeb6YObpPzP/u9l9O4ajOGpNXUpHeHLsaFdJC/NndeGb0ONseLCp6bqmv3hAq5LH564UtOhivNJbGd/tpR+4T+cI9Y8zF9vmBa62dR+Fdo5w5w1r3RsOb3Nvc04fO3+Tma1dypMgNAJEoRLqzvI3DGUKjHpg+zcEXwPKF/GQ2dltCq+eHLQvngUFO+CzO93bc/q7FCqnEjT0Oug5wfscZsfiQN+FlyJrel85feHeCFnZhMDMuSa0/uF+SBn7iKFA7V1l/PbA9NDQAB+IBCEIZMpPqDueCtD8+6keVGvj67F/XeA+9c3/feK+PekdVx4ZMKJYQmXC86H191cvz2xtcH6+Xce42h4odJUkMTudm49zOgqDe5oKMxLJ13DI9zHdnl6H5JpN2xtTgTctgyEO5c7TQiUIjQxRqITQ2f0rVJocnW0eZSB++xz2rDTWfRUzjRWSayin0GmE+3b3P8CAS13bbfqEfr3eE0Pr7y9Kxldknqfy47RG+Zvya36sy1nY3w2wx9nBySnEJ+EucF39uxSFSmiciEIlhEbhLnh5JHxqKqZZ0xRdxdF6F6nWBCrpcOcWuNWcR8thDepwQu2uF+r0Z0IKfm9OToXOrzXAoWBZQvGhctB2oJEDaPCVwfUXIoTju/4gTN9LoNpwrXuHeD7HlJ9YqIRGivhQCaHhLAuza5mrrSaFavvC+pWnLpgzhvsivYX7tlOh6nlOLS9osiLddxgealZzd7OFKjUbSh2lNqoqYer3gIa3nLL4sVCZb27BTuG17uU/w7QQBTwUlDWzw3NaXxaqs542Up30vdB3DrOr5kORn5JP1QpVFNKDCEIMIAqVUEtMN+eaFKqaMqJHm1Ajn5zKidf0WpCKitlCFEzCQfMNrc/5kN4SvnnYuGFZPBQmfzKZb27BOqWL71Rs4fwOSw8Hztc0+EojfUkwmH8PzvQag/6v5mNqqvFWY5JYQWj4yJSfEBor3/FuCzXJZTgJ1c/HrKQok0LV46wgDnYqHH7+NmMervnwUBUVa6JvC5NPC0AQFqqANzyZqokpdi6GfWvdv++n/ZRScdLxJGPZxEd9xkved98+4UZjOe5fcEMYKg9IlJ/QyBGFSvCPrQJ2mTJnV9mM4sRe/cq82yJFk9zQnownmkrZWBKMKvMQnN9HoKkMc00/i6+8UyEqVJ4WtGpFziTrCIcvm5eTvA/ly1/dPi9FTyxUMcFrp8MLJ4Y2heb8Hfsq2dJtjFHIN9sRjNDxJCMidOhUV4BCXZAoP6GRIwqV4E15EXx4A3x0A7wyCg5uMdqryn33D1QItT5JyiAkBcCcFdySYJRUAfebVvczfR+rA1iozJxwg2vdmdIgVAuV8qNQmWU9drRxU0zzKAky9h9G6oR2JouGP4XKGT4fyKdMiA4hKVSOvv4iWOtSGy8QFvGhEho34kMlePPLS7Dibdf2lq8hu7N3egQnUVWoTIV+2w+Fnb/473vK3e6RTRYr2J2WHNNT9aS38Ul1slLHMSPugOxOvq+pLNCyh+FYfsl77scFYvBVhvKT1RaXNUr5Vqj8kdPPKPsxz5QU1F8ahhG3G3mFbOVGYlbxoYotQrH4OH8bWW3d26d+Fz55/OEvn5kgNBLEQiV44zmAz7sDlr/pivADV6LAylLY/mPkZPPErFAFuvGMuse9j8XqqknWYWjgazmTZTrrop16Lwy4DE69H/pfBn0uNHVWMO1nuPa70BWUVj0MC5O/3FK1nVJJTPXdnpBkvA8hNqmNhUpZ4LI50HmkkcC1bX9Xn/pSmJMcU94jbq+f8wtCjBPQQqWUSgG+B5Id/T/QWt/v0UcBTwHjgRJgstZ6uee5hBhn9tXGTbdJe+99nvX2AMqOQN6S+perJhLTgnsyvtpRqiU509VmSTBSBNy0HJp1gvkP1HytgVfAMcON2nZm0lvAOc+5twUzLZjcxCjZM/YRGHot/O+PsOx1/ze8to7pu/ZDAp/biVn58mehaiAopcZijENW4FWt9SMe+ycAfwPsgA34o9b6R8e+bUARUAXYtNYeVaajSG0Vqi6nGq9IkZBkTD8LQiMlmCm/cmC01vqoUioR+FEp9ZnW+mdTn3FAV8drKPCCYynEE6sdUUAj/xxc/9LDkNa8/uQJBjeH9BqevHMd1qWMVnD+60b9wXaOe6bTIff6RVCw3f85nMWCgyEYheqeHe7b7YcaClWrnr6v3fEkuP232hecPXN67Y6LA5RSVuA54HQgD1iilPpYa22uY7QA+FhrrZVSfYH3AJNTHaO01gciJnSwBKtQ3fCzERUIkFJDFYDzZ8APTxgPEYIghI2ACpXWWgPOdNeJjpenKWAC8Kaj789KqaZKqRyt9Z6wSitEiCCnlOy26PvbWCy4FKkg5e490XcZmNY9jVc4qE1R6H6ToONwaOoj5N1JyMqU4zMZ968QIrni0odqCLBZa70VQCk1E2NcqlaotNbmtP3pxIuzT7BTvJYE6HWu8VAw5Fr//XL6wYVvhEc2QRCqCWrUV0pZlVIrgP3AV1prTy/cdsBO03aeo02IFzbNd60HO4BXVYK9KnA/p59SfaCspvxMDrnrUvQ1XNRGoVLKW5kKVwh6UIpvfOgXfghqDFJKnauU2gB8CphruGjgS6XUMqXU1HqVNGSC/F7Smht+gSNud0/hIQhCRAhq1NdaV2mt+wO5wBCllGeRJ1+jtdcooJSaqpRaqpRamp+fH7KwQj3y9nmmjWAtVJXBTUfURrkIFnP5jMw2xvIPj9ff9YIl7O+5llaj2ihk0bY61o6gxiCt9VytdXfgHAx/KifDtdYDMdwXpimlTvZ5kWiMYb7+Y57T8qnZ3qkzBEGIKCGN+lrrAuBbYKzHrjzA7MmcC3gVfNJav6y1Hqy1HtyyZcvQJBUiR0gWKlvgfv6Ui8R03+2hYE5+OfJuOOcFI3t6ajZktvV/XH0TjzpJfCdkDGoMcqK1/h44VinVwrG927HcD8zFmEL0dVzkx7DnfIjiGbFZn/mlBEEIioAKlVKqpVKqqWM9FTgN2ODR7WPgCmUwDCgU/6l4JgQfqmCm/PwpVL3PDV4kf1gSXCUvrMnQ/xLDwnLnZrh1Td3PX1vCZqGqq5JTm+PjURtkCdBVKdVJKZUETMIYl6pRSnVxRCSjlBoIJAEHlVLpSqlMR3s6MAaI4o8nCDwVKs8ksIIgRJxgovxygDccUTQW4D2t9SdKqesAtNYvAvMwUiZsxkibMKWe5BXCQWkBFO0x8h2BUVLGTLCWiu//ZZwrIH5u0OGwiCiLq7CrW/HhKN9gwj3lV9tpuJQmxjKpYfvUaK1tSqkbgS8w0ibM0Fqv9RinzsN48KsESoGLHBF/rYG5Dl0rAXhHa/15VN5IsBw33sgP5yTav3dBEIKK8lsFeFXkdAxQznUNTAuvaEK9MWOskZjzr/vh+8dh2PXu+4Otzbfpy+D6+VMGzL4hgybDsv8Edz4wHHBLDho3Emd+pVjy/QmXQuXMPXXMibU7/pS7IL0l9L0wcN84R2s9D+PhztxmHqceBR71cdxWoF+9CxhOmrSDu3fAI44gBkswz8aCINQnkim9MeLMcv7RNPj+Mfjh3+77C3Z4H1MXnFXtPTErVBltanduS4KpKKsP593anreuhEuhOuZEuHMr9DirdscnpsIJ08SC0ZBw1oZMaQKnPWCsy/crCFFHFKrGjDORp7mkDMDR/eG9jr/kn04FqMVxcNKtoZ0zw5GPKTHNVfTXV63BW1bCn/36Jtcf4ZzyS49w8tRYsvQ1Vuw1RM9e+KZrveMIYyk+VIIQdUShEqCqwn378Lb6uU6Lbu7bTh+qEbdDYgr83/9c+9r0NZZ9L3KVjTFzzvNG5u+2A4ySF+BboUpMca/3FynqM1VEfRHfUX4NC11DsIfZId35nfmr0ygIQsSIw1FfCDueisjRvXU739nPejQ4Bn2zktFukMtC5Zyu6GRK/dNzgrHMausqG2MmrTkMnmJYU4bdYLTVZwLRkIlHK49ToYpH2RsYwUTPArQbaEypT3y5fuURBCEgolAJ3haquuKMHgQ480nXulmhmvypqZCrjxt4sqMWmT/rktkJt++FRlHWSE+N1YQ/C1Vqtn+fMkFwEkx+NzAeRs54GJrk1q88giAEREJDGjq7f4XD26HXOcb2jp+9+1QUh/eaTgUpMwcGXwkbPnXucPVJTMWn5crJ4ClQWQJDr/NzjRj1GRl8JSyd4d8P6a7fIytPKDinj8SHKvrUNOUnCEJMIgpVQ+flkcYyZwW8MBwqfShPlaXhvWa1guRRY89TcaqOyvNxA7cmwkl/9G5PaQplBbEb1eTvvcYVolBFFa2NKgSCIMQVolA1ZOaa8kutme1bmQLIWxze6zqtR56WDs/7tC/lY+IrrsznPs+tvI+JJWqaxhSEYHjzbPj9e+/27md654wTBCFmEIWqobLkVVj5jmu7aYfIXdvTQuVULjyDyKqVD5NyFO8JKE+9z7Au9J0UbUmEeGT5m76VKYD+l0LHkyIrjyAIQROjj/lCnfn0dvft+rLonHiTd5vzWspjys9TowrFZyfBERZ+8p3GMlZLqaS3gHNfgKS0aEtSCyRtQtT52Mf/yUnF0cjJIQhCyIhC1VgINgzbH9cv8q3EnPoA3PCLe1u1f5OHouSZydyXhcofNyyE8183sn4/UOjKPSWEj+ZdjGXrntGVQ/BN+ZFoSyAIQg3IlF9joa5RQ6164KYgXb3AeGK2JkCr7vCXvfCwo8xLtYXKUwaHAtWsk/t2MApVdmfjJdQfXU+Ha793JVUVYotWougKQiwjClVjIRgL1Z1b4V9+lBal3Kfmcge77zdnavb0oXJOJXkm8gxFoRIiQ0581QhuNPzpd0jLjrYUgiDUgNzJGiK+6oD98lLg4yxh/jl4+kY5la7mXY2lRMQJQnCIMiUIMY9YqBoivrIs71sd+LiAyTJDVXw8+jdpD6P+Ah1OcDQ0hJxNgiAIgiAKVcMk2LIVnljC9HPwjN6r9qmyQLczTP1qSOwpCILxn7z0/WhLIQhCEIhpoCFSa4UqgIVq8idBnsijyG7XMTBkKox/3KObWKgEoUbOexWOHR1tKQRBCAK5k8UbOxfDCydBRYn/PrVVqAJN+eUEGf3laaGyJsL4f0Fmaz/95GcoCD6xhblwuSAI9YZM+cUbX/zZ8IfauxpSmxopCDxzMtWXhQqMnFMBpwY9LFR+u4lTuiDUSFV5tCUQBCFIxDQQb1iTjWXBdnhuCHx+t3efmhSqzqP87wtGsWnVHVp0qblPs45GLqMzn6y5n6RNEISasYlCJQjxglio4g2nNapor7HcvtB9/+d/hp+fi6xMniQkw3U/BO4nCpUguJOQCrZS13aVTPkJQrwgd7J4w+pQqOyVxtJczmXHL0EoUyHWaxtwec1WrbrQe6KxbHpM/ZxfEOKJyjJ3ZQqg29joyCIIQsiIQhVvOBWqKue0nklBmjEmtHMNvd6oi1cTE56FKz4M7bxBX/86o2RNVk79nF9oVCilxiqlNiqlNiulvObClVITlFKrlFIrlFJLlVInBXtsRHjYEbRx0q3G//KBQmh+bFREEQQhdAIqVEqp9kqpb5RS65VSa5VSt/joM1IpVegYqFYope6rH3EFEhw+VM6pgAO/wU9PBX+8Z4HiaKKUe8kaQaglSikr8BwwDugJXKyU8ix+twDop7XuD1wJvBrCsfXL9/9yrdc2qEQQhKgSjIXKBtyute4BDAOm+RlsftBa93e8HgqrlIILq4dCBfBVCPprVaXpXInhkUkQos8QYLPWeqvWugKYCUwwd9BaH9XamauDdFzm3YDH1iuHtsLXf3dtm/+jgiDEDQEVKq31Hq31csd6EbAeaFffgjUaNi+An18Mvr/TKX3h0+7t0/sEd3yZaYovMc17/4DLgpdFEGKHdsBO03YePsYppdS5SqkNwKcYVqqgj603jux23xZHdEGIS0LyoVJKdQQGAL/42H2CUmqlUuozpVSvcAjXKPjvRPj8rsD9Pr0dNsxzWag8Kdjh/9iLZ7rW3RSqFO++E6IcISgItcNXzg+vCAyt9VytdXfgHOBvoRwLoJSa6vC/Wpqfn19bWT2Fct+WZJ6CEJcErVAppTKA2cAftdZHPHYvB47RWvcDngE+9HOO8A9GDZW/tYR3LnJtL3kVZl7sncQzGI4bBx1ONNb7ms6Z4Md/6dyXQr+GIESXPKC9aTsX2O2nL1rr74FjlVItQjlWa/2y1nqw1npwy5Yt6y41+PBrDDESVxCEmCAohUoplYihTL2ttZ7juV9rfURrfdSxPg9IdAxUnv3CPxg1VKoq4LfPvdv9WagCcdlsuG09jL4X+lxotPlzCO83qXbXEITosQToqpTqpJRKAiYBH5s7KKW6KGVkr1VKDQSSgIPBHFtv7P4VvnnYvS33+IhcWhCE8BIwsadjAHoNWK+1fsJPnzbAPq21VkoNwVDUDoZV0saM3fQEa62FhQogKc14AYy4zUgIetx4Y/vM6bBrWZ1EFIRoorW2KaVuBL4ArMAMrfVapdR1jv0vAucBVyilKoFS4CKHk7rPYyMi+Cungq5ybxs0OSKXFgQhvASTKX04cDmwWim1wtH2Z6ADVA9U5wPXK6VsGAPVJFM0jRAMS2fA4Ct97wt3Pa9WPeA20/1i8BTjJQhxjMM6Ps+j7UXT+qPAo8EeGxE8p/vGPSa1LQUhTgmoUGmtfyRAlVut9bPAs+ESqlHyya3GVFxyhvc+cz2vWMojJQhC3bBY3fNODb02erIIglAnJFN6PGAOoxaFShAaDhYppyoIDQVRqGIJT18KJ2YL1c/PR0YWQRDqH2WNtgSCIIQJeTyKJex+FCqzharcM2NFABJ85JoKhj+uDn2wb90HcgfX7nqC0BgRC5UgNBjk3xxL+JvOq1Mpilo6uDbtEPox1/9Yu2sJQmPFIhYqQWgoyJRfLOHLQvXT03UslirBloIQs4hCJQgNBlGoYglfitNX90LJgdqfU5zYBSF2ER8qQWgwiEIVS/hzSn+zDoXvJR2YIMQu4kMlCA0GUagiQZUNPrgK9gVIvuzPKd0XTY+pef/wPxrLEbcHf05BECKLTPkJQoNBHo8iQf56WPMB5G+A63/y38+pUC1/K/A5a8qmPOByOP1B4yUIQuwiCpUgNBjEQhUJgp1201Ww9kP4+MYgOtegUJ31VHDXEwQhusiUnyA0GEShiigBUhjYq+CjaUGeyse5MtrA1O/kqVcQ4gWzQnX6Q9GTQxCEOiOPRxHBj4Xqk9s8ulURdN4o5UMXvmNjSFIJghBlzFF+w2+JnhyCINQZsVBFk6WvuW+Hkm8qNdtY9r0ofPIIghBZxJosCA0GUagizY5f4IEmcGS39z67vWZnczPNOhrLTieHTTRBECKM8//e5bToyiEIQp2RKb9I4HRKV8Dil4z17Qt99Athym/8Y9C0PXQbh+vkgiDEFRXF0OFEuHhWtCURBKGOiIUqoihXagRflii7LXi9KLUZnHofJKb4P58gCLFNySFoeRxY5dlWEOIdUagijTMbuq+SE/YQLFROLImOFVGoBCGu0BpKD0NadrQlEQQhDMhjUURwTPntXWW8wLczqr/SMzVhTYRe58KgybWWThCEKLBxnvGfT0iNtiSCIIQBUajqG1sFHNnj3e4r7YG9KvSpO6Xggv/USjRBEKLIR44Evkd2RVcOQRDCgkz51ZaqSqgsDdzvfzfDzIu929f/z7stlFp+giDEN617GcvcwdGVQxCEsCAKVW157XR4uE3gfus/8d1+cLN3m78ov+ZdjOWFbxnrf/o9aDEFQYhR2g00lv0vja4cgiCEBVGoasvuX4PrF8oUnr8pP+f0YItucNMycWIVBB8opcYqpTYqpTYrpe72sf9SpdQqx2uhUqqfad82pdRqpdQKpdTSiAhcWQopTSVCVxAaCKJQhZsfn4R3L3Ft+xssfU3v2W1QctC73RkRGEomdUFoRCilrMBzwDigJ3CxUqqnR7ffgVO01n2BvwEve+wfpbXur7WOzBzc1m+hrCAilxIEof4JqFAppdorpb5RSq1XSq1VSnkVnFIGTzueDFcppQbWj7hxwPwHYOOnpgY/CtXu5d5t/qL8nBGB2l4XyQShITME2Ky13qq1rgBmAhPMHbTWC7XWhx2bPwO5kRKuyu6jnueB3yJ1eUEQIkAwFiobcLvWugcwDJjm48lvHNDV8ZoKvBBWKeMZX9F8/ij0E+3jPEdt0ioIQuOgHbDTtJ3naPPHVcBnpm0NfKmUWqaUmurvIKXUVKXUUqXU0vz8/KAEm/fsrXz9yHnujbtXGMv2w4I6hyAIsU/Au73Weo/WerljvQhYj/dANQF4Uxv8DDRVSuWEXdp4JBT/iK/u9d3uzDHVpH2dxRGEBoqvP5oPsxAopUZhKFR3mZqHa60HYjwcTlNK+SySqbV+WWs9WGs9uGXLlkEJ1pQjjKj4wYgMdjLrMmOZkhXUOQRBiH1C8qFSSnUEBgC/eOwK9emwEVFHh9NzXoDjr4IHCiG9RXhEEoSGRx5gfuLIBbwqkCul+gKvAhO01tUOi1rr3Y7lfmAuxhRiWDjUfBApVFA1/yFXo/Ph6NhTw3UZQRCiTNAKlVIqA5gN/FFrfcRzt49DvJ4Oa2MujyteHOHdVtcInv6XBO4jCMISoKtSqpNSKgmYBHxs7qCU6gDMAS7XWv9mak9XSmU614ExwJpwCVaUOxIA66KnYcU7YLcbtTjTmsPQa8N1GUEQokxQCpVSKhFDmXpbaz3HR5egng5rYy6PK5xlZcyE4kPlSU6/wH0EQUBrbQNuBL7AcEt4T2u9Vil1nVLqOke3+4DmwPMe6RFaAz8qpVYCi4FPtdafh0u25PQsbqm4wdj48Hp4qJkRuKK1pEwQhAZEwNIzSikFvAas11o/4afbx8CNSqmZwFCgUGvto95KY6SWA+axp8LlvnRXQRB8obWeB8zzaHvRtH41cLWP47YC9fb0kp6cwEf2k/hH619I37fMtaP0UH1dUhCEKBCM+WQ4cDkw2vFUt0IpNd7jyW8esBXYDLwC3FA/4sYZBTvh6N7Qjxt2A1z4RvjlEQQh4mQkG8+t60a/HmVJBEGoTwJaqLTWPxLAzKK11sC0cAnVILCVw7uTguub2RaKTDOkbQdCcmb9yCUIQkRxKlTvrjzMoBt/xZLWFJ49Htr0jq5ggiCElYAKlVBL/t4q+L6n3mv4VjixJoZfHkEQokLPtlmc3rM1c5bv4sDRCl6f3Anrn7ZEWyxBEMKMlJ6pKxs/C9wnIB4GQGtSGM4pCEIskGi18PLlg7jt9G58/1s+z3/jozC6IAhxjyhUdeXdSVBRUnOfFt2g38U1dPDIMJEgCpUgNCSUUtw0ugtn92vL9AWbWL/HM/OMIAjxjihU4aCqvOb9LboZleX9YUmAbuNc22KhEoQGh1KKhyb0wmpRzFqyM/ABgiDEFaJQhYOqSiNZX03YalC6cgfDJTOhtcNJ1ZocPtkEQYgZmqYlMfq4Vnyyag92XwWTBUGIW0ShCgd7V8OBjf73K4u7FSspw7X+QCFkd3Z2NBZWiRUQhIbKqO4tOXC0nG0Hi6MtiiAIYUTu3OHgvxN9t2e1gyO7jGzItgpXu8Xqu7/TN1352S8IQtzTN7cpAKt3FdK5ZUbNnQVBiBvEQlWfVPtCKbCVudq1H1N/dZkamQoQhIZK11YZpCRaWLmzMNqiCIIQRkShqk+cifs6jYBT7nK1a3/+VirAfkEQ4p0Eq4XjWmeyaX9RtEURBCGMiEIVCnY7LHwGyoMcCAf+H9y6DgZfBd3GwF3bjXZth8vmwIVvuvc/zhHpl9EmfDILghBztM5K4YdNB6IthiAIYUR8qELht8/gy7/C3jXB9W/WEZq0c207M6BrO3Q51bv/yX+CwVdCRghZ1gVBiDsSE4xn2c37i+jSSspMCUJDQCxUoVB+1Fiumhlc/7Tm7tsWh/7qLy2CxSLKlCA0Ai4d2gGAvYUBctgJghA3iEIVCroq+L4n/wlSm7m3JSTD6L/ClZ+HVy5BEOKKnCapAKzMK4iuIIIghA2Z8gsGWwUsfgkSU4Pr37wLjP6L730n3xk+uQRBiEs6Nk+jbZMUVuwsiLYogiCECVGogmHVLMN3qibSWkCJw8lU8kgJglADSil6tm3CzkMB6oAKghA3yJRfTbx4EvznTEhKC9z3rOkwbYmxnt6yXsUSBCH+aZ+dys5DJWh/eekEQYgrxEJVE3tXG0u7LXBfraFFVxj3GPQ6t37lEgQh7umQnUZxRRWHiitoniH1OwUh3hELlT8KdrjWdywK4gBtlJgZeq1E6gmCEJD2zQzL9w6Z9hOEBoEoVE52LYfD213b0/uEdrxkNxcEIQQ6NDcUqp2HS6MsiSAI4UAUKievjIKn+sKRPUZG9FARPwhBiCpKqbFKqY1Kqc1Kqbt97L9UKbXK8VqolOoX7LH1QW4zI2pYHNMFoWEgPlSePNEdcofU4kBRqAQhWiilrMBzwOlAHrBEKfWx1nqdqdvvwCla68NKqXHAy8DQII8NO2lJCbTISBaFShAaCGKh8kXe4uD6Xf01pDv8pcRCJQjRZAiwWWu9VWtdAcwEJpg7aK0Xaq0POzZ/BnKDPba+aJ+dKj5UgtBAEIWqLuQOgk4joi2FIAjQDthp2s5ztPnjKuCzWh4bNjpkp4lCJQgNBFGo6owyFuKULgjRRPlo82k2VkqNwlCo7qrFsVOVUkuVUkvz8/NrJaiZ9s3S2FNYRmWVjB+CEO8EVKiUUjOUUvuVUmv87B+plCpUSq1wvO4Lv5gxwpBr4Zjh7m09zzaWOf28+wuCECnygPam7Vxgt2cnpVRf4FVggtb6YCjHAmitX9ZaD9ZaD27Zsu4JfDtkp1Fl1+RJpJ8gxD3BWKj+A4wN0OcHrXV/x+uhuosVo5zxD5gyz72t5wS49yC0PC46MgmCALAE6KqU6qSUSgImAR+bOyilOgBzgMu11r+Fcmx90bNtFgDfbtwficsJglCPBIzy01p/r5TqGAFZose6j4LrZ3V8XEOvh5Qm3u2CIEQFrbVNKXUj8AVgBWZordcqpa5z7H8RuA9oDjyvlAKwOaxNPo+NhNy92maRkmhhl1ioBCHuCZcmcIJSaiWGmfwOf4ORUmoqMBWgQ4cOYbp0HbGVw3tXhHbMuEfqRxZBEGqN1noeMM+j7UXT+tXA1cEeGwmUUrTMTCb/aHmkLy0IQpgJh1P6cuAYrXU/4BngQ38dw+1/EBbsVdGWQBCERkznFhms3X0k2mIIglBH6qxQaa2PaK2POtbnAYlKqRZ1lixS6CAVqmt/qF85BEFolJzUpQWb9x9l35GyaIsiCEIdqLNCpZRqoxwOCUqpIY5zHqz5qBgiWAtVTt/6lUMQhEZJjxzDMf33A8VRlkQQhLoQ0IdKKfUuMBJooZTKA+4HEqHaP+F84HqllA0oBSZpHUdpw2XKTxCEKOKs6bc1v5hhnZtHWRpBEGpLMFF+FwfY/yzwbNgkijTBTvkJgiDUA8c0T6NFRjJLtx/ikqExEqwjCELISKZ0u813e/9LITkLTnvQqNknCIJQDyil6JCdyp4C8aEShHim8SZQKjsCS1+DXuf63j/6Xjjn+cjKJAhCo6RDdhqfrt5DaUUVqUnWaIsjCEItaLwWqm8ehvkPwJo5vvcnpkRUHEEQGi8nHtuCyirNrgJJ8CkI8UrjVaiqKozlUT8lHxLTIieLIAiNmvbZxnizX1InCELc0ngVquRMY1lW4Hu/NSliogiC0LhpnZUMwKb9R6MsiSAItaXxKlRJGcayYKerLXcIJBghzBiptQRBEOqdVlmGi8H9H0ekhKAgCPVA43VKr6o0ltt/dLXZbXDDIsjfEB2ZBEFolGQkN96hWBAaCo3TQvX7D/D9Y97tOX0huxMcNy7yMgmC0Ki5Y0w3AEorJDeeIMQjjVOh2uanLt84H0qWIAhCBHA6pm/YK4WSBSEeaZwKlbb7bk9IjqwcgiAIDoZ2MsrO3P7eyihLIghCbRCFShAEIQZo08RwTN8qRZIFIS5pnArVD//2bjvr6cjLIQiC4IMqe/zUlxcEwaBxKFRVNji8zVg/vN13n3aDIiaOIAiCL+49sycAR8v81BgVBCFmaRwK1YIH4al+ULgLnurru48z0acgCEKUyEox0ieszCuIriCCIIRM41Cotn5rLHcs8t9HFCpBEKLMcW2MceiKGYujLIkgCKHSOBQq5Xibs6/y30cUKkEQokyPnKxoiyAIQi1pXAqVL6xJcNt6sCZGTh5BEAQfJFpdY5XW4pguCPFE41SoTnsA/rgGLpsD9+ZDVtuoiCUIQvhQSo1VSm1USm1WSt3tY393pdQipVS5UuoOj33blFKrlVIrlFJLIye1N3eP6w7A/qLyaIohCEKINE6FKjkTmraHLqdGRx5BEMKKUsoKPAeMA3oCFyulenp0OwTcDDzu5zSjtNb9tdaD60/SwAztlA3AGdO/j6YYgiCESONUqJIyoiOHIAj1xRBgs9Z6q9a6ApgJTDB30Frv11ovASqjIWCwDOjQDICCkpgWUxAEDxqHQoWHL0LzLtERQxCE+qIdsNO0nedoCxYNfKmUWqaUmhpWyWrBlOEdSbAoKqukqoMgxAsNX6EqPgA7f3Ft95oIuVG16AuCEH6Uj7ZQvLqHa60HYkwZTlNKnezzIkpNVUotVUotzc/Pr42cQdE3twk2u2bptsP1dg1BEMJLw1WoDm+HB5rAv451b2/ZPTryCIJQn+QB7U3bucDuYA/WWu92LPcDczGmEH31e1lrPVhrPbhly5Z1ELdm+uY2BeDnrQfr7RqCIISXgAqVUmqGUmq/UmqNn/1KKfW0I7JmlVJqYPjFrAX5G323tx0QWTkEQYgES4CuSqlOSqkkYBLwcTAHKqXSlVKZznVgDOBzvIsUbbKMQslPLdgUTTEEQQiBhCD6/Ad4FnjTz/5xQFfHayjwgmMZXRJTvNtuWy8pEgShAaK1timlbgS+AKzADK31WqXUdY79Lyql2gBLgSzArpT6I0ZEYAtgrlIKjDHxHa3151F4G9WkJyfQrXUGuwvKoimGIAghEFCh0lp/r5TqWEOXCcCb2shC97NSqqlSKkdrvSdcQtaKihLvNlGmBKHBorWeB8zzaHvRtL4XYyrQkyNAv/qVLnTG9s7h6QWb2F1QStumqdEWRxCEAITDh6qu0TX1Q6UPhUoQBCFOcHrZn/jI1+RLkk9BiHnCoVAFHV0TqQgZQBQqQRDimutOcQXUPLXgtyhKIghCMIRDoQo6uiZSETKA95Tfea/V7/UEQRDCSGqStXr9vz/v4HBxRRSlEQQhEOFQqD4GrnBE+w0DCqPqP6U1zH8Adix0tV08E/qcHzWRBEEQasMLl7qCpk969OsoSiIIQiACOqUrpd4FRgItlFJ5wP1AIlQ7fM4DxgObgRJgSn0JGxQVR+HHJ13bV38NuYOiJ48gCEItGdcnh1tO7cpTCzZRXFEVbXEEQaiBYKL8Lg6wXwPTwiZRXSg/Cq+d4d4mypQgCHHMrad3q85HtSqvoDrppyAIsUXDypS+82fYvzbaUgiCINQLZz/7E/uLJDeVIMQiDUuhsiZFWwJBEISw8+DZvarXi8psUZREEAR/BJMpPX4oPuBaH3wlHH919GQRBEEIE1aLKztNcbkNrTWOzO6CIMQIDcdCVVkGHzj84W9cCmc+Ca171XyMIAhCHHByV1eamd8PFNPpnnnMXLwjihIJguBJw1CoKsvgtdNc28mZ0ZNFEAQhzHRonsYrVwwG4PEvjcLvb/8iCpUgxBINQ6GaOxX2rnZtZ7aJniyCIAj1wKndWwGw81ApAGWVkkZBEGKJ+FeoSg7Buo9c23dsjp4sgiAI9YTForhnXPfq7U37j1JSIQ7qghArxL9C9Vgn13qX0yCjnkvaCIIgRIlxvXPctp/5Wh4gBSFWiH+Fyoz2WZNZEAShQdA+O9VtW6b9BCF2iG+Fyu4xmPS9MDpyCIIgRAClFEkJrmE7I7lhZb4RhHgmvhWq0gLX+qn3Q79JURNFEAQhEiz762n0bpcFwMHiCjre/Slfb9gXZakEQYhvhWrXUmPZpi+ccGN0ZREEQYgAmSmJfHLTCNpnp/KOI3WC+FIJQvSJb4XqI4cSNeUzSJCyM4IgNB565mRVr6/ddSSKkgiCAHGgUFXY7Cz+6AV+37nTfcfGz6F4PzTvAskZ0RFOEAQhSvzj3D7V6xVVdvYdkaLJghBNYt6jsSR/O32X30vKr3dDTj+oqoSj+6DkoNHhzCejK6AgCEIUaJ6RTEZyAkfLjVxU+46U0TorJcpSCULjJeYtVE1zOvFUh6f5TveHPSth/zqXMjVoCnQ6OaryCYIgRItTurny7p397E98tW4f+4vEUiUI0SDmFSqAP4z9A3N7TOfM9HeZWnErf7LfwKrO18CYv0VbNEEQYgSl1Fil1Eal1Gal1N0+9ndXSi1SSpUrpe4I5dhY5d8X9mNC/7bV29e8uZQxT34fRYkEofESFwpV73ZNmD5pAJ/cOZ4/33Yn+zudy9nrRjFjyYFoiyYIQgyglLICzwHjgJ7AxUqpnh7dDgE3A4/X4tiYJCXRyhMX9ndrKyipZM2uQrbmH42OUILQSIkLhcpMxxbpvHT5IFISLTz0yTo27y+KtkiCIESfIcBmrfVWrXUFMBOYYO6gtd6vtV4CVIZ6bCxjtSjevWYYI7q2qG4785kfGf3v76IolSA0PuJOoQJITrDy5R9PITnBwj/nbYi2OIIgRJ92gDkUOM/RVt/HxgQnHNucU7u38mpfnVcYBWkEoXESlwoVQIfmadx8alcWbNjP52v2RlscQRCii/LRFmxxz6CPVUpNVUotVUotzc/PD1q4SHDFCR354o8nc1oPl2J1+/srsNulxqkgRIK4VagArjqpE8e1zuTheesot0mRUEFoxOQB7U3bucDucB+rtX5Zaz1Yaz24ZcuWvrpEDYtFcVybTO4Z36O67bd9R+n853niGiEIESCuFaqURCt//kMPdh4q5a9z10RbHEEQoscSoKtSqpNSKgmYBHwcgWNjjpaZyV5tpz3hHfl3z5xVPPnVb5EQSRAaBUEpVEGEI49UShUqpVY4XveFX1TfnNKtJVef1In3l+XxwbK8SF1WEIQYQmttA24EvgDWA+9prdcqpa5TSl0HoJRqo5TKA24D/qqUylNKZfk7NjrvpO5kpSTy+R9HcPvp3dzaN+93j/p7d/FOnlqwKZKiCUKDJmCmdFNI8ekYpvElSqmPtdbrPLr+oLU+sx5kDMidY49j/vp93PH+SoZ1zia3WVo0xBDqmcrKSvLy8igrk8SFsU5KSgq5ubkkJiZG7Jpa63nAPI+2F03rezGm84I6Np7p3iaLZmlJ/NtkgTrtie94ffLxjPLhvN7YkbFFMFPb8SuY0jPVIcUASilnSLGnQhU1khOs/OPcPlzy6i+Mfvw7Ft4zmhYZ3mZvIb7Jy8sjMzOTjh07opQvP2IhFtBac/DgQfLy8ujUqVO0xWm0tM5KYdsjf2DEY1+z81ApAH/7ZJ2XQrVs+yEGHZMdDRFjBhlbBCd1Gb+CmfILNqT4BKXUSqXUZ0qpXiFJEQZO7NKCP4/vTkWVnSteWyxO6g2QsrIymjdvLgNejKOUonnz5vK0HyPMmnpC9frWA8V0vPtTHvqf63n4vBcWsbewcX9XMrYITuoyfgWjUAUTUrwcOEZr3Q94BvjQ54nqOeR46snH0rZJCuv2HOGuD1aF/fxC9JEBLz6Q7yl2aNs0lQ1/G8uNo7pUt8346Xe3Ps4Cy40Z+c0KTmr7WwhGoQoYUqy1PqK1PupYnwckKqVa4EEkQo7nThsOwIcrdvPnuavr5RpC46SgoIDnn3++VseOHz+egoKCGvvcd999zJ8/v1bn96Rjx44cOCClmQSDlEQrd5xxHDeMPNbn/r9/uo6LX/6ZLn+eR0mFKFeRJp7GFsE/wShUAUOKHdEzyrE+xHHeg+EWNhhaZ6Ww8r4xALzzyw6vyBZBqC01DXpVVTVPMc+bN4+mTZvW2Oehhx7itNNOq614ghCQP43tzqtXDPZq/3ZjPou2HsRm1/x5jjyIRhoZW7yx2eJPsQ+oUAUTjgycD6xRSq0EngYmaa2jlp63SVoin958EmBEttwy81cqbPZoiSM0EO6++262bNlC//79ufPOO/n2228ZNWoUl1xyCX369AHgnHPOYdCgQfTq1YuXX365+linxWjbtm306NGDa665hl69ejFmzBhKSw2H4cmTJ/PBBx9U97///vsZOHAgffr0YcMGo8RSfn4+p59+OgMHDuTaa6/lmGOOCWiJeuKJJ+jduze9e/dm+vTpABQXF/OHP/yBfv360bt3b2bNmlX9Hnv27Enfvn254447wvr5CbHBCcc2Z3yfNm61/8x8uGI3t7+3kgNHyyMsWeMlnsaW66+/nsGDB9OrVy/uv//+6vYlS5Zw4okn0q9fP4YMGUJRURFVVVXccccd9OnTh759+/LMM8+4yQywdOlSRo4cCcADDzzA1KlTGTNmDFdccQXbtm1jxIgRDBw4kIEDB7Jw4cLq6z322GP06dOHfv36VX9+AwcOrN6/adMmBg0aVOfvJhSCifILJhz5WeDZ8IpWN3q1bcLjF/TjjvdX8tGK3Xy0YjcvXDqQM3q1wWKRufJ458H/rWXd7iNhPWfPtlncf5b/eIpHHnmENWvWsGLFCgC+/fZbFi9ezJo1a6qjQWbMmEF2djalpaUcf/zxnHfeeTRv3tztPJs2beLdd9/llVde4cILL2T27NlcdtllXtdr0aIFy5cv5/nnn+fxxx/n1Vdf5cEHH2T06NHcc889fP75524Dqy+WLVvG66+/zi+//ILWmqFDh3LKKaewdetW2rZty6effgpAYWEhhw4dYu7cuWzYsAGlVMBpBCE+SU9O4PlLjRvNws0HuOTVX7z6zF6ex+zlecy54UTaNU3l+9/yuWBwe69+DREZW2oeWx5++GGys7Opqqri1FNPZdWqVXTv3p2LLrqIWbNmcfzxx3PkyBFSU1N5+eWX+f333/n1119JSEjg0KFDAT+rZcuW8eOPP5KamkpJSQlfffUVKSkpbNq0iYsvvpilS5fy2Wef8eGHH/LLL7+QlpbGoUOHyM7OpkmTJqxYsYL+/fvz+uuvM3ny5IDXCydxnSk9EOcPyuXTm0+ilSNz8PVvL+e0J6UCuxA+hgwZ4hZa+/TTT9OvXz+GDRvGzp072bTJO3Fip06d6N+/PwCDBg1i27ZtPs89ceJErz4//vgjkyZNAmDs2LE0a9asRvl+/PFHzj33XNLT08nIyGDixIn88MMP9OnTh/nz53PXXXfxww8/0KRJE7KyskhJSeHqq69mzpw5pKVJPreGzoldWrDhb2N5/tKBPvdPfH4hQ/+xgDs/WMXgv39FQUkFUZx8aFTE6tjy3nvvMXDgQAYMGMDatWtZt24dGzduJCcnh+OPPx6ArKwsEhISmD9/Ptdddx0JCYbtJjs7cHqOs88+m9TUVMDID3bNNdfQp08fLrjgAtatM6JT58+fz5QpU6rHKOd5r776al5//XWqqqqYNWsWl1xyScDrhZOgLFTxTK+2TVj8l9M49/mf+HVHAVvzi7n/ozUs2nqQT28eQaK1QeuUDZaanvYiSXp6evX6t99+y/z581m0aBFpaWmMHDnSZ+htcrIrR5rVaq02y/vrZ7Vaq/0JQr2Z+evfrVs3li1bxrx587jnnnsYM2YM9913H4sXL2bBggXMnDmTZ599lq+//jqk6wnxR0qilfF9chjSKZtVeQW0bZrK1vxir34HjlYw+t/fUVBSwQ93jaZd09Tqfb/tK6JpWiKHiyvpkJ1GapI1km8hrMjY4p/ff/+dxx9/nCVLltCsWTMmT55MWVkZWmufkXH+2hMSErDbDTccz/dhft9PPvkkrVu3ZuXKldjtdlJSUmo873nnnVdtaRs0aJCXBa++aTTaxNwbhvPkRf0AeGPRdn7bd5Re930hldiFoMnMzKSoyH+R2cLCQpo1a0ZaWhobNmzg559/DrsMJ510Eu+99x4AX375JYcPH66x/8knn8yHH35ISUkJxcXFzJ07lxEjRrB7927S0tK47LLLuOOOO1i+fDlHjx6lsLCQ8ePHM3369OrpB6FxMPOaYax7cCzzbh7Bz/ec6rPPoeIK7BqGP/I1E5//iSe/+o2nF2xizJPfM+ThBZwx/Xtue2+F13F5h0vqWfr4Jl7GliNHjpCenk6TJk3Yt28fn332GQDdu3dn9+7dLFmyBICioiJsNhtjxozhxRdfrFbanFN+HTt2ZNmyZQDMnj3br0yFhYXk5ORgsVh46623qh30x4wZw4wZMygpKXE7b0pKCmeccQbXX389U6ZMqfNnEiqNRqECOHdALvNvO7l6u6LKzuh/f8uYJ7/DViVO60LNNG/enOHDh9O7d2/uvPNOr/1jx47FZrPRt29f7r33XoYNGxZ2Ge6//36+/PJLBg4cyGeffUZOTg6ZmZl++w8cOJDJkyczZMgQhg4dytVXX82AAQNYvXo1Q4YMoX///jz88MP89a9/paioiDPPPJO+fftyyimn8OSTT4ZdfiF2sVgUFosiJdFKmyYpzL7+xOqKE1OGd/Tqv3xHAU8t2MQTHgWWP1uzlzcWbuO5bzYza8kOFqzfx0mPfsPXG/ZF4m3EJfEytvTr148BAwbQq1cvrrzySoYPN9IUJSUlMWvWLG666Sb69evH6aefTllZGVdffTUdOnSgb9++9OvXj3feeaf6WrfccgsjRozAavVvzbzhhht44403GDZsGL/99lu19Wrs2LGcffbZDB48mP79+/P4449XH3PppZeilGLMmDHh/ogCoqI1Hz548GC9dOnSqFy73FbFih0FXP3GUoocCe26t8nkw2nDSUmMX1N1Q2f9+vX06NEj2mJElfLycqxWKwkJCSxatIjrr78+Zi1Jvr4vpdQyrbV33H4cEs0xLJKU26pITrDS8e5P63SetCQrt57WjePaZNKrbRbNY6g8mIwt8TW21MTjjz9OYWEhf/vb3+p0ntqMXw3eh8oXyQlWhnZuzq/3nc7gh+dTUFLJhr1FdL/3cwDev+4EisttDOmUTVpSo/yIhBhlx44dXHjhhdjtdpKSknjllVeiLZLQwElOMB4y/zPleNKTE9hdUMpz32zmt32h5fgrqaji4XnrAUiwKF6fcjzN05Np1yyVX3cc5uMVu/n3hf1QSvHGwm2MOq4VHZpHNzCiym7naJmNJmlJUZUjEjSEseXcc89ly5YtUfP9bNTaQoLVwor7xlBYUsmU/yxm+Y4CAC54cVF1n5cuH0SXVhl0bpEupQmEqNO1a1d+/fXXaIshNEJGHucqqjyhfzsKSipokprI7OW7uOP9lfxlfA/KbVW0yEjm7gDJQW12zeWvLfZqz22WytNfbwbgtezf+f5Po7z6bN5/FKtF0a5pKl9v2MfwLi2wKMWc5XlcOvSYsKbFyTtcSmFpJd0SrQ1+9qK+xhbnLFgk7p9z586t92vURKNWqJw0SUtkzg3DOXC0nNW7Cpny+pLqfde+ZTjO9W/flEfP68txbYw55bLKKv4xbz03ju5Cq8yUqMgtCIIQLZo6rDbnDmhHn3ZNqsdGgN7tmvDF2r0841COLhrcnmbpSbz43ZYaz+lUpgB2HCph2fZDrN19hPs+WktGcgKL7hnNaU8YqW+SEixU2OxcPKQDTVITefG7LaQkWrlgcHt+2XqQXQWlTByYi9aadxfvZHDHZnRsnk6iVfHEV7+Rkmhlmqm+odaao+U2MpITqm/+zoTQ+UXltMpKrrbW+aK8sooym50mqYl++9SkXNi1Zk9BKa2yUhpU9PnqXYWkJydwbMuMoI+x2zX7ispolZmCNY7yRjZKH6pAFJfb+GBZHh+u2MWvDquVkxFdWzC6eysqbHb++ZmRYfbFywYytndOFCRtXIifQ3whPlRC3uES3vp5O7effhxWi+K1H7cyoEMz7p69ihOPbcGspTt58sL+THtneZ2uc9VJnXjtR6Pgc/c2mWzY64qYe/PKIVwxYzE9c7JYt+cID03oxX0frQVg2yN/QGvN0pVryDnmWA4VV9C5RToZKYZStHHvEcodSlVSgoW0xARsdjudfSgHq/MK0EDf3KYUllaQX1TBsS3dZzZ2HirhcEkFfXObeh1fUFLBjkMlNEtLon22/6lOrTVllVWkxok7yqq8AgCf79kfB46Ws7uglFaZKbRpEh2DRW3GL1GogmDd7iP887P1/LDJf4mPjs3TaJ2VwpEyG5/cdFJcadXxgihU8YUoVEIo3PXBKmYt3Vnv1+mQncaOQ0a4facW6ZzVN4c+GcW07tAZgHZNU9lVUEqCxYLN7or+tiiF3XG/NCsHWmvKbHY27TOUuN5tm7Bmd2H1uZzO91prVu8y2nvkZHlZoTbtL6K0ooqmaUl0qEGhOlJaybaDxeQ2S6NZWiJ7CstIsChaZbkUD7vW2KrsJNVgUQuFClsVG/YW0bF5Olk1WOB8EaxCVW6roqjURovMZA4eLWdXQSnZ6UnkNouOH504pdcTPdtm8dZVQwFYvuMwc5fvYs7yPIorXEUrtx0sYdtB40967J/nkZpo5ZoRnUhLTqBfblOWbjvE0M7NOb5jM/HFEgRB8ODR8/vyyHl9UEqxq6AUu13z0+YDWCyKIR2z2VVQyiOfbWBPYSn3ntmTW2auqNV1nMoUwO8Hinn66828crZrhmFXgZEM06xMAdXKFBizGEkJFnYXGD5WZvKPlpOenEBxuQ2bXVNuqyLRamGTyYl/8/6jNM9IokV6crXPV6npfqK1ptKhEFXY7CRajT6HSyopqTAi04+WVVJUVll9fadCZauys7uwjIKSCnq3bYLFoqqnGvcdKScj2VptgTO/t4NHy0lNtLKroIwurTLcjAJO2Q6XVISsUPnCrjVFZTayUlzTq78fKKbCZqdZeiIWR1s400RWVtmxKlWvpedEoQqRgR2aMbBDM/52Tm/sds3na/fyw6Z83l3s/mRVWlnl5g/gSf/2TTmjVxvG9W7Dp6v3sGTbIW4//Th+2nKA8wflku3wT7BYFAePlnOkzEanFul+zyfEJhkZGRw9epTdu3dz8803VxcoNTNy5Egef/xxBg/2b7iZPn06U6dOrS61MH78eN55552AVeYD8cADD5CRkSGFkIWYwHlzdWZhnzSkQ/W+ji3S+d9NJ1VvV9k1g45pxgfL8vhoxW6uObkz9364JiJybsn3H+G470iZ27p520lllZ29hWXY7ZrWWSnkmwpRK2B/UTn7jpRxbMsMtuQfpWlqEpVVdoodyhRAjw6tWbQxj/179/Do/XfzxtszKbfZKSpzKXgnnzKSBx7+J9379OdQcQUA+4sMa9HBo+WkJVl56flnOffiKyisNCxm0664gCdfnMGALrlYLYojpZXYHJqNrUpTWmGrnm60a40CCksraZKaWKOxwFZlZ19ROTlNUsh3vL+OLdLJcih3VY5r2DU4TxPOxNvr9xwhLSmBLq2C9+UKFVGo6oDFohjfJ4fxfXL458S+HC6uIDMlgR82HSA9OYG7Z69i6wHvEg4AK3YWsGJnAY9+vqG67duN+QA88tkGn8dM6N+W9OQEerTJJDs9mW6tM2iekUyztES25BeTnZ5EdnoSVXbNjkMlARWwI2WVrNlVyInH+q46Hy78lQloTLRt29anMhUMpRU2pk+fzmWXXVatUM2bN6/GY6rsGrvWDcq5VRDMTByYC8DtY47j9jHHAXD5sGM4cLScRIuFtGQrb/+8nV0FpVxxQkfAyPR+/osLeWRiX9btOVLtd5VoVfRp16R6Si5S7C8qZ39RuVvb4ZIKr/WC0gr80apNDv9+6Q0OHC332lduqzIc6ovdjy+rrKq2xE2fPp0Bo8+iWbZRpuW5N983rl1sWKO2HXTdw4orbGzaf5Te7Zpw8Gg5ewrLaJmZTH5ROW2bppKSYMGuISMlgb2FZdWJYQH2FJZxuKSCjCRrtbO/rcpQmCpsVSaFSldbpqqCcEnSWqO1xmKxsPdIGSkJFpqmJaG1psquSbBaqi10JRU27Fqz/4ghW0KYx0dRqMJIs3TDqjSquxFe/PUdI6v3aa3578/b6dY6k9W7Ctl6oJhVeQUkWS3V6RqcUSv++GjF7pDkOX9QLt3bZHLgaAX/W7kbq0Vx2+nd+OOsFfTMyaLcVsWW/GIW3j2aOcvz+O63fO4/qxcHi43+Z/bNYUt+MUM7ZfP5mr1MGtKelTsLGXlcS+6es5rJJx7DoGOy0VpTbrOzbPthUpOsDOzgKqp5+hPfsb+onHP6t+XeM3uy41AJHbLTfP6Qp729nNHdW3HeoFzeXbyDzJQEzuzb1q1PcbmNRKuFpATv40srbBwtr6JlZs0JA21VdqrsmuQQw6DvuusujjnmGG644QbAsO5kZmZy7bXXMmHCBA4fPkxlZSV///vfmTBhgtuxmzZvZcKEs1i3di2lpaVMmTKFdevW0aNHD7d6W9dffz1LliyhtLSU888/nzvu+St/f+wJdu/ezahRo2jRogXffPMNHTt2ZOnSpbRo0YInnniCGTNmAHDVVVdx66238sPydVx58UROHXkyCxcupF27dnz00UfVRUd9sWLFCq677jpKSko49thjmTFjBs2aNePpp5/mxRdfJCEhgZ49ezJz5ky+++47brnlFsCwKnz//fc1ZmwXhEhhvolPHt7JbV/77DQ2PTwegPOAe8/sid2u2bBhA0op2mensfNQCS0zk2mWlsTvB4qprLKjUGg0nVtkUFJhY+8Rw2/JZjcsNHW1ozz5j/tp2649F/3f1QC88MQjpKVncMFlk7nlqks5UliArbKSG+/8K6POMOTXQKLVwrZt27hp8kXMWbCIstJS7rt9Gls3baRTl+Pc6uT9/Z7bWLvyV8rKyzh9/NnccPs9vD3jJXbt3s3VF55F0+zmvPbe/xh3Ql/e+fQbWmW24++PPMY7b70BwMSLr+Cyq69n184dnDvqAvofP4wVyxbTqnUOT732NoVJCex2WNCUUnzz5Txee+bflFdU0LRZNk+/NIOUrGyOFhdz+y038+vyZVgtFm79058ZOfYsfvpmPk8/9jcSFWQ2bcYL73zI9Ecfpm2LZlw97RaUguHHD+C/s+ZSbqvimkvPY+TIkSxa9DMfffQh//znP/lh4S/V7++BBx5kf1EZ+7as5S933UHhkSISk5KZ+7/PuOi8CTz27yc5bYSRcX748OG88MIL9O3bt07foyhUEUIpxeWOp6Shnd0LNpZVGvPTKYlWKh03+3V7jtAyI5nTnviOjOQErjypEz9uOsCirQerj0uyWkhOsFRne/fkg2V5Xm1/nLUCgHV7jlS3nfiIKwnamc/86Pf4Z79xn8L830pDwWufncrOQy6l4I4x3Xj5+60cKXPJ9cai7RwuqeRjxzETB7ZjQv92vL90J8u3H6bcZudgcQWfrt7DwGOacY8jj037ZmmU2+zYtUaXVFLpMLX3WPkPLHtXY7UYilWV3U5VpZ1UQCdbDbMxhum4yq6xOga/yio7aMOsnJRspazS+LxTEi1UteqDZfwjaK05WFxBcoKFjOQEEiwWCkorOevc87jz9tu59rrrsSiYNes9vvjic1JSUnj97VkkpWawd99+JpwxirHj/0ByovH3KqmwseOw4R+gteaFF14gLS2NVatWsWrVKgYOHEhZpfFZPfzww2RnZ1Nps3HaqacxauxZXHrltbzz6vPM++IrmmUb1kStjSfI7duX8frrr7Po559Zu6uAKyaczsiRIymttLLj9y1cN2smr7zyChdeeCGzZ8/msssu8/lbAbjiiiuY/tRTjB41ivvuu48HH3yQ6dOn88gjj7Bp8xYOl2lSMZ6CH3/8cZ577jmGDx/O0aNHq4uWCkK8YbGo6immZmlJNPvuPthrjD/d0WiMsQRAocgAWnmcQztUKptdY0Fhs9uxWhQVVXa0hsqWvWhy7r8Bqq1gbZukkmBV7DhUwoSJF/D4g3/m8qumUmGz89UnH/LcW++TlJzCk6+8RUZmFocPHeTys09n5Jhx1Rb/So+Sae+9NYOU1DQ++Oonflu/hknjRlbvu+lP99KkWTOqqqqYOmkCv61fw6VXXst/X3mOV9/7X7WFysm3P/3Mu/99k//+bz5ozaVnn86gYcPJatKU7b9v4Z/Pvsr9jz3FnddPYf5nH3PmxItcn4fWDDz+BE756CuUUsx5902enf4Ed9z3dx7758NkZmUxe/5CAI4UFLBn3z4evOsWZnwwjxP792D1ll3Vn+eBo+XsKTTuL1V2zYFiYwzauHEjTzz7Itf/5Z9Y05K4dNpd3PBX1/v7cfFSOh3bjSlXXMpjz82gd/+BHC06QlGVhYkXX8Gsd/7LaSOMkjbl5eV1VqZAFKqYwJwwLtFqIdFKtZVn49/HVe8z50zxxc9bD1Jhs9M8I4m1u46QlZrA+0vzyEpN5PiO2cxbvYcfNx9gSMdsRnRtwZ4jZXy1bh/5Rd6m4lAwK1MAj3/5m89+TmUKYM7yXcxZvstnv1GPf1u9PuG5n6rXXzk7B+ckZkFJJamVdsDboldcXuXV5gunMuVcLy2rZI9J0fQkK7cb+/bvZ+HqTezdt4+UjEwKLFmU5R/lvnvuYfkvC7FYLOzbs5ufVm9hWO9j0dpwQK2wGddZvauQT75YwLQbbzKiX7I70LVHL3YeKqWwpIJnX3uL9956nYrKSg7s38f6desY3r4Ldg1bDxTTzJ5C39ym2Ox2dheW8uP8bzlt3JnsKrKTlp7ByDPO5Pvvv6fbkFG0a38Mx/XsTWmFja69+rJh0xa25B8lMyWBiko7bZulYquyU2Gzs31PPgcPHaZF1wHsPFTC6LMu4KarL2dPYSnde/bmgkmXcNJpY7nwvInsyiuga59B3HbbbVx66aVMnDiR3NzcoD7z+kQpNRZ4CrACr2qtH/HYrxz7xwMlwGSt9XLHvm1AEVAF2BpKJKJQNxSKYJwVnL0SHQ7PVosxpic4HvhITap2DOrdtgkllVVkJBu335REKz3bnsg9N+WTZjvCzt/zaNWiOSf2687BolIeeex+vvvuOxITrOTv28PB/P20aNW6+trOmRGAlUsWcfV1N9AsLYluPXrTtUcvwHj4XjDvQ2b99z9U2Wwc2L+PLb9tpFuP3oBRFqh7mywKSyuq3QR+XfIzo8eeSbOsTMptdk4deybLFy9i5OnjaNf+GLr36gNAjz792L3TOzrzUP5e7rzhSg7s30tlZSXt2h8DwFfz5/Poc69V98tq2pRvv/qMQUNPJLfDMew4VEKTZs28zudJTm572h3Xz7hWSQVffDKX2e+84fb+FIqWrVrTu/9AADIyswA4/cwJXHD6v9h7+CivvPoakydPDni9YBCFqgExzGT56tW2CYBbfqxLhnbwOuYf5/bxattdUEpOEyMFRH5RGSUVVXRskU6FzU5pRRWrdxUyunsryiqreH9pHgWlFZw3MJecJqmc9OjXHC23cfGQDlTZNW/9vB0wpjMtCv7vxI4UldlYvv0wWSmJHC230bllOp+v2cvADs1YvO1Qje8xJdFKWWUVe064n/SkBDcnzUhw2viz+eSjuRzcv48zzj4PgFnvvsPhgwd5d963JCYmMu6EvpSXl7N5/1G/UwGHPSKDAH5asZ5Xn3uKdz75mqymTbn31hs4UOh0fnWdyRmGDFBYWkFJRRUVpifV3YVldAMSk5KqffjKKjUlJaUUl9sodlg0D5VUcLC4glJdTt7hkuoopsMlFdURSvlF5fz7tXdZ9stCvvvyM0576nHmLFjE5Bv+yGlnjOP7BV8ybNgw5s+fT/fu3Wv3oYYBpZQVeA44HcgDliilPtZarzN1Gwd0dbyGAi84lk5Gaa3950YRGgfjHgncpw5YLKpamQLXA/X555/Ph3PmsHfvXi6+eBKZKYnMnvk2hw8eYNWKX0lMTKRjx46oqkpymqRiUUYKiMOVyaQkWumb25T05ARaZaXSPjuNJqmJJCdYOKZ5GkmlB/jvK8/x3U+LaNuqBZde/n9Y7Ta6tspEoWiVmUJSgoWWjiTV7ZulYbUY06fdWmdysLiCFhnJKKXITE4gOTmZRKuFbq0zyc5I4WDBEcMVw2qpHpMfve9PXDzlOkaOGc+yRT/y/BPG56q1RmEU4a6w2enaKoNfEq0uT3QTVmsCdu0a2yrKjYf/5ulJpKYa/qQKxc4d23jzpWfdxs6K8nLDcujjvKmpaQwbMZK335vNe++/x6/LloXjqxWFSvCmrSPCpklqos+sv86kcymJVq45ubPbvmX3nu62/bdzetdaDluVneKKKiqr7DRLS+K3jRvo1joTm92O3a5JSrCitaakooq0JCtKKcPiUmUnLSkBuyMBXnKClaKySrJSErHZNfuLymiSmsjh4koSrIqWmckUlFSSaDX+5OW2KhIsFgpLK0lOtKA1JCdYqLJr/u+yS/jjjddz4MABPvzsK1pmJmMrO0qXY9rSp31zvpy/gN15O1FARnICFgXHtsyg6EBi9YAzetQpzP94NmNPP5XNG9ezaf1akhMsqMpSMjLSycjKoqr4MAu/W8CQE42oprT0TMpLiklt04rySjtKKZKtVk4ddQq3TruWm2+9g5IKG19//gkPP/VSjZ9rWlICVouqjgZKTrSSmdWErCZNWbn0Z/oNHsYnc2YxeOhwtF2zd/cuhpw4ggHHD2PeRx9QUlxM4eFDtD/2OK7q3pN1K5eyYcOGqCpUwBBgs9Z6K4BSaiYwATArVBOAN7XhofqzUqqpUipHa70n8uIKgjuTJk3immuu4cCBA3z3nZENvrCwkFatWpGYmMg333zD9u3b6dQyo9pPtGlaEgUmheHkk0/m7bffZtSoUezYspE1q1eTlGClqKiI9PR0clo2Z//+/Sz46gvGnDaa1CQrzZpmYa9wn2XISk3k/D+MYfLkyfzlz/eQqjQff/Qhb775JtnZaSQlWDiudSYWizLG2rQkeuRkYdeaQ8UVZKcnUXK0iKG9u9KrbROemDeb9OQE+uY25ezxY/nygzf4w/TpABQUFHDOGaN46J7bKTm4h7TmOVgri8lt04q27duz5LsFdGqRzveLFrNr53Y6ZKeRlmQlKcFCmyYptMhIpmxfFU2zMhnYtR3Lf9vOwu8WMPb0U/nDiMHckb+f3ZvWcPzxx7Nt7wE6tmpGVnoKF132f9zwf5M45eSTyc7ODst3KAqVELMkWC00SfV2Pk+wWMDRrJQi3fS0l2C1VDu8W5SqLm7tLJORZFHVieIyTblYzI7szidG83mdDD9+AGUlxXTs0J5+3QyH15umXslZZ53FicOG0L9/f7p37073nCw6OrIppycn0K5pKlaLontOFrffchNTpkxh/CnD6N+/P0OGDKFD83QGDx7MrMGDuPiM4XTu3JkRJw2nXbM0+uY25eZp13Hz5AvJycnhm2++IcGi6NI6gxa9TuTqK6dw0R9GAzDtuqlceMYItm/fTkqitTqBYE7TVI4mVHkl12udlUJGehJ9c5sy653/Vjuld+7cmddff52MjAymXXIDhYWFaK2547ZbOanXMdx447/49ttvsVqt9OzZk3HjxhFl2gHmeYc83K1P/vq0A/ZgmAC/VEpp4CWt9cu+LqKUmgpMBejQwdviKwi1pVevXhQVFdGuXTtycoyZhUsvvZSzzjqLwYMHV48tNXH99dczZcoU+vbtWz22APTr148BAwbQq1cvOnfuzPDhw6uPmTp1KuPGjaseW5wMHDiQyZMnV5/j6quvZuDAgWzbtg3AZz4ni1LVQQEPPPAAF0+6iHbt2jFs2DC2/W5EVN57771MmzaNPn36YLVauf/++5k4cSIvv/wy10++BLvdTqtWrfjqq6+46crLOO+T2YwYdjzHH3883bp1qx6XLUpVl307ftBABg4cwKD+favHztQkK6kpKbz/3ixuuukmSktLSU1NZf78+SRaLUwcczJ/adqEK6+cEvJ35Q/JlC7EDZIpPb6IZKZ0pdQFwBla66sd25cDQ7TWN5n6fAr8U2v9o2N7AfAnrfUypVRbrfVupVQr4CvgJq319zVdU8awhoOMLY2P3bt3M3LkSDZs2IDF4v3gXpvxS5LUCILQEMgD2pu2cwHPPCN++2itncv9wFyMKURBEBogb775JkOHDuXhhx/2qUzVFlGoBEFoCCwBuiqlOimlkoBJwMcefT4GrlAGw4BCrfUepVS6UioTQCmVDowBIpNyWxCEiHPFFVewc+dOLrjggrCeV3yoBEGIe7TWNqXUjcAXGGkTZmit1yqlrnPsfxGYh5EyYTNG2gSn80RrYK4jt08C8I7W+vMIvwVBEOKcoBSquuR3EYRwImVs4oNo+GZqredhKE3mthdN6xqY5uO4rUC/ehdQiGlkbBGc1Hb8CjjlZ8rvMg7oCVyslOrp0c2c32UqRn4XQQgrKSkpHDx4MCo3ayF4tNYcPHhQsqcLcYOMLYKTuoxfwVioJL+LEBPk5uaSl5dHfn5+tEURApCSkhIT2dMFIRhkbBHM1Hb8Ckahqmt+F0EIC4mJiXTq1ClwR0EQhBCQsUUIB8FE+fmaVPa0iwbTB6XUVKXUUqXUUnkSEARBEAShoRCMQlWn/C5mtNYva60Ha60Ht2zZMlRZBUEQBEEQYpJgFKpa53cJs6yCIAiCIAgxSVClZ5RS44HpuPK7PGzO7+JIm/AsMBZHfhetdY01GZRS+cD2EGRtAcRjJXiRO7KI3JEnFNmP0Vo3CPN0iGNYvH6/InfkiVfZG4PcNY5fUavlFypKqaX1UQOsvhG5I4vIHXniWfZIEa+fkcgdeeJVdpFbSs8IgiAIgiDUGVGoBEEQBEEQ6kg8KVQvR1uAWiJyRxaRO/LEs+yRIl4/I5E78sSr7I1e7rjxoRIEQRAEQYhV4slCJQiCIAiCEJPEvEKllBqrlNqolNqslLo72vKYUUq1V0p9o5Rar5Raq5S6xdGerZT6Sim1ybFsZjrmHsd72aiUOiN60huFr5VSvyqlPnFsx7zcjjqRHyilNjg+9xPiRO5bHb+RNUqpd5VSKbEqt1JqhlJqv1JqjaktZFmVUoOUUqsd+552pFdpdMTqGCbjV3SQMaze5Yze+KW1jtkXRt6rLUBnIAlYCfSMtlwm+XKAgY71TOA3oCfwGHC3o/1u4FHHek/He0gGOjnemzWK8t8GvAN84tiOebmBN4CrHetJQNNYlxujruXvQKpj+z1gcqzKDZwMDATWmNpClhVYDJyAUZrqM2BctH7r0XrF8hgm41fU5JYxrH5ljdr4FZUfVAgfzAnAF6bte4B7oi1XDfJ+BJwObARyHG05wEZf8gNfACdESdZcYAEw2jQgxbTcQJbjT6082mNdbmfx8GyMguSfAGNiWW6go8eAFJKsjj4bTO0XAy9F+rOP9iuexjAZvyIit4xhkZE3KuNXrE/5Ob9EJ3mOtphDKdURGAD8ArTWjtI7jmUrR7dYej/TgT8BdlNbrMvdGcgHXneY+l9VSqUT43JrrXcBjwM7gD0YpZm+JMbl9iBUWds51j3bGxux+F16IeNXxJAxLDpEZPyKdYXK15xlzIUlKqUygNnAH7XWR2rq6qMt4u9HKXUmsF9rvSzYQ3y0ReN7SMAw5b6gtR4AFGOYb/0RE3I75usnYJiU2wLpSqnLajrER1vM/e4d+JM1nt5DfRLzn4OMXxFFxrDYIqzjV6wrVHlAe9N2LrA7SrL4RCmViDEYva21nuNo3qeUynHszwH2O9pj5f0MB85WSm0DZgKjlVL/JfblzgPytNa/OLY/wBicYl3u04Dftdb5WutKYA5wIrEvt5lQZc1zrHu2NzZi8busRsaviCNjWHSIyPgV6wrVEqCrUqqTUioJmAR8HGWZqnF4/b8GrNdaP2Ha9THwf471/8PwTXC2T1JKJSulOgFdMRzfIorW+h6tda7WuiPGZ/q11voyYl/uvcBOpdRxjqZTgXXEuNwYZvJhSqk0x2/mVGA9sS+3mZBkdZjVi5RSwxzv+QrTMY2JmB3DZPyKPDKGRY3IjF+Rdm6rhXPZeIzoky3AX6Itj4dsJ2GYAVcBKxyv8UBzDIfJTY5ltumYvzjey0ZiIOoJGInLqTPm5Qb6A0sdn/mHQLM4kftBYAOwBngLI6okJuUG3sXwk6jEeFK7qjayAoMd73cL8CwejriN5RWrY5iMX1GTWcaw+pUzauOXZEoXBEEQBEGoI7E+5ScIgiAIghDziEIlCIIgCIJQR0ShEgRBEARBqCOiUAmCIAiCINQRUagEQRAEQRDqiChUgiAIgiAIdUQUKkEQBEEQhDoiCpUgCIIgCEId+X9oLoiJDeFK3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].plot(hist.epoch, hist.history['loss'])\n",
    "axs[0].plot(hist.epoch, hist.history['val_loss'])\n",
    "axs[0].legend(('training loss', 'validation loss'), loc='lower right')\n",
    "axs[1].plot(hist.epoch, hist.history['mse'])\n",
    "axs[1].plot(hist.epoch, hist.history['val_mse'])\n",
    "axs[1].legend(('training accuracy','validation accuracy'), loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cab6c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    mod = tf.keras.models.Sequential()\n",
    "    mod.add(tf.keras.layers.Dense(57, input_dim=np.shape(train_x)[1], activation = 'relu'))\n",
    "    #mod.add(tf.keras.Dropout(.5))\n",
    "    mod.add(tf.keras.layers.Dense(12, activation = 'relu'))\n",
    "    #mod.add(tf.keras.Dropout(.5))\n",
    "    mod.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    mod.compile(loss = 'binary_crossentropy', optimizer =tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "106ac610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 57)                3306      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 12)                696       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 4,015\n",
      "Trainable params: 4,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "28ade705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6064 - val_loss: 0.6836 - val_accuracy: 0.5891\n",
      "Epoch 2/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.6102 - val_loss: 0.6790 - val_accuracy: 0.5891\n",
      "Epoch 3/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.6102 - val_loss: 0.6784 - val_accuracy: 0.5891\n",
      "Epoch 4/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6104 - val_loss: 0.6848 - val_accuracy: 0.5891\n",
      "Epoch 5/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.6102 - val_loss: 0.6807 - val_accuracy: 0.5891\n",
      "Epoch 6/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6102 - val_loss: 0.6848 - val_accuracy: 0.5891\n",
      "Epoch 7/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.6112 - val_loss: 0.6816 - val_accuracy: 0.5924\n",
      "Epoch 8/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6110 - val_loss: 0.6845 - val_accuracy: 0.5913\n",
      "Epoch 9/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6126 - val_loss: 0.6761 - val_accuracy: 0.5989\n",
      "Epoch 10/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6137 - val_loss: 0.6850 - val_accuracy: 0.5870\n",
      "Epoch 11/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6126 - val_loss: 0.6855 - val_accuracy: 0.5826\n",
      "Epoch 12/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6151 - val_loss: 0.6932 - val_accuracy: 0.5467\n",
      "Epoch 13/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6172 - val_loss: 0.6869 - val_accuracy: 0.5685\n",
      "Epoch 14/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6235 - val_loss: 0.6833 - val_accuracy: 0.5804\n",
      "Epoch 15/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6194 - val_loss: 0.6764 - val_accuracy: 0.5837\n",
      "Epoch 16/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6243 - val_loss: 0.6943 - val_accuracy: 0.5739\n",
      "Epoch 17/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6256 - val_loss: 0.7025 - val_accuracy: 0.5804\n",
      "Epoch 18/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6256 - val_loss: 0.6949 - val_accuracy: 0.5739\n",
      "Epoch 19/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6373 - val_loss: 0.6987 - val_accuracy: 0.5913\n",
      "Epoch 20/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6419 - val_loss: 0.6939 - val_accuracy: 0.5685\n",
      "Epoch 21/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6444 - val_loss: 0.7029 - val_accuracy: 0.5609\n",
      "Epoch 22/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6509 - val_loss: 0.6890 - val_accuracy: 0.5772\n",
      "Epoch 23/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.6487 - val_loss: 0.7150 - val_accuracy: 0.5761\n",
      "Epoch 24/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6164 - accuracy: 0.6574 - val_loss: 0.7160 - val_accuracy: 0.5750\n",
      "Epoch 25/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6151 - accuracy: 0.6487 - val_loss: 0.7274 - val_accuracy: 0.5663\n",
      "Epoch 26/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6088 - accuracy: 0.6710 - val_loss: 0.7182 - val_accuracy: 0.5348\n",
      "Epoch 27/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6601 - val_loss: 0.7479 - val_accuracy: 0.5739\n",
      "Epoch 28/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.6664 - val_loss: 0.7152 - val_accuracy: 0.5728\n",
      "Epoch 29/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.6683 - val_loss: 0.7445 - val_accuracy: 0.5630\n",
      "Epoch 30/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.6724 - val_loss: 0.7202 - val_accuracy: 0.5717\n",
      "Epoch 31/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.6767 - val_loss: 0.7842 - val_accuracy: 0.5641\n",
      "Epoch 32/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5902 - accuracy: 0.6816 - val_loss: 0.7513 - val_accuracy: 0.5576\n",
      "Epoch 33/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.6813 - val_loss: 0.7241 - val_accuracy: 0.5576\n",
      "Epoch 34/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.6873 - val_loss: 0.7525 - val_accuracy: 0.5239\n",
      "Epoch 35/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6819 - val_loss: 0.7425 - val_accuracy: 0.5663\n",
      "Epoch 36/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6908 - val_loss: 0.7671 - val_accuracy: 0.5098\n",
      "Epoch 37/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5767 - accuracy: 0.6955 - val_loss: 0.7462 - val_accuracy: 0.5641\n",
      "Epoch 38/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.6968 - val_loss: 0.7669 - val_accuracy: 0.5283\n",
      "Epoch 39/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.6985 - val_loss: 0.7664 - val_accuracy: 0.5359\n",
      "Epoch 40/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.6911 - val_loss: 0.7724 - val_accuracy: 0.5554\n",
      "Epoch 41/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7012 - val_loss: 0.7596 - val_accuracy: 0.5598\n",
      "Epoch 42/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.6985 - val_loss: 0.7866 - val_accuracy: 0.5239\n",
      "Epoch 43/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5611 - accuracy: 0.7028 - val_loss: 0.7811 - val_accuracy: 0.5522\n",
      "Epoch 44/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7042 - val_loss: 0.8072 - val_accuracy: 0.5500\n",
      "Epoch 45/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7077 - val_loss: 0.7686 - val_accuracy: 0.5522\n",
      "Epoch 46/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7074 - val_loss: 0.7997 - val_accuracy: 0.5554\n",
      "Epoch 47/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7101 - val_loss: 0.7780 - val_accuracy: 0.5728\n",
      "Epoch 48/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.7107 - val_loss: 0.8116 - val_accuracy: 0.5163\n",
      "Epoch 49/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7156 - val_loss: 0.7982 - val_accuracy: 0.5576\n",
      "Epoch 50/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7096 - val_loss: 0.8073 - val_accuracy: 0.5587\n",
      "Epoch 51/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7145 - val_loss: 0.8201 - val_accuracy: 0.5739\n",
      "Epoch 52/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.7180 - val_loss: 0.8546 - val_accuracy: 0.5663\n",
      "Epoch 53/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.7120 - val_loss: 0.8337 - val_accuracy: 0.5370\n",
      "Epoch 54/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.7131 - val_loss: 0.8126 - val_accuracy: 0.5565\n",
      "Epoch 55/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7248 - val_loss: 0.8077 - val_accuracy: 0.5761\n",
      "Epoch 56/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7153 - val_loss: 0.8482 - val_accuracy: 0.5587\n",
      "Epoch 57/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.7237 - val_loss: 0.8467 - val_accuracy: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5268 - accuracy: 0.7281 - val_loss: 0.8297 - val_accuracy: 0.5348\n",
      "Epoch 59/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7240 - val_loss: 0.8559 - val_accuracy: 0.5304\n",
      "Epoch 60/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7177 - val_loss: 0.8041 - val_accuracy: 0.5739\n",
      "Epoch 61/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7245 - val_loss: 0.8402 - val_accuracy: 0.5630\n",
      "Epoch 62/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7321 - val_loss: 0.8985 - val_accuracy: 0.5522\n",
      "Epoch 63/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7283 - val_loss: 0.8756 - val_accuracy: 0.5130\n",
      "Epoch 64/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7267 - val_loss: 0.8373 - val_accuracy: 0.5424\n",
      "Epoch 65/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7281 - val_loss: 0.8758 - val_accuracy: 0.5228\n",
      "Epoch 66/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7370 - val_loss: 0.8445 - val_accuracy: 0.5522\n",
      "Epoch 67/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7330 - val_loss: 0.8616 - val_accuracy: 0.5467\n",
      "Epoch 68/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7278 - val_loss: 0.8904 - val_accuracy: 0.5283\n",
      "Epoch 69/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7400 - val_loss: 0.9152 - val_accuracy: 0.5598\n",
      "Epoch 70/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7351 - val_loss: 0.9247 - val_accuracy: 0.5130\n",
      "Epoch 71/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7370 - val_loss: 0.8965 - val_accuracy: 0.5348\n",
      "Epoch 72/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7422 - val_loss: 0.8728 - val_accuracy: 0.5652\n",
      "Epoch 73/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7433 - val_loss: 0.8992 - val_accuracy: 0.5565\n",
      "Epoch 74/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7419 - val_loss: 0.8979 - val_accuracy: 0.5489\n",
      "Epoch 75/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7422 - val_loss: 0.9225 - val_accuracy: 0.5620\n",
      "Epoch 76/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7422 - val_loss: 0.8963 - val_accuracy: 0.5435\n",
      "Epoch 77/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7414 - val_loss: 0.9238 - val_accuracy: 0.5587\n",
      "Epoch 78/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7427 - val_loss: 0.9241 - val_accuracy: 0.5435\n",
      "Epoch 79/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7463 - val_loss: 0.9473 - val_accuracy: 0.5207\n",
      "Epoch 80/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7490 - val_loss: 0.9126 - val_accuracy: 0.5391\n",
      "Epoch 81/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7433 - val_loss: 0.8979 - val_accuracy: 0.5641\n",
      "Epoch 82/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7498 - val_loss: 0.9370 - val_accuracy: 0.5217\n",
      "Epoch 83/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7422 - val_loss: 0.9568 - val_accuracy: 0.5489\n",
      "Epoch 84/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7541 - val_loss: 0.9792 - val_accuracy: 0.5293\n",
      "Epoch 85/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7555 - val_loss: 0.9311 - val_accuracy: 0.5576\n",
      "Epoch 86/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7490 - val_loss: 0.9840 - val_accuracy: 0.5446\n",
      "Epoch 87/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7471 - val_loss: 0.9453 - val_accuracy: 0.5565\n",
      "Epoch 88/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7585 - val_loss: 0.9748 - val_accuracy: 0.5120\n",
      "Epoch 89/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7493 - val_loss: 0.9385 - val_accuracy: 0.5478\n",
      "Epoch 90/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7514 - val_loss: 0.9642 - val_accuracy: 0.5598\n",
      "Epoch 91/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7596 - val_loss: 0.9482 - val_accuracy: 0.5402\n",
      "Epoch 92/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7547 - val_loss: 1.0255 - val_accuracy: 0.5402\n",
      "Epoch 93/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7675 - val_loss: 1.0081 - val_accuracy: 0.5674\n",
      "Epoch 94/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7601 - val_loss: 0.9894 - val_accuracy: 0.5293\n",
      "Epoch 95/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7615 - val_loss: 0.9993 - val_accuracy: 0.5457\n",
      "Epoch 96/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7615 - val_loss: 0.9475 - val_accuracy: 0.5576\n",
      "Epoch 97/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 1.0337 - val_accuracy: 0.5576\n",
      "Epoch 98/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7631 - val_loss: 0.9526 - val_accuracy: 0.5565\n",
      "Epoch 99/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7669 - val_loss: 1.0101 - val_accuracy: 0.5413\n",
      "Epoch 100/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7699 - val_loss: 1.0209 - val_accuracy: 0.5424\n",
      "Epoch 101/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7669 - val_loss: 1.0430 - val_accuracy: 0.5500\n",
      "Epoch 102/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7653 - val_loss: 1.0042 - val_accuracy: 0.5609\n",
      "Epoch 103/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7704 - val_loss: 1.0267 - val_accuracy: 0.5370\n",
      "Epoch 104/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7669 - val_loss: 1.0574 - val_accuracy: 0.5326\n",
      "Epoch 105/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7685 - val_loss: 0.9847 - val_accuracy: 0.5598\n",
      "Epoch 106/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7656 - val_loss: 1.0685 - val_accuracy: 0.5543\n",
      "Epoch 107/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7791 - val_loss: 0.9785 - val_accuracy: 0.5576\n",
      "Epoch 108/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7759 - val_loss: 1.0404 - val_accuracy: 0.5250\n",
      "Epoch 109/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7789 - val_loss: 1.0293 - val_accuracy: 0.5283\n",
      "Epoch 110/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7797 - val_loss: 1.0180 - val_accuracy: 0.5489\n",
      "Epoch 111/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7764 - val_loss: 1.1305 - val_accuracy: 0.5207\n",
      "Epoch 112/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7770 - val_loss: 1.0209 - val_accuracy: 0.5446\n",
      "Epoch 113/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7742 - val_loss: 1.0395 - val_accuracy: 0.5467\n",
      "Epoch 114/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7772 - val_loss: 1.0327 - val_accuracy: 0.5435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7821 - val_loss: 1.1296 - val_accuracy: 0.5293\n",
      "Epoch 116/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7748 - val_loss: 1.0991 - val_accuracy: 0.5217\n",
      "Epoch 117/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7816 - val_loss: 1.1225 - val_accuracy: 0.5054\n",
      "Epoch 118/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7851 - val_loss: 1.0365 - val_accuracy: 0.5489\n",
      "Epoch 119/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7794 - val_loss: 1.0707 - val_accuracy: 0.5435\n",
      "Epoch 120/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7756 - val_loss: 1.0946 - val_accuracy: 0.5500\n",
      "Epoch 121/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7838 - val_loss: 1.0958 - val_accuracy: 0.5239\n",
      "Epoch 122/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7884 - val_loss: 1.0853 - val_accuracy: 0.5391\n",
      "Epoch 123/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7886 - val_loss: 1.0497 - val_accuracy: 0.5543\n",
      "Epoch 124/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7911 - val_loss: 1.0910 - val_accuracy: 0.5348\n",
      "Epoch 125/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7851 - val_loss: 1.1072 - val_accuracy: 0.5457\n",
      "Epoch 126/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7886 - val_loss: 1.0978 - val_accuracy: 0.5304\n",
      "Epoch 127/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7813 - val_loss: 1.1547 - val_accuracy: 0.5283\n",
      "Epoch 128/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7889 - val_loss: 1.1438 - val_accuracy: 0.5185\n",
      "Epoch 129/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7905 - val_loss: 1.1675 - val_accuracy: 0.5489\n",
      "Epoch 130/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.7859 - val_loss: 1.1618 - val_accuracy: 0.5522\n",
      "Epoch 131/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.7916 - val_loss: 1.1057 - val_accuracy: 0.5489\n",
      "Epoch 132/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.7916 - val_loss: 1.1519 - val_accuracy: 0.5424\n",
      "Epoch 133/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7800 - val_loss: 1.1769 - val_accuracy: 0.5076\n",
      "Epoch 134/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7884 - val_loss: 1.1138 - val_accuracy: 0.5348\n",
      "Epoch 135/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7960 - val_loss: 1.1580 - val_accuracy: 0.5446\n",
      "Epoch 136/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4193 - accuracy: 0.7943 - val_loss: 1.2066 - val_accuracy: 0.5196\n",
      "Epoch 137/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7935 - val_loss: 1.1637 - val_accuracy: 0.5511\n",
      "Epoch 138/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.7935 - val_loss: 1.2039 - val_accuracy: 0.5250\n",
      "Epoch 139/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.7976 - val_loss: 1.1595 - val_accuracy: 0.5413\n",
      "Epoch 140/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.7949 - val_loss: 1.1296 - val_accuracy: 0.5413\n",
      "Epoch 141/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.7933 - val_loss: 1.2541 - val_accuracy: 0.4500\n",
      "Epoch 142/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.7968 - val_loss: 1.2300 - val_accuracy: 0.5228\n",
      "Epoch 143/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8017 - val_loss: 1.2017 - val_accuracy: 0.5359\n",
      "Epoch 144/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.7952 - val_loss: 1.2057 - val_accuracy: 0.5348\n",
      "Epoch 145/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.7960 - val_loss: 1.2793 - val_accuracy: 0.4957\n",
      "Epoch 146/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.7987 - val_loss: 1.1693 - val_accuracy: 0.5533\n",
      "Epoch 147/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.7995 - val_loss: 1.2064 - val_accuracy: 0.5228\n",
      "Epoch 148/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.7960 - val_loss: 1.2372 - val_accuracy: 0.5109\n",
      "Epoch 149/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8003 - val_loss: 1.1880 - val_accuracy: 0.5435\n",
      "Epoch 150/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.7927 - val_loss: 1.1640 - val_accuracy: 0.5446\n",
      "Epoch 151/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8030 - val_loss: 1.2721 - val_accuracy: 0.5228\n",
      "Epoch 152/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.7916 - val_loss: 1.1503 - val_accuracy: 0.5413\n",
      "Epoch 153/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8068 - val_loss: 1.2394 - val_accuracy: 0.5207\n",
      "Epoch 154/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.7952 - val_loss: 1.2200 - val_accuracy: 0.5576\n",
      "Epoch 155/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.7968 - val_loss: 1.2566 - val_accuracy: 0.5239\n",
      "Epoch 156/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.7992 - val_loss: 1.2658 - val_accuracy: 0.5120\n",
      "Epoch 157/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8052 - val_loss: 1.2409 - val_accuracy: 0.5391\n",
      "Epoch 158/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8074 - val_loss: 1.2449 - val_accuracy: 0.5076\n",
      "Epoch 159/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.7998 - val_loss: 1.2690 - val_accuracy: 0.5239\n",
      "Epoch 160/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8011 - val_loss: 1.2312 - val_accuracy: 0.5446\n",
      "Epoch 161/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8039 - val_loss: 1.2672 - val_accuracy: 0.5054\n",
      "Epoch 162/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8003 - val_loss: 1.3127 - val_accuracy: 0.5457\n",
      "Epoch 163/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8025 - val_loss: 1.2453 - val_accuracy: 0.5304\n",
      "Epoch 164/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8060 - val_loss: 1.3197 - val_accuracy: 0.5457\n",
      "Epoch 165/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.7976 - val_loss: 1.2754 - val_accuracy: 0.5239\n",
      "Epoch 166/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8093 - val_loss: 1.2168 - val_accuracy: 0.5435\n",
      "Epoch 167/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8025 - val_loss: 1.3006 - val_accuracy: 0.5098\n",
      "Epoch 168/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8117 - val_loss: 1.3252 - val_accuracy: 0.5087\n",
      "Epoch 169/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.7990 - val_loss: 1.3015 - val_accuracy: 0.5402\n",
      "Epoch 170/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8087 - val_loss: 1.3572 - val_accuracy: 0.5087\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8123 - val_loss: 1.2485 - val_accuracy: 0.5750\n",
      "Epoch 172/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8036 - val_loss: 1.2553 - val_accuracy: 0.5337\n",
      "Epoch 173/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8047 - val_loss: 1.3006 - val_accuracy: 0.5141\n",
      "Epoch 174/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8074 - val_loss: 1.3026 - val_accuracy: 0.5283\n",
      "Epoch 175/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8139 - val_loss: 1.2786 - val_accuracy: 0.5402\n",
      "Epoch 176/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8131 - val_loss: 1.3946 - val_accuracy: 0.4457\n",
      "Epoch 177/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.7982 - val_loss: 1.3244 - val_accuracy: 0.5348\n",
      "Epoch 178/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8104 - val_loss: 1.3116 - val_accuracy: 0.5413\n",
      "Epoch 179/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8085 - val_loss: 1.3018 - val_accuracy: 0.5728\n",
      "Epoch 180/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8101 - val_loss: 1.3264 - val_accuracy: 0.5326\n",
      "Epoch 181/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8155 - val_loss: 1.3025 - val_accuracy: 0.5380\n",
      "Epoch 182/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8117 - val_loss: 1.3577 - val_accuracy: 0.5250\n",
      "Epoch 183/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8150 - val_loss: 1.3397 - val_accuracy: 0.5261\n",
      "Epoch 184/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8126 - val_loss: 1.2701 - val_accuracy: 0.5543\n",
      "Epoch 185/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8166 - val_loss: 1.3408 - val_accuracy: 0.5174\n",
      "Epoch 186/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8093 - val_loss: 1.3194 - val_accuracy: 0.5424\n",
      "Epoch 187/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8068 - val_loss: 1.4347 - val_accuracy: 0.5207\n",
      "Epoch 188/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8085 - val_loss: 1.3034 - val_accuracy: 0.5565\n",
      "Epoch 189/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8164 - val_loss: 1.3942 - val_accuracy: 0.5087\n",
      "Epoch 190/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8090 - val_loss: 1.2797 - val_accuracy: 0.5576\n",
      "Epoch 191/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8210 - val_loss: 1.3456 - val_accuracy: 0.5370\n",
      "Epoch 192/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8191 - val_loss: 1.2456 - val_accuracy: 0.5717\n",
      "Epoch 193/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8123 - val_loss: 1.2874 - val_accuracy: 0.5522\n",
      "Epoch 194/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8153 - val_loss: 1.3401 - val_accuracy: 0.5261\n",
      "Epoch 195/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8172 - val_loss: 1.3789 - val_accuracy: 0.5359\n",
      "Epoch 196/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8139 - val_loss: 1.3247 - val_accuracy: 0.5380\n",
      "Epoch 197/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8161 - val_loss: 1.3078 - val_accuracy: 0.5543\n",
      "Epoch 198/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8142 - val_loss: 1.3599 - val_accuracy: 0.5120\n",
      "Epoch 199/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8193 - val_loss: 1.4448 - val_accuracy: 0.5228\n",
      "Epoch 200/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8117 - val_loss: 1.3391 - val_accuracy: 0.5163\n",
      "Epoch 201/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8218 - val_loss: 1.4953 - val_accuracy: 0.4609\n",
      "Epoch 202/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8098 - val_loss: 1.3847 - val_accuracy: 0.5228\n",
      "Epoch 203/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8204 - val_loss: 1.3306 - val_accuracy: 0.5554\n",
      "Epoch 204/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8126 - val_loss: 1.3250 - val_accuracy: 0.5609\n",
      "Epoch 205/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8207 - val_loss: 1.3380 - val_accuracy: 0.5587\n",
      "Epoch 206/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8185 - val_loss: 1.3908 - val_accuracy: 0.5565\n",
      "Epoch 207/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8115 - val_loss: 1.4457 - val_accuracy: 0.4717\n",
      "Epoch 208/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8188 - val_loss: 1.3599 - val_accuracy: 0.5446\n",
      "Epoch 209/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8207 - val_loss: 1.4233 - val_accuracy: 0.4935\n",
      "Epoch 210/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8174 - val_loss: 1.3566 - val_accuracy: 0.5609\n",
      "Epoch 211/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8169 - val_loss: 1.4408 - val_accuracy: 0.5065\n",
      "Epoch 212/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8098 - val_loss: 1.2932 - val_accuracy: 0.5674\n",
      "Epoch 213/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8240 - val_loss: 1.4032 - val_accuracy: 0.5326\n",
      "Epoch 214/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8196 - val_loss: 1.3950 - val_accuracy: 0.5554\n",
      "Epoch 215/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8267 - val_loss: 1.3958 - val_accuracy: 0.5261\n",
      "Epoch 216/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8226 - val_loss: 1.3840 - val_accuracy: 0.5467\n",
      "Epoch 217/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8242 - val_loss: 1.4941 - val_accuracy: 0.5337\n",
      "Epoch 218/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8218 - val_loss: 1.4865 - val_accuracy: 0.5261\n",
      "Epoch 219/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8207 - val_loss: 1.3787 - val_accuracy: 0.5554\n",
      "Epoch 220/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8278 - val_loss: 1.4119 - val_accuracy: 0.5489\n",
      "Epoch 221/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8237 - val_loss: 1.4310 - val_accuracy: 0.5489\n",
      "Epoch 222/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8221 - val_loss: 1.4202 - val_accuracy: 0.5402\n",
      "Epoch 223/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8199 - val_loss: 1.4879 - val_accuracy: 0.5272\n",
      "Epoch 224/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8289 - val_loss: 1.5290 - val_accuracy: 0.5250\n",
      "Epoch 225/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3538 - accuracy: 0.8256 - val_loss: 1.4932 - val_accuracy: 0.5163\n",
      "Epoch 226/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8269 - val_loss: 1.4360 - val_accuracy: 0.5370\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8259 - val_loss: 1.4264 - val_accuracy: 0.5380\n",
      "Epoch 228/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8218 - val_loss: 1.3790 - val_accuracy: 0.5641\n",
      "Epoch 229/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8218 - val_loss: 1.5393 - val_accuracy: 0.5413\n",
      "Epoch 230/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8250 - val_loss: 1.4483 - val_accuracy: 0.5565\n",
      "Epoch 231/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8272 - val_loss: 1.4944 - val_accuracy: 0.5283\n",
      "Epoch 232/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8253 - val_loss: 1.5144 - val_accuracy: 0.5576\n",
      "Epoch 233/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8256 - val_loss: 1.5433 - val_accuracy: 0.4783\n",
      "Epoch 234/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8299 - val_loss: 1.4307 - val_accuracy: 0.5337\n",
      "Epoch 235/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8253 - val_loss: 1.5560 - val_accuracy: 0.5207\n",
      "Epoch 236/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8253 - val_loss: 1.4770 - val_accuracy: 0.5261\n",
      "Epoch 237/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8248 - val_loss: 1.4454 - val_accuracy: 0.5185\n",
      "Epoch 238/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8278 - val_loss: 1.6058 - val_accuracy: 0.5467\n",
      "Epoch 239/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8264 - val_loss: 1.4850 - val_accuracy: 0.5326\n",
      "Epoch 240/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8223 - val_loss: 1.6532 - val_accuracy: 0.4620\n",
      "Epoch 241/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8231 - val_loss: 1.5624 - val_accuracy: 0.5359\n",
      "Epoch 242/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8286 - val_loss: 1.5219 - val_accuracy: 0.5467\n",
      "Epoch 243/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8321 - val_loss: 1.4493 - val_accuracy: 0.5587\n",
      "Epoch 244/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8286 - val_loss: 1.5023 - val_accuracy: 0.5359\n",
      "Epoch 245/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8229 - val_loss: 1.5849 - val_accuracy: 0.5250\n",
      "Epoch 246/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8297 - val_loss: 1.4899 - val_accuracy: 0.5478\n",
      "Epoch 247/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8324 - val_loss: 1.5385 - val_accuracy: 0.5370\n",
      "Epoch 248/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8346 - val_loss: 1.6330 - val_accuracy: 0.4663\n",
      "Epoch 249/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8256 - val_loss: 1.5559 - val_accuracy: 0.5478\n",
      "Epoch 250/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8321 - val_loss: 1.5910 - val_accuracy: 0.5424\n",
      "Epoch 251/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.8229 - val_loss: 1.5127 - val_accuracy: 0.5478\n",
      "Epoch 252/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8335 - val_loss: 1.5461 - val_accuracy: 0.4761\n",
      "Epoch 253/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8321 - val_loss: 1.5279 - val_accuracy: 0.5370\n",
      "Epoch 254/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8332 - val_loss: 1.5654 - val_accuracy: 0.4804\n",
      "Epoch 255/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8291 - val_loss: 1.5635 - val_accuracy: 0.5196\n",
      "Epoch 256/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8308 - val_loss: 1.6328 - val_accuracy: 0.5533\n",
      "Epoch 257/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8356 - val_loss: 1.6216 - val_accuracy: 0.5152\n",
      "Epoch 258/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8286 - val_loss: 1.5101 - val_accuracy: 0.5435\n",
      "Epoch 259/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8337 - val_loss: 1.6046 - val_accuracy: 0.5304\n",
      "Epoch 260/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8324 - val_loss: 1.5625 - val_accuracy: 0.5043\n",
      "Epoch 261/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8310 - val_loss: 1.4945 - val_accuracy: 0.5500\n",
      "Epoch 262/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8335 - val_loss: 1.5127 - val_accuracy: 0.5565\n",
      "Epoch 263/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8240 - val_loss: 1.6286 - val_accuracy: 0.5196\n",
      "Epoch 264/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8264 - val_loss: 1.5455 - val_accuracy: 0.5467\n",
      "Epoch 265/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8327 - val_loss: 1.6512 - val_accuracy: 0.5163\n",
      "Epoch 266/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8351 - val_loss: 1.6056 - val_accuracy: 0.5109\n",
      "Epoch 267/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8308 - val_loss: 1.5766 - val_accuracy: 0.5391\n",
      "Epoch 268/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8324 - val_loss: 1.6458 - val_accuracy: 0.5217\n",
      "Epoch 269/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8367 - val_loss: 1.6436 - val_accuracy: 0.5304\n",
      "Epoch 270/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8318 - val_loss: 1.6444 - val_accuracy: 0.5152\n",
      "Epoch 271/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8302 - val_loss: 1.7117 - val_accuracy: 0.4685\n",
      "Epoch 272/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8316 - val_loss: 1.5851 - val_accuracy: 0.5261\n",
      "Epoch 273/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8335 - val_loss: 1.6612 - val_accuracy: 0.5185\n",
      "Epoch 274/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8316 - val_loss: 1.5597 - val_accuracy: 0.5380\n",
      "Epoch 275/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8286 - val_loss: 1.5841 - val_accuracy: 0.5348\n",
      "Epoch 276/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8316 - val_loss: 1.5726 - val_accuracy: 0.5435\n",
      "Epoch 277/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8283 - val_loss: 1.6816 - val_accuracy: 0.5043\n",
      "Epoch 278/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8346 - val_loss: 1.6592 - val_accuracy: 0.5196\n",
      "Epoch 279/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8310 - val_loss: 1.5760 - val_accuracy: 0.5522\n",
      "Epoch 280/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8365 - val_loss: 1.6141 - val_accuracy: 0.5337\n",
      "Epoch 281/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8394 - val_loss: 1.5884 - val_accuracy: 0.5522\n",
      "Epoch 282/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8427 - val_loss: 1.7592 - val_accuracy: 0.5043\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8449 - val_loss: 1.6475 - val_accuracy: 0.5522\n",
      "Epoch 284/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8362 - val_loss: 1.6274 - val_accuracy: 0.5522\n",
      "Epoch 285/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8318 - val_loss: 1.6916 - val_accuracy: 0.5315\n",
      "Epoch 286/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8348 - val_loss: 1.7334 - val_accuracy: 0.4793\n",
      "Epoch 287/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8392 - val_loss: 1.6963 - val_accuracy: 0.5446\n",
      "Epoch 288/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8411 - val_loss: 1.6662 - val_accuracy: 0.5228\n",
      "Epoch 289/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8375 - val_loss: 1.6129 - val_accuracy: 0.5533\n",
      "Epoch 290/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8318 - val_loss: 1.6867 - val_accuracy: 0.5174\n",
      "Epoch 291/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8365 - val_loss: 1.5923 - val_accuracy: 0.5478\n",
      "Epoch 292/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8471 - val_loss: 1.6483 - val_accuracy: 0.5467\n",
      "Epoch 293/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8375 - val_loss: 1.7538 - val_accuracy: 0.5054\n",
      "Epoch 294/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8291 - val_loss: 1.8005 - val_accuracy: 0.5228\n",
      "Epoch 295/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8381 - val_loss: 1.7810 - val_accuracy: 0.5174\n",
      "Epoch 296/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8392 - val_loss: 1.7340 - val_accuracy: 0.5196\n",
      "Epoch 297/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8427 - val_loss: 1.7025 - val_accuracy: 0.5391\n",
      "Epoch 298/500\n",
      "185/185 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.83 - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8381 - val_loss: 1.7685 - val_accuracy: 0.5217\n",
      "Epoch 299/500\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8378 - val_loss: 1.7595 - val_accuracy: 0.5250\n",
      "Epoch 300/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8340 - val_loss: 1.7300 - val_accuracy: 0.5402\n",
      "Epoch 301/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8370 - val_loss: 1.7772 - val_accuracy: 0.5043\n",
      "Epoch 302/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8329 - val_loss: 1.7293 - val_accuracy: 0.5424\n",
      "Epoch 303/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8432 - val_loss: 1.7465 - val_accuracy: 0.5337\n",
      "Epoch 304/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8438 - val_loss: 1.6707 - val_accuracy: 0.5478\n",
      "Epoch 305/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8446 - val_loss: 1.7518 - val_accuracy: 0.5457\n",
      "Epoch 306/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8370 - val_loss: 1.7192 - val_accuracy: 0.5304\n",
      "Epoch 307/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3213 - accuracy: 0.8435 - val_loss: 1.7456 - val_accuracy: 0.5370\n",
      "Epoch 308/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8340 - val_loss: 1.6666 - val_accuracy: 0.5489\n",
      "Epoch 309/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8460 - val_loss: 1.7386 - val_accuracy: 0.5261\n",
      "Epoch 310/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8443 - val_loss: 1.7215 - val_accuracy: 0.5359\n",
      "Epoch 311/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8400 - val_loss: 1.7110 - val_accuracy: 0.5630\n",
      "Epoch 312/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8405 - val_loss: 1.7239 - val_accuracy: 0.5533\n",
      "Epoch 313/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8465 - val_loss: 1.7756 - val_accuracy: 0.5239\n",
      "Epoch 314/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8354 - val_loss: 1.6990 - val_accuracy: 0.5304\n",
      "Epoch 315/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8332 - val_loss: 1.7660 - val_accuracy: 0.5359\n",
      "Epoch 316/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8484 - val_loss: 1.6941 - val_accuracy: 0.5457\n",
      "Epoch 317/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8337 - val_loss: 1.6744 - val_accuracy: 0.5413\n",
      "Epoch 318/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8400 - val_loss: 1.7605 - val_accuracy: 0.5359\n",
      "Epoch 319/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3222 - accuracy: 0.8413 - val_loss: 1.7261 - val_accuracy: 0.5120\n",
      "Epoch 320/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8386 - val_loss: 1.8085 - val_accuracy: 0.5467\n",
      "Epoch 321/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8476 - val_loss: 1.7290 - val_accuracy: 0.5500\n",
      "Epoch 322/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8411 - val_loss: 1.6875 - val_accuracy: 0.5533\n",
      "Epoch 323/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8457 - val_loss: 1.7045 - val_accuracy: 0.5228\n",
      "Epoch 324/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8362 - val_loss: 1.7411 - val_accuracy: 0.5500\n",
      "Epoch 325/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8354 - val_loss: 1.7845 - val_accuracy: 0.5370\n",
      "Epoch 326/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8435 - val_loss: 1.8441 - val_accuracy: 0.5413\n",
      "Epoch 327/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8446 - val_loss: 1.8253 - val_accuracy: 0.5250\n",
      "Epoch 328/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8405 - val_loss: 1.8398 - val_accuracy: 0.5196\n",
      "Epoch 329/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8462 - val_loss: 1.7151 - val_accuracy: 0.5380\n",
      "Epoch 330/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8449 - val_loss: 1.7293 - val_accuracy: 0.5500\n",
      "Epoch 331/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8435 - val_loss: 1.8618 - val_accuracy: 0.5272\n",
      "Epoch 332/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8419 - val_loss: 1.7748 - val_accuracy: 0.5424\n",
      "Epoch 333/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8506 - val_loss: 1.8245 - val_accuracy: 0.5196\n",
      "Epoch 334/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3236 - accuracy: 0.8362 - val_loss: 1.8994 - val_accuracy: 0.5239\n",
      "Epoch 335/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8514 - val_loss: 1.7842 - val_accuracy: 0.5489\n",
      "Epoch 336/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8506 - val_loss: 1.8047 - val_accuracy: 0.5446\n",
      "Epoch 337/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3171 - accuracy: 0.8452 - val_loss: 1.7970 - val_accuracy: 0.5413\n",
      "Epoch 338/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8460 - val_loss: 1.8703 - val_accuracy: 0.4837\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8354 - val_loss: 1.6801 - val_accuracy: 0.5609\n",
      "Epoch 340/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8495 - val_loss: 1.6979 - val_accuracy: 0.5457\n",
      "Epoch 341/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8473 - val_loss: 1.8597 - val_accuracy: 0.5283\n",
      "Epoch 342/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8473 - val_loss: 1.7933 - val_accuracy: 0.5446\n",
      "Epoch 343/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3179 - accuracy: 0.8405 - val_loss: 1.8851 - val_accuracy: 0.5174\n",
      "Epoch 344/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8490 - val_loss: 1.7496 - val_accuracy: 0.5478\n",
      "Epoch 345/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.8498 - val_loss: 1.7983 - val_accuracy: 0.5478\n",
      "Epoch 346/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3153 - accuracy: 0.8443 - val_loss: 1.7314 - val_accuracy: 0.5565\n",
      "Epoch 347/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3144 - accuracy: 0.8400 - val_loss: 1.7637 - val_accuracy: 0.5533\n",
      "Epoch 348/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8430 - val_loss: 1.8382 - val_accuracy: 0.5391\n",
      "Epoch 349/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8438 - val_loss: 1.8568 - val_accuracy: 0.5293\n",
      "Epoch 350/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8509 - val_loss: 1.8667 - val_accuracy: 0.5380\n",
      "Epoch 351/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8452 - val_loss: 1.7883 - val_accuracy: 0.5457\n",
      "Epoch 352/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8462 - val_loss: 1.8229 - val_accuracy: 0.5489\n",
      "Epoch 353/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8576 - val_loss: 1.9856 - val_accuracy: 0.5196\n",
      "Epoch 354/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8514 - val_loss: 1.9391 - val_accuracy: 0.4880\n",
      "Epoch 355/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8449 - val_loss: 1.8520 - val_accuracy: 0.5467\n",
      "Epoch 356/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8498 - val_loss: 1.8453 - val_accuracy: 0.5446\n",
      "Epoch 357/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8484 - val_loss: 1.9090 - val_accuracy: 0.5185\n",
      "Epoch 358/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8536 - val_loss: 1.8896 - val_accuracy: 0.5261\n",
      "Epoch 359/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8525 - val_loss: 1.8932 - val_accuracy: 0.5370\n",
      "Epoch 360/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8498 - val_loss: 1.8944 - val_accuracy: 0.4870\n",
      "Epoch 361/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8446 - val_loss: 1.8132 - val_accuracy: 0.5554\n",
      "Epoch 362/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8359 - val_loss: 1.8952 - val_accuracy: 0.5087\n",
      "Epoch 363/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8422 - val_loss: 1.8835 - val_accuracy: 0.5413\n",
      "Epoch 364/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8465 - val_loss: 1.9007 - val_accuracy: 0.5261\n",
      "Epoch 365/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.8541 - val_loss: 1.8855 - val_accuracy: 0.5467\n",
      "Epoch 366/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8471 - val_loss: 1.9159 - val_accuracy: 0.5098\n",
      "Epoch 367/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8509 - val_loss: 1.8367 - val_accuracy: 0.5370\n",
      "Epoch 368/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8511 - val_loss: 1.8602 - val_accuracy: 0.5500\n",
      "Epoch 369/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8443 - val_loss: 1.9126 - val_accuracy: 0.5359\n",
      "Epoch 370/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8484 - val_loss: 1.7868 - val_accuracy: 0.5554\n",
      "Epoch 371/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8549 - val_loss: 1.8120 - val_accuracy: 0.5641\n",
      "Epoch 372/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3060 - accuracy: 0.8514 - val_loss: 1.8470 - val_accuracy: 0.5489\n",
      "Epoch 373/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8490 - val_loss: 1.9876 - val_accuracy: 0.5272\n",
      "Epoch 374/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8481 - val_loss: 1.8944 - val_accuracy: 0.5315\n",
      "Epoch 375/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8519 - val_loss: 1.9074 - val_accuracy: 0.5283\n",
      "Epoch 376/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8457 - val_loss: 1.8476 - val_accuracy: 0.5511\n",
      "Epoch 377/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8449 - val_loss: 1.8926 - val_accuracy: 0.5489\n",
      "Epoch 378/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8511 - val_loss: 1.8556 - val_accuracy: 0.5435\n",
      "Epoch 379/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8506 - val_loss: 1.8639 - val_accuracy: 0.5543\n",
      "Epoch 380/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8536 - val_loss: 1.8873 - val_accuracy: 0.5522\n",
      "Epoch 381/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8460 - val_loss: 1.9475 - val_accuracy: 0.5359\n",
      "Epoch 382/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8541 - val_loss: 1.9558 - val_accuracy: 0.5293\n",
      "Epoch 383/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8492 - val_loss: 2.0927 - val_accuracy: 0.5196\n",
      "Epoch 384/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8536 - val_loss: 1.9642 - val_accuracy: 0.5457\n",
      "Epoch 385/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8533 - val_loss: 1.8914 - val_accuracy: 0.5467\n",
      "Epoch 386/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8471 - val_loss: 1.9552 - val_accuracy: 0.5391\n",
      "Epoch 387/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8528 - val_loss: 2.0423 - val_accuracy: 0.4957\n",
      "Epoch 388/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8484 - val_loss: 1.9150 - val_accuracy: 0.5533\n",
      "Epoch 389/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8533 - val_loss: 2.0584 - val_accuracy: 0.5228\n",
      "Epoch 390/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8533 - val_loss: 1.9590 - val_accuracy: 0.5293\n",
      "Epoch 391/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8549 - val_loss: 1.9047 - val_accuracy: 0.5348\n",
      "Epoch 392/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8481 - val_loss: 1.9981 - val_accuracy: 0.5293\n",
      "Epoch 393/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8560 - val_loss: 1.9533 - val_accuracy: 0.5446\n",
      "Epoch 394/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8555 - val_loss: 2.0324 - val_accuracy: 0.4783\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8495 - val_loss: 2.0567 - val_accuracy: 0.5380\n",
      "Epoch 396/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8566 - val_loss: 2.0774 - val_accuracy: 0.5391\n",
      "Epoch 397/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8457 - val_loss: 1.9726 - val_accuracy: 0.5511\n",
      "Epoch 398/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.8552 - val_loss: 1.9516 - val_accuracy: 0.5511\n",
      "Epoch 399/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8438 - val_loss: 1.9194 - val_accuracy: 0.5457\n",
      "Epoch 400/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8517 - val_loss: 2.0820 - val_accuracy: 0.5152\n",
      "Epoch 401/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8411 - val_loss: 1.9723 - val_accuracy: 0.5370\n",
      "Epoch 402/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2938 - accuracy: 0.8563 - val_loss: 1.9001 - val_accuracy: 0.5391\n",
      "Epoch 403/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8593 - val_loss: 1.9762 - val_accuracy: 0.5446\n",
      "Epoch 404/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8457 - val_loss: 2.0222 - val_accuracy: 0.5359\n",
      "Epoch 405/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8498 - val_loss: 1.9785 - val_accuracy: 0.5413\n",
      "Epoch 406/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8620 - val_loss: 2.0030 - val_accuracy: 0.5446\n",
      "Epoch 407/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2939 - accuracy: 0.8595 - val_loss: 2.0131 - val_accuracy: 0.5446\n",
      "Epoch 408/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8555 - val_loss: 1.9565 - val_accuracy: 0.5446\n",
      "Epoch 409/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8547 - val_loss: 2.0039 - val_accuracy: 0.5500\n",
      "Epoch 410/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.8574 - val_loss: 2.0184 - val_accuracy: 0.5250\n",
      "Epoch 411/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8484 - val_loss: 2.0429 - val_accuracy: 0.5370\n",
      "Epoch 412/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8598 - val_loss: 2.0726 - val_accuracy: 0.5380\n",
      "Epoch 413/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2915 - accuracy: 0.8642 - val_loss: 1.9765 - val_accuracy: 0.5565\n",
      "Epoch 414/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8528 - val_loss: 2.0622 - val_accuracy: 0.4978\n",
      "Epoch 415/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8506 - val_loss: 2.0851 - val_accuracy: 0.5076\n",
      "Epoch 416/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8538 - val_loss: 2.0615 - val_accuracy: 0.5304\n",
      "Epoch 417/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8606 - val_loss: 2.1618 - val_accuracy: 0.5293\n",
      "Epoch 418/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8549 - val_loss: 2.0016 - val_accuracy: 0.5522\n",
      "Epoch 419/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8514 - val_loss: 2.1473 - val_accuracy: 0.5022\n",
      "Epoch 420/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8509 - val_loss: 1.9111 - val_accuracy: 0.5739\n",
      "Epoch 421/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8566 - val_loss: 2.0518 - val_accuracy: 0.5391\n",
      "Epoch 422/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8555 - val_loss: 2.1078 - val_accuracy: 0.5087\n",
      "Epoch 423/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8609 - val_loss: 2.0319 - val_accuracy: 0.5576\n",
      "Epoch 424/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8587 - val_loss: 2.1168 - val_accuracy: 0.5315\n",
      "Epoch 425/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 0.8587 - val_loss: 2.1965 - val_accuracy: 0.5098\n",
      "Epoch 426/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.8538 - val_loss: 2.1405 - val_accuracy: 0.5304\n",
      "Epoch 427/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8549 - val_loss: 2.0862 - val_accuracy: 0.5424\n",
      "Epoch 428/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8566 - val_loss: 2.1447 - val_accuracy: 0.5413\n",
      "Epoch 429/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.8519 - val_loss: 2.0034 - val_accuracy: 0.5576\n",
      "Epoch 430/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.8574 - val_loss: 2.0496 - val_accuracy: 0.5424\n",
      "Epoch 431/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8533 - val_loss: 2.0467 - val_accuracy: 0.5446\n",
      "Epoch 432/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8476 - val_loss: 2.0613 - val_accuracy: 0.5478\n",
      "Epoch 433/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8593 - val_loss: 2.0889 - val_accuracy: 0.5283\n",
      "Epoch 434/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2813 - accuracy: 0.8642 - val_loss: 1.9807 - val_accuracy: 0.5750\n",
      "Epoch 435/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8560 - val_loss: 2.1857 - val_accuracy: 0.5152\n",
      "Epoch 436/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8628 - val_loss: 2.1535 - val_accuracy: 0.5620\n",
      "Epoch 437/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2896 - accuracy: 0.8582 - val_loss: 2.1493 - val_accuracy: 0.5359\n",
      "Epoch 438/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2885 - accuracy: 0.8563 - val_loss: 2.1214 - val_accuracy: 0.5457\n",
      "Epoch 439/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8579 - val_loss: 1.9937 - val_accuracy: 0.5652\n",
      "Epoch 440/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.8625 - val_loss: 2.0585 - val_accuracy: 0.5467\n",
      "Epoch 441/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8479 - val_loss: 2.1115 - val_accuracy: 0.5511\n",
      "Epoch 442/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8495 - val_loss: 2.1007 - val_accuracy: 0.5511\n",
      "Epoch 443/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2940 - accuracy: 0.8590 - val_loss: 2.1932 - val_accuracy: 0.5446\n",
      "Epoch 444/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8644 - val_loss: 2.1811 - val_accuracy: 0.5261\n",
      "Epoch 445/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 0.8574 - val_loss: 2.0422 - val_accuracy: 0.5641\n",
      "Epoch 446/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.8601 - val_loss: 2.0992 - val_accuracy: 0.5076\n",
      "Epoch 447/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2936 - accuracy: 0.8552 - val_loss: 2.2472 - val_accuracy: 0.4696\n",
      "Epoch 448/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8563 - val_loss: 2.0533 - val_accuracy: 0.5511\n",
      "Epoch 449/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.8598 - val_loss: 2.2090 - val_accuracy: 0.4870\n",
      "Epoch 450/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8579 - val_loss: 2.0257 - val_accuracy: 0.5587\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8579 - val_loss: 2.1558 - val_accuracy: 0.5380\n",
      "Epoch 452/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8650 - val_loss: 2.0891 - val_accuracy: 0.5522\n",
      "Epoch 453/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8585 - val_loss: 2.1335 - val_accuracy: 0.5380\n",
      "Epoch 454/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8669 - val_loss: 2.0841 - val_accuracy: 0.5109\n",
      "Epoch 455/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8416 - val_loss: 2.1443 - val_accuracy: 0.5380\n",
      "Epoch 456/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8631 - val_loss: 2.1757 - val_accuracy: 0.5489\n",
      "Epoch 457/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8574 - val_loss: 2.1816 - val_accuracy: 0.5326\n",
      "Epoch 458/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8653 - val_loss: 2.2107 - val_accuracy: 0.5196\n",
      "Epoch 459/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8549 - val_loss: 2.1857 - val_accuracy: 0.5446\n",
      "Epoch 460/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.8563 - val_loss: 2.1669 - val_accuracy: 0.5120\n",
      "Epoch 461/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.8628 - val_loss: 2.1973 - val_accuracy: 0.5272\n",
      "Epoch 462/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2848 - accuracy: 0.8663 - val_loss: 2.1525 - val_accuracy: 0.5522\n",
      "Epoch 463/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8653 - val_loss: 2.0973 - val_accuracy: 0.5446\n",
      "Epoch 464/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8604 - val_loss: 2.1412 - val_accuracy: 0.5130\n",
      "Epoch 465/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2863 - accuracy: 0.8590 - val_loss: 2.1822 - val_accuracy: 0.5457\n",
      "Epoch 466/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8555 - val_loss: 2.0804 - val_accuracy: 0.5326\n",
      "Epoch 467/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2854 - accuracy: 0.8617 - val_loss: 2.2055 - val_accuracy: 0.5380\n",
      "Epoch 468/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8587 - val_loss: 2.3899 - val_accuracy: 0.4620\n",
      "Epoch 469/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.8530 - val_loss: 2.2867 - val_accuracy: 0.4837\n",
      "Epoch 470/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8576 - val_loss: 2.1408 - val_accuracy: 0.5609\n",
      "Epoch 471/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.8587 - val_loss: 2.2677 - val_accuracy: 0.5293\n",
      "Epoch 472/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.8617 - val_loss: 2.3324 - val_accuracy: 0.5250\n",
      "Epoch 473/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8623 - val_loss: 2.2350 - val_accuracy: 0.5326\n",
      "Epoch 474/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.8634 - val_loss: 2.1145 - val_accuracy: 0.5446\n",
      "Epoch 475/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.8655 - val_loss: 2.1675 - val_accuracy: 0.5152\n",
      "Epoch 476/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8609 - val_loss: 2.2546 - val_accuracy: 0.5457\n",
      "Epoch 477/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8617 - val_loss: 2.2337 - val_accuracy: 0.4891\n",
      "Epoch 478/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8557 - val_loss: 2.1757 - val_accuracy: 0.5402\n",
      "Epoch 479/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2787 - accuracy: 0.8685 - val_loss: 2.1540 - val_accuracy: 0.5565\n",
      "Epoch 480/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8666 - val_loss: 2.0791 - val_accuracy: 0.5598\n",
      "Epoch 481/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2832 - accuracy: 0.8617 - val_loss: 2.2147 - val_accuracy: 0.5359\n",
      "Epoch 482/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8617 - val_loss: 2.0936 - val_accuracy: 0.5674\n",
      "Epoch 483/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8655 - val_loss: 2.2005 - val_accuracy: 0.5413\n",
      "Epoch 484/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8625 - val_loss: 2.2495 - val_accuracy: 0.5348\n",
      "Epoch 485/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8585 - val_loss: 2.2947 - val_accuracy: 0.5402\n",
      "Epoch 486/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.8625 - val_loss: 2.2540 - val_accuracy: 0.5304\n",
      "Epoch 487/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8617 - val_loss: 2.3350 - val_accuracy: 0.5348\n",
      "Epoch 488/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.8612 - val_loss: 2.1530 - val_accuracy: 0.5652\n",
      "Epoch 489/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.8623 - val_loss: 2.3281 - val_accuracy: 0.4913\n",
      "Epoch 490/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8615 - val_loss: 2.2853 - val_accuracy: 0.5489\n",
      "Epoch 491/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8620 - val_loss: 2.1394 - val_accuracy: 0.5554\n",
      "Epoch 492/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8628 - val_loss: 2.1781 - val_accuracy: 0.5457\n",
      "Epoch 493/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8563 - val_loss: 2.2367 - val_accuracy: 0.5141\n",
      "Epoch 494/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2793 - accuracy: 0.8595 - val_loss: 2.2706 - val_accuracy: 0.5011\n",
      "Epoch 495/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8634 - val_loss: 2.1923 - val_accuracy: 0.5304\n",
      "Epoch 496/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8623 - val_loss: 2.3332 - val_accuracy: 0.5446\n",
      "Epoch 497/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2795 - accuracy: 0.8623 - val_loss: 2.2730 - val_accuracy: 0.5500\n",
      "Epoch 498/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8636 - val_loss: 2.3138 - val_accuracy: 0.5304\n",
      "Epoch 499/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2822 - accuracy: 0.8593 - val_loss: 2.2216 - val_accuracy: 0.5380\n",
      "Epoch 500/500\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.8685 - val_loss: 2.2651 - val_accuracy: 0.5457\n"
     ]
    }
   ],
   "source": [
    "hist =  mod.fit(x=train_x, y=train_y,\n",
    "                  epochs=500, batch_size=20,\n",
    "                  validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f451da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
